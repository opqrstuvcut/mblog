<!DOCTYPE html>
<html lang="ja">
<head>
	<meta name="generator" content="Hugo 0.148.2"><script src="/mblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=mblog/livereload" data-no-instant defer></script>
  
    <title>MatLoverによるMatlab以外のブログ</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/mblog/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LFC5W8DKV1"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-LFC5W8DKV1');
        }
      </script>



  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terminal.min.77ee67c1d456ac0c280223661a10b75c7729c59aeb33001424a72a14b363e310.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/mblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/mblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="ja" />
<meta property="og:type" content="website" />
<meta property="og:title" content="MatLoverによるMatlab以外のブログ">
<meta property="og:description" content="" />
<meta property="og:url" content="http://localhost:1313/mblog/" />
<meta property="og:site_name" content="MatLoverによるMatlab以外のブログ" />

  <meta property="og:image" content="http://localhost:1313/mblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/mblog/index.xml" rel="alternate" type="application/rss+xml" title="MatLoverによるMatlab以外のブログ" />







<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous">

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
            ],
            throwOnError : false
        });
    });
</script>


<style>
  section.article-content h2 {
    background-color: rgb(245, 245, 245);
    padding: 10px;
  }

  :root {
    --ja-font-family: "メイリオ", "Meiryo";
    --base-font-family: "Lato", var(--sys-font-family), var(--ja-font-family),
      sans-serif;
    --body-background: #ffffe0;
  }


</style>


</head>
<body>


<div class="container full">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://localhost:1313/mblog/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/mblog/">Home</a></li>
        
      
        
          <li><a href="/mblog/archives/">Archives</a></li>
        
      
        
          <li><a href="/mblog/search/">Search</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/mblog/" >Home</a></li>
        
      
        
          <li><a href="/mblog/archives/" >Archives</a></li>
        
      
        
          <li><a href="/mblog/search/" >Search</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
    

    
    
      
    
    

    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/laplacian%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE2%E9%9A%8E%E5%BE%AE%E5%88%86/">Laplacianで画像の2階微分</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-18</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/laplacian/">laplacian</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/laplacian%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE2%E9%9A%8E%E5%BE%AE%E5%88%86/87a340899433b8d46b1c936e1a54fad5.png"
    class="post-cover"
    alt="Laplacianで画像の2階微分"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>今回はLaplacianを扱います。</p>
<h1 id="そもそものlaplacian">そもそものLaplacian</h1>
<p>Laplacianの復習的な話ですが、2階偏微分可能な関数$f(x,y)$に対して以下をLaplacianといいます。
$$ \Delta f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}.  $$</p>
<p>これを画像に適用することで、ピクセル値の極小値あるいは極大値となるピクセルを見つけることが可能になります。これはエッジ検出に利用可能だということがわかるかと思います。</p>
<h1 id="laplacianのフィルタ">Laplacianのフィルタ</h1>
<p>Laplacianのフィルタの最も基本的なものは以下で定義されます。</p>
<p><img src="/mblog/posts/laplacian%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE2%E9%9A%8E%E5%BE%AE%E5%88%86/bee0ab3292b4f50ed6d2be23f0c1016e.png" alt=""></p>
<p>これを使った畳み込み演算によってLaplacianができるという主張ですが、このフィルタの導出は以下のとおりです。</p>
<p>$(x,y)$の位置にあるピクセルの1階の偏微分の近似は以下のようにあらわされます。</p>
<p>$$ \frac{\partial f}{\partial x} \approx f(x + 1, y) - f(x,y ).$$
これを利用すると、2階の偏微分は</p>
<p>$$\begin{aligned} \frac{\partial^2 f}{\partial x^2} &amp;\approx&amp; f(x+1,y ) - f(x, y) - (f(x,y ) - f(x-1,y )) \\ &amp;=&amp; f(x+1, y) - 2f(x, y) + f(x-1,y ).\end{aligned}$$
同様に
$$  \begin{aligned}
\frac{\partial^2 f}{\partial y^2} &amp;\approx&amp; f(x,y+1) - f(x, y) - (f(x,y ) - f(x,y-1 )) \\ &amp;=&amp; f(x, y+1) - 2f(x, y) + f(x,y-1 ).
\end{aligned}$$
よって、
$$  \begin{aligned} \Delta f &amp;= \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} \\ &amp;= f(x+1,y ) - 2f(x,y ) + f(x-1,y ) + f(x,y+1 ) - 2f(x,y ) + f(x,y -1)\\ &amp;= f(x+1,y ) + f(x-1,y ) + f(x,y+1 ) + f(x,y -1) - 4f(x,y ) . \end{aligned} $$
以上から先程のようなフィルタになることが理解できたでしょうか？</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/laplacian%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE2%E9%9A%8E%E5%BE%AE%E5%88%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/">Sobelフィルタで微分</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-16</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/sobel/">Sobel</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/d0092a9ae18af82d66d3a2d25fd7b5b8.png"
    class="post-cover"
    alt="Sobelフィルタで微分"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>よくある画像処理のオペレーターとして、画像の微分があります。
いくつかやり方はありますが、今日はSobel微分を取り上げます。</p>
<h1 id="sobelフィルタ">Sobelフィルタ</h1>
<p>Sobel微分はSobelフィルタを使った畳み込みをすることで実現できます。
例えば、3×3のSobelフィルタは以下のようなカーネルになります。</p>
<p><strong>x方向の微分用のSobelフィルタ</strong></p>
<p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/06f36d9912cf22cbb6024e116ac375c6.png" alt=""></p>
<p><strong>y方向の微分用のSobelフィルタ</strong></p>
<p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/438e89f42f3662532c9b539e8b339e72.png" alt=""></p>
<p>これらのフィルタは何をあらわしているんでしょうか？
実はSobelフィルタは微分と平滑化をあわせもったフィルタになっています。
ここでいう微分のフィルタとはx方向の場合には以下を指します。</p>
<p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/4de0963d506ce8ba6ff7cd4dc964ec89.png" alt=""></p>
<p>これは$(x,y)$座標のピクセルに注目しているときに、その左右にあるピクセルの差を取る演算を示しています。いわゆる中心差分と呼ばれる微分の計算方法になります。</p>
<p>次に平滑化ですが、これは以下のフィルタです。</p>
<p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/b565807c31fbb9a5b556d107afb56dd6.png" alt=""></p>
<p>ガウス平滑化に似たように中心の重みが大きい平滑化になります。</p>
<p>ここまでで定義した微分のフィルタに対して平滑化のフィルタによる畳込みを計算すると、実はSobelフィルタと同じものがあらわれます。つまり、画像に対して微分のフィルタを適用した後に平滑化のフィルタを適用することとと、画像に対してSobelフィルタを適用することは等しいです。</p>
<p>以上がSobelフィルタが何をしているかの話になります。</p>
<h1 id="sobelフィルタを適用">Sobelフィルタを適用</h1>
<p>OpenCVでは以下のようにすることで、Sobelフィルタを適用できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">soblex</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ddepth</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">CV_16S</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span></code></pre></div><p>第二引数のddepthにSobelによる返り値を格納する型を指定します。CV_16Sは符号付きの16ビット整数です。
第三、第四引数のところは微分する次数を指定します。dx=1、dy=0とすると、x方向のSobelフィルタを使うことになりますし、dx=0、dy=1とするとy方向のSobelフィルタです。
最後のksizeはカーネルサイズになります。一応31まで指定が可能なようです。</p>
<p>次の画像にSobelフィルタを適用してみます。</p>
<p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/1bd07117287ac2fc9f1b1281b6832c55.png" alt=""></p>
<p>x方向のSobelフィルタの適用</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">soblex</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">noise_img</span><span class="p">,</span> <span class="n">ddepth</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">CV_16S</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/c1bfd5c5980138180846871b0e6266e9.png" alt=""></p>
<p>正の勾配は白色、負の勾配は黒色で描画されています。</p>
<p>y方向のSobelフィルタの適用</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">sobley</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">noise_img</span><span class="p">,</span> <span class="n">ddepth</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">CV_16S</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/211fe0b45188b2279f21d34fa4991f82.png" alt=""></p>
<p>これも同様に正の勾配は白色、負の勾配は黒色で描画されています。</p>
<p>なお、それぞれのSobelフィルタの適用結果を足し合わせると次のようになります。</p>
<p><img src="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/d0092a9ae18af82d66d3a2d25fd7b5b8.png" alt=""></p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/imencode%E3%81%A8imdecode%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E4%B8%8A%E3%81%A7%E3%81%AE%E7%94%BB%E5%83%8F%E5%9C%A7%E7%B8%AE/">imencodeとimdecodeによるメモリ上での画像圧縮</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-16</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%9C%A7%E7%B8%AE/">圧縮</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/imencode%E3%81%A8imdecode%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E4%B8%8A%E3%81%A7%E3%81%AE%E7%94%BB%E5%83%8F%E5%9C%A7%E7%B8%AE/ef33a82444b4c9bca9b7fb97cad0d467.png"
    class="post-cover"
    alt="imencodeとimdecodeによるメモリ上での画像圧縮"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>画像をpngなどからjpgに変換したいときに、ぱっと思いつくのはファイルを読み込んで、それをjpgの拡張子で書き込みした後に再度読み込みなおすことです。
1度動かすならばそれでも良いのですが、何度も繰り返しおこなう場合にはファイルの読み書きの時間が気になります。</p>
<p>OpenCVではファイルへの読み書きをおこなうことなく、<strong>メモリ上でファイル形式を変更</strong>できる（jpgへの圧縮などができる）ような方法が提供されています。</p>
<p>流れとしては、<strong>imencodeでメモリ上にファイル形式を変更したバイト列を作成</strong>し、それを<strong>imdecodeで画像に変換</strong>するという流れになります。imencodeがファイルへの書き込み、imdecodeがファイルの読み込みに対応する感じになります。</p>
<h1 id="imencode">imencode</h1>
<p>画像を他のファイルを形式に変更するimencodeは次のようにして利用します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">ret</span><span class="p">,</span> <span class="n">encoded</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imencode</span><span class="p">(</span><span class="s2">&#34;.jpg&#34;</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">IMWRITE_JPEG_QUALITY</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</span></span></code></pre></div><p>1つめの引数がどの拡張子に変換するかをあらわす文字列で、ここではjpgを指定しています。</p>
<p>3つめの引数に指定した拡張子に変換するときのパラメータを指定します。
例えばjpgの場合には画像の質を指定できますので、それをタプルの形式で与えており、ここではjpgの質を10で圧縮するようにしています。</p>
<p>imencodeによって生成されたjpgになった画像の情報はencodedに格納されています。</p>
<h1 id="imdecode">imdecode</h1>
<p>メモリ上の画像データを読み込むimdecodeは以下のようにします。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">decoded</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imdecode</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_COLOR</span><span class="p">)</span>
</span></span></code></pre></div><p>第一引数はimencodeの出力です。
flagsは何かしら指定しないといけないのですが、これはどう読み込むかをあらわすフラグです。
BGRの3channelで読み込む場合には<strong>cv2.IMREAD_COLOR</strong>を指定し、Gray scaleの1channelで読み込む場合には<strong>cv2.IMREAD_GRAYSCALE</strong>を指定します。</p>
<h1 id="適用結果">適用結果</h1>
<p>jpgのqualityを10にしてimencodeした後にimdecodeした結果を元の画像と比較してみます。</p>
<table>
  <thead>
      <tr>
          <th>元画像</th>
          <th>imdecode後の画像</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/imencode%E3%81%A8imdecode%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E4%B8%8A%E3%81%A7%E3%81%AE%E7%94%BB%E5%83%8F%E5%9C%A7%E7%B8%AE/92b8b770bc70d432712df04481e7be54.png" alt=""></td>
          <td><img src="/mblog/posts/imencode%E3%81%A8imdecode%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E4%B8%8A%E3%81%A7%E3%81%AE%E7%94%BB%E5%83%8F%E5%9C%A7%E7%B8%AE/ef33a82444b4c9bca9b7fb97cad0d467.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>右側の画像はノイズがのっていることが分かるでしょうか？ちゃんとjpgの形式で圧縮されたようです。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/imencode%E3%81%A8imdecode%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E4%B8%8A%E3%81%A7%E3%81%AE%E7%94%BB%E5%83%8F%E5%9C%A7%E7%B8%AE/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/">サンプルコードでなにかとあらわれるガウス平滑化</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-14</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%B9%B3%E6%BB%91%E5%8C%96/">平滑化</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/">ガウス平滑化</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/bc05ecb93cbcd05f4c4724aca94cb99d.png"
    class="post-cover"
    alt="サンプルコードでなにかとあらわれるガウス平滑化"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>今日はなにかとサンプルコードで使われるガウス平滑化です。</p>
<h1 id="ガウス平滑化とは">ガウス平滑化とは</h1>
<p>前々回取り上げた単純平滑化は局所領域の平均をとることで、平滑化をおこないました。これは局所領域内の各ピクセルの重み付けがすべて等しいともいえます。
ガウス平滑化では二次元のガウス分布を離散化した値を重みとして利用するような平滑化になります。
$$g(x,y) = \frac{1}{2\pi\sqrt{\sigma^2}}\exp\left(-\frac{x^2 + y^2}{\sigma^2}\right).$$</p>
<h1 id="単純平滑化との違いは">単純平滑化との違いは？</h1>
<p>具体的なカーネルの比較の例は以下のとおりです。</p>
<table>
  <thead>
      <tr>
          <th>単純平滑化</th>
          <th>ガウス平滑化</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/8895112ad45858fe181a5e782b6272b8.png" alt=""></td>
          <td><img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/a52dd83d01f0b21101de43a83f848fec.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>ガウス平滑化の場合には中心の重みが大きく、そこから遠ざかるほど、重みが小さくなっていきます。</p>
<p>画像に与える影響の違いとしては、単純平滑化よりも中心の重みが大きいことで、平滑化後のボケが少ないことが挙げられます。</p>
<h1 id="単純平滑化とガウス平滑化の違いを実験">単純平滑化とガウス平滑化の違いを実験</h1>
<p>OpenCVでガウス平滑化を使う場合は以下のようにすればOKです。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">blur</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">sigmaX</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sigmaY</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></div><p>ksizeはカーネルの大きさ（局所領域のサイズ）、sigmaXはガウス分布のx方向の分散、sigmaYはy方向の分散になります。分散は0を入れると、デフォルト値を計算し、それを利用してくれます。</p>
<p>次のようなノイズを乗せた画像を用意しました。<br>
<img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/40b4f641660e55df405fd807093db845.png" alt=""></p>
<p>それぞれの平滑化の適用結果が以下のとおりです。すべてカーネルサイズは9×9です。</p>
<table>
  <thead>
      <tr>
          <th>単純平滑化</th>
          <th>メディアンフィルタ</th>
          <th>ガウス平滑化</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/4d71836b404ed79205c7c67756d42792.png" alt=""></td>
          <td><img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/ff4182f83c9c46e9f2ae319ecb7b1269.png" alt=""></td>
          <td><img src="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/bc05ecb93cbcd05f4c4724aca94cb99d.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>単純平滑化とガウス平滑化を比べると、ガウス平滑化のほうが若干ノイズが多めの気がしますが、ボケが少ないです。
メディアンフィルタはノイズは取れますが、もとの情報が結構落ちてますね。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/">外れ値に強いMedianBlur</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-13</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/medianblur/">medianBlur</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/38fd4d2636a29433a5cd4a3204c1dca5.png"
    class="post-cover"
    alt="外れ値に強いMedianBlur"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>単純平滑化の場合には、局所領域内での平均を取るため、周辺とは大きく異なるピクセル値をもつピクセルがあると、その影響が大きすぎて上手くいかない場合があります。
そのようなケースでは中央値を使うようにすると、上手くいくかもしれません。</p>
<h1 id="medianblur">medianBlur</h1>
<p>OpenCVではmedianBlurという関数で局所領域内の中央値を使うような平滑化をおこなえます。</p>
<p>以下がmedianBlurを実際に実行したコードになります。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">cv2</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;noro-min.jpeg&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">blur</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">medianBlur</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">blur</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">blur</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">blur</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p>人工的に画像にノイズを乗せて、blurとmedianBlurを適用した結果を比べてみます。</p>
<table>
  <thead>
      <tr>
          <th>ノイズを乗せた画像</th>
          <th>blurを適用した画像</th>
          <th>medianBlurを適用した画像</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/28e324c722b76a17f033eec94f612f1f.png" alt=""></td>
          <td><img src="/mblog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/3b26ff8d1e9fbe2c3266d45ddecc0122.png" alt=""></td>
          <td><img src="/mblog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/38fd4d2636a29433a5cd4a3204c1dca5.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>中央値を使うことで、ノイズを上手く取り除くことができています。
ただし、文字の部分などは結構ボケるようになりました。中央値を使うと、白い背景と近い部分のピクセルはすべて白に置き換えられてしまうからです。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/">AdaptiveThresholdで照明環境が微妙な画像を二値化</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-11</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/adaptivethreshold/">AdaptiveThreshold</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/849c7e82970effeb19b44b3bf511192f.png"
    class="post-cover"
    alt="AdaptiveThresholdで照明環境が微妙な画像を二値化"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>画像処理で結構シビアなのが、照明環境です。
例えば次の画像のように、画像の中で明暗が異なると、大津の二値化ではうまくいきません。</p>
<table>
  <thead>
      <tr>
          <th>入力画像</th>
          <th>大津の二値化適用</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/eb7aff1ca26db41846c27ade2b8681d2.png" alt=""></td>
          <td><img src="/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/520f7e6ea01d43ab346861221bf1fe10.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>とはいえ、アプリケーションによっては撮影者に常に気をつけてもらうことも難しかったりします。
そんなときにはAdaptiveThresholdが役に立ちます。</p>
<h1 id="adaptivethresholdとは">AdaptiveThresholdとは？</h1>
<p>OpenCVで使えるAdaptiveThresholdには2パターンあるのですが、まずは簡単な局所領域での平均を利用する方から説明します。</p>
<h2 id="局所領域での平均を用いたadaptivethreshold">局所領域での平均を用いたAdaptiveThreshold</h2>
<p>この方法では、ある座標$(x,y)$のピクセルの二値化をおこなうときには、$(x,y)$を中心としたある大きさの局所領域内の各ピクセルのグレースケール値の平均値を計算します。
この平均値から指定した定数を引いた値をしきい値$T(x,y)$とします。
もし$(x,y)$のグレースケール値が$T(x,y)$を超えれば255に置き換え（255以外にもこの値は指定できます）て、$T(x,y)$以下であれば、$0$にします。</p>
<p>ざっくり言えば、$(x,y)$の周辺領域の平均値を二値化のしきい値にするということになります。</p>
<p>こうすると何が良いかといえば、周辺領域が暗ければ、しきい値は暗い方に設定されますし、周辺領域が明るければ、しきい値は明るい方に設定されます。つまり、局所領域内である程度明暗がわかれていれば、きちんと二値化ができるということです。すごいですね。</p>
<p>この方法は、次のようにcv2.adaptiveThresholdによって利用可能です。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">gray_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">bi_img</span>  <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">adaptiveThreshold</span><span class="p">(</span><span class="n">gray_img</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">cv2</span><span class="o">.</span><span class="n">ADAPTIVE_THRESH_MEAN_C</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_BINARY</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bi_img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/6abacf437bd256e750b4faee6d4e7863.png" alt=""></p>
<p>ちゃんとそれっぽく二値化されてます！</p>
<p>adaptiveThresholdの各引数は以下のとおりです。
局所領域は$(x,y)$を中心とした領域になるため、<strong>領域の大きさは奇数で指定</strong>しなければいけないことに注意してください。</p>
<table>
  <thead>
      <tr>
          <th>引数</th>
          <th>意味</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>入力画像</td>
      </tr>
      <tr>
          <td>2</td>
          <td>ここで説明した方法を使うことをあらわす値</td>
      </tr>
      <tr>
          <td>3</td>
          <td>threshold typeでこれは前々回説明したものと同じ</td>
      </tr>
      <tr>
          <td>4</td>
          <td>周辺領域の大きさで、11ということは11×11の領域で平均値を計算している</td>
      </tr>
      <tr>
          <td>5</td>
          <td>しきい値を決めるときに平均値から引かれる定数</td>
      </tr>
  </tbody>
</table>
<h2 id="局所領域でのガウス分布による重み付を用いたadaptivethreshold">局所領域でのガウス分布による重み付を用いたAdaptiveThreshold</h2>
<p>先程の平均値は局所領域内は平等に扱うような方法でしたが、問題によっては、局所領域の中心$(x,y)$に近いほど重要視して、遠ざかるほど影響を小さくしたいなぁと思うときがあります。
そんなときにはガウス分布による重み付けを利用することができます。</p>
<p>OpenCVで利用するときにはさきほどの第二引数を<strong>cv2.ADAPTIVE_THRESH_GAUSSIAN_C</strong>に変えるだけでOKです。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">gray_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">bi_img</span>  <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">adaptiveThreshold</span><span class="p">(</span><span class="n">gray_img</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">cv2</span><span class="o">.</span><span class="n">ADAPTIVE_THRESH_GAUSSIAN_C</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_BINARY</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bi_img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/849c7e82970effeb19b44b3bf511192f.png" alt=""></p>
<p>こちらも上手くいっています。</p>
<h1 id="おわりに">おわりに</h1>
<p>問題設定によっては平均の方だと上手くいかず、ガウス分布の重み付けのほうは上手くいったりしますので、そのあたりの使い分けは試行錯誤するしかないかなと思います。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/">大津の二値化で楽をする</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-07-10</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E4%BA%8C%E5%80%A4%E5%8C%96/">二値化</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%A4%A7%E6%B4%A5%E4%BA%8C%E5%80%A4%E5%8C%96/">大津二値化</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/28686c735e0c8f6271a0dd5b95693c1a.png"
    class="post-cover"
    alt="大津の二値化で楽をする"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<h1 id="大津の2値化とは">大津の2値化とは？</h1>
<p>シンプルな二値化では、何かしらのしきい値を決めてあげる必要がありました。</p>
<p>人間がグレースケール値のヒストグラムを見てしきい値を決めたり、試行錯誤するというのも良いですが、場合によってはしきい値を自動で決定したくなります。</p>
<p>そのような方法として有名なのが大津の2値化です。
大津の2値化を使うことで、ある意味での最適なしきい値を決定してくれます。</p>
<h1 id="大津の2値化の中身は">大津の2値化の中身は？</h1>
<p>大津の2値化では、グレースケールのヒストグラムを描いたときに、山が2つ存在するケースを想定しています。例えば次のようなヒストグラムです。<br>
<img src="/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/2cddfa11c25f3a6ebe609ba0fa5dc8ea.png" alt=""></p>
<p>つまり、画像の白い部分と黒い部分の区別がある程度はっきりとつくようなケースを指しています。
白いところ、黒いところ、それらの間くらいの色の3種類が多数を占めているような、ヒストグラム上で山が3つできるような状況は想定されていません（アプリケーションによっては、それでも上手くいくかもしれませんが）。</p>
<p>さて、ヒストグラムが2つの山をもつようなグレースケールの画像が与えられたとして、大津の2値化はどのようにしきい値を決めているのでしょうか？</p>
<p>大津の2値化では、しきい値以下のグレースケール値としきい値より大きい値のグレースケール値の2つのグループにわけ、それぞれの分散をそれぞれ計算した後、それらの重み付きの和を考えます。しきい値はこの分散の重み付き和が最小になるように決められます。</p>
<p>式であらわせば、グレースケール値のしきい値$t$、しきい値$t$以下のグループの分散$\sigma-2_1(t)$、しきい値より大きいグループの分散$\sigma^2_2(t)$、しきい値以下の値の個数$q_1(t)$、しきい値より大きい値の個数$q_2(t)$を用いて以下のようになります。</p>
<p>$$ \sigma^2(t)=p_1(t) \sigma^2_1(t) + p_2(t) \sigma^2_2(t).$$</p>
<p>大津の2値化では$\sigma^2(t)$を最小化するようなしきい値$t$を見つけます。</p>
<p>直感的には分散が最小になるようなしきい値を見つけるのは良い方法のように思えます。
なぜかといえば、谷の部分からしきい値を動かしていき、どちらかの山の一部が他方のグループに取り込まれると、取り込まれた分が与える分散の増加分が非常に大きいと予想できるからです。</p>
<h1 id="大津の2値化の適用結果">大津の2値化の適用結果</h1>
<p>大津の2値化を実際に適用してみます。
次のようなグレースケールの画像が与えられたとします。</p>
<p><img src="/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/bb8d931f67d1a9957fb65c5605ed86af.png" alt=""></p>
<p>この画像のグレースケール値のヒストグラムは以下のとおりです（先程のヒストグラムと同じものです）。</p>
<p><img src="/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/8a267c58a6c9a13ad6abd0ec6677ec8a.png" alt=""></p>
<p>大津の2値化を適用する際にはThreshoold typeのところにcv2.THRESH_OTSUを追加します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">ret</span><span class="p">,</span> <span class="n">bin_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_BINARY</span> <span class="o">+</span> <span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_OTSU</span><span class="p">)</span>
</span></span></code></pre></div><p>上記のようなコードを実行すると、大津の2値化によって2値化された画像が得られます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&#34;ex_img.jpg&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ret</span><span class="p">,</span> <span class="n">bin_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_BINARY</span> <span class="o">+</span> <span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_OTSU</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bin_img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/28686c735e0c8f6271a0dd5b95693c1a.png" alt=""></p>
<p>しきい値が自動で適切に設定され、キレイに二値化できてますね。</p>
<h1 id="ガウシアンフィルタとの組み合わせ">ガウシアンフィルタとの組み合わせ</h1>
<p>ここでは詳しくは述べませんが、ノイズが多い画像では、ガウシアンフィルタで平滑化することでノイズが軽減され、ヒストグラムの山がよりシャープになりえます。</p>
<p>そうすると、大津の2値化後の結果がより人間の感覚にあったものとなったりします。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/">貧乏人なのでPoor Man’s BERTを読んで解説</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-06-21</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/bert/">BERT</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/deeplearning/">DeepLearning</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E/">自然言語</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%92%B8%E7%95%99/">蒸留</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E9%AB%98%E9%80%9F%E5%8C%96/">高速化</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/transformer/">Transformer</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/">深層学習</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>最近自然言語処理をよくやっていて、BERTを使うことも多いです。
BERTの性能は高く素晴らしいのですが、実際使う上では、私のような計算リソース弱者には辛いところがあります。</p>
<p>例えば、BERTは非常にパラメータ数が多いことで有名ですが、パラメータが多いと、fine-tuningでの学習や推論の時間がかかることや大きめのメモリが積んであるGPUがないと学習ができない、といった部分がネックになりえます。</p>
<p>BERTのパラメータ数を減らす試みとしてはTinyBERTやDistilBERTによる蒸留を使った手法がありますが、今回紹介する<a href="https://arxiv.org/abs/2004.03844">Poor Man’s BERT: Smaller and Faster Transformer Models</a>ではBERTのTransformerの数を単純に減らすことでパラメータ数を減らしています。</p>
<p>実際にTinyBERTやDistilBERTと同じことをするのは難しいですが、今回のように層を減らして学習するのは容易にできますので、とても実用性があるのではないかと思います。</p>
<h1 id="比較実験">比較実験</h1>
<p>論文では12層のTransformerをもつBERTモデルから色々な方法でTransformerを減らし、性能比較をおこなっています。24層をもつ、いわゆるBERT-Largeは、貧乏人にはメモリが足らずにfine-tuningも難しいのです。</p>
<p>次の図がTransformer層の減らし方の一覧です。</p>
<p><img src="/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/5f4774908272540e27f4ce5fc5750c2a.png" alt=""></p>
<p>各方法の詳細は以下のとおりです。</p>
<h2 id="top-layer-dropping">Top-Layer Dropping</h2>
<p>先行研究によると、BERTの後ろの層は目的関数に特化したような重みになっているようです。つまり、BERTで汎用的に使えるように学習されている部分は前の層ということになります。
このため、後ろの層に関しては減らしても性能がそんなに悪化しないんじゃないかという仮定のもと、BERTの最後から4つあるいは6つのTransformerを削除します。</p>
<h2 id="even-alternate-droppingodd-alternate-dropping">Even Alternate Dropping、Odd Alternate Dropping</h2>
<p>先行研究によると、BERTの各層では冗長性があります。つまり、隣り合った層の出力は似ているということです。
このため、1個おきにTransformerを削除します。</p>
<h2 id="contribution-based-dropping">Contribution based Dropping</h2>
<p>Alternate Droppingと少し似ていますが、入力と出力があまり変わらないような層を削除するような方法です。
各Transformer層のなかで[CLS]の入力と出力のcosine類似度が大きい傾向にある層をあらかじめ見つけておき、それを削除します。</p>
<h2 id="symmetric-dropping">Symmetric Dropping</h2>
<p>もしかすると、12層のTransformerのうち、真ん中のあたりはあまり重要じゃないかもしれません。
ということで、前と後ろは残して真ん中付近のTransformerを削除します。</p>
<h2 id="bottom-layer-dropping">Bottom-Layer Dropping</h2>
<p>BERTの最初のほうの層が文脈の理解に重要といわれており、最初のほうを消す理論的な理由はないですが、年のために最初のほうのTransformerを削除したモデルも試します。</p>
<h1 id="実験">実験</h1>
<h2 id="手法間の性能比較">手法間の性能比較</h2>
<p>先程示した方法とDistilBERTをGLUEタスクのスコアで比較した結果が以下になります。BERTだけではなくXLNetでも実験してくれています。</p>
<p><img src="/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/ade970e39b6211acf56131ea9aadba79.png" alt=""></p>
<p>これから以下のことが分かります。</p>
<ul>
<li>各方法のスコアは12層あるBertには劣る。</li>
<li>4層減らす分にはBottom-Layer Dropping以外の方法ではそれほど性能に差がでないが、6層減らす場合にはTop-Layer Dropping（最後の6層を消す）が性能劣化が小さい。</li>
<li>Top-Layer Droppingの6層を消した場合はDistilBERTと似たような性能になっている。学習の手間はDistilBERTのほうが圧倒的に大きいので、性能が同程度、計算時間も同程度ならば本手法を使うメリットが大きいです。</li>
<li>XLNetの場合には最後の4層を消したモデルでも12層あるXLNetとほぼ同じ性能が出せる（＝性能劣化が少ない）。</li>
</ul>
<h2 id="タスクごとの性能変化の検証">タスクごとの性能変化の検証</h2>
<p>次にタスクごとの性能の変化を見ていきます。前の実験から後ろの層を消していくTop-Layer Droppingが良いとわかっているため、Top-Layer Droppingに限って実験がされています。</p>
<p><img src="/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/b57a4ec7197ef20d888886b7a515f4d1.png" alt=""></p>
<p>問題によっては6層消してもほとんど変化がなかったりします。</p>
<p>余談ですが、私が自分で試したある問題では6層消して8ポイント分、4層消して4ポイント分の性能劣化、2層消して2ポイント分の性能劣化になりました。</p>
<h2 id="タスクごとの性能劣化がおこる層数の検証">タスクごとの性能劣化がおこる層数の検証</h2>
<p>タスクごとに後ろを何層削ると1%、2%、3%の性能劣化がおこるのかを示した表です。</p>
<p><img src="/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/43d338f8c5365b5751f603e4304d4337.png" alt=""></p>
<p>ビックリしますが、XLNetは結構層を消しても性能劣化が起こりづらいですね。</p>
<h2 id="パラメータ数や計算時間比較">パラメータ数や計算時間比較</h2>
<p>学習時間・推論時間は削った層の割合だけおおよそ減ることが予想されますが、実際に計算時間がどれくらい変わったかを示したのが以下の表です。</p>
<p><img src="/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/75c986295e10731fc36355969fc01cf6.png" alt=""></p>
<p>6層削ったモデルでは学習時間・推論時間の両方でだいたい半分くらいになってますね。</p>
<h2 id="bertとxlnetの層数での比較">BERTとXLNetの層数での比較</h2>
<p>BERTとXLNetのTransformerの数を変えると、どう性能が変化するかを示したのが以下の図です。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/aws%E3%81%AElambda%E3%81%8B%E3%82%89postgres%E3%82%92%E5%88%A9%E7%94%A8/">AWSのLambdaからPostgresを利用</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-05-04</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/aws/">AWS</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/postgresql/">PostgreSQL</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/python/">Python</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/lambda/">Lambda</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>AWSのLambda（Python）からPostgresを利用するためのライブラリの使い方のメモです。何もトラブルなく使えましたが、一応。
ライブラリのレポジトリは<a href="https://github.com/jkehler/awslambda-psycopg2">こちら</a>です。</p>
<ol>
<li>ライブラリのclone</li>
</ol>
<pre tabindex="0"><code>git clone https://github.com/jkehler/awslambda-psycopg2.git
</code></pre><ol start="2">
<li>
<p>適切な名前にリネーム
LambdaでPython3.6を利用する場合にはcloneしてきたレポジトリにある<strong>psycopg2-3.6</strong>を<strong>psycopg2</strong>にリネームします。あるいはPython3.7を利用する方は<strong>psycopg2-3.7</strong>を<strong>psycopg2</strong>にリネームします。</p>
</li>
<li>
<p>適切な位置への配置<br>
psycopg2をLambdaにデプロイするコードと同じディレクトリに配置します。
例： lambda/hoge.pyというPythonスクリプトをデプロイする場合にはlambdaディレクトリ以下にpsycopg2を配置する。</p>
</li>
<li>
<p>Lambdaにデプロイする！</p>
</li>
</ol>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/aws%E3%81%AElambda%E3%81%8B%E3%82%89postgres%E3%82%92%E5%88%A9%E7%94%A8/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E9%96%A2%E6%95%B0%E3%81%8C%E4%B8%8A%E3%81%AB%E5%87%B8%E3%81%A7%E3%81%82%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E5%BF%85%E8%A6%81%E5%8D%81%E5%88%86%E6%9D%A1%E4%BB%B6%E3%81%AF%E3%83%98%E3%83%83%E3%82%BB%E8%A1%8C%E5%88%97%E3%81%8C%E5%8D%8A%E8%B2%A0%E5%AE%9A%E5%80%A4%E3%81%AE%E8%A8%BC%E6%98%8E/">関数が上に凸であることの必要十分条件はヘッセ行列が半負定値の証明</a>
        </h2>

        <div class="post-meta"><time class="post-date">2020-03-11</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/%E6%95%B0%E5%AD%A6/">数学</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%98%E3%83%83%E3%82%BB%E8%A1%8C%E5%88%97/">ヘッセ行列</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%B2%A0%E5%AE%9A%E5%80%A4/">負定値</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/hessian/">hessian</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%87%B8/">凸</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>関数が上に凸であることの必要十分条件はヘッセ行列が半負定値であることです。ネット上だと日本語でまとまっている文献があんまりないかもと思ったので、今回はこの証明をまとめます。
なお、関数が下に凸のときにはヘッセ行列は半正定値となります。上に凸の定義を使っているところを下に凸の定義に置き換え、正定値を負定値に置き換えれば、同じ議論が可能です。
また出てくる関数$f$は暗黙的に定義域で2階微分可能としています。</p>
<h1 id="定義">定義</h1>
<h2 id="関数が上に凸の定義">関数が上に凸の定義</h2>
<p>関数$f:\mathbb{R}^{n} \rightarrow \mathbb{R}$が上に凸とは任意の元$\mathbf{x}^{(1)}, \mathbf{x}^{(2)} \in \mathbb{R}^{n}$と任意の$t \in [0,1]$に対して以下が成り立つことを指します。
$$ f(t\mathbf{x}^{(2)} + (1 -t)\mathbf{x}^{(1)}) \geq tf(\mathbf{x}^{(2)}) + (1 -t) f(\mathbf{x}^{(1)}).$$</p>
<h2 id="ヘッセ行列の定義">ヘッセ行列の定義</h2>
<p>関数$f:\mathbb{R}^{n} \rightarrow \mathbb{R}$のヘッセ行列$H$を以下のように定義します。
$$H_f = \nabla^2 f = \begin{pmatrix} \frac{\partial^2 f}{\partial x_1^2}   &amp;\frac{\partial^2 f}{\partial x_1\partial x_2} &amp; \dots &amp; \frac{\partial^2 f}{\partial x_1\partial x_n} \cr
\frac{\partial^2 f}{\partial x_2\partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2}   &amp; \dots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \cr
\vdots &amp;  \vdots &amp; \ddots  &amp; \vdots \cr
\frac{\partial^2 f}{\partial x_n\partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2}   &amp; \dots &amp; \frac{\partial^2 f}{ \partial x_n^2}
\end{pmatrix}.$$</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E9%96%A2%E6%95%B0%E3%81%8C%E4%B8%8A%E3%81%AB%E5%87%B8%E3%81%A7%E3%81%82%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E5%BF%85%E8%A6%81%E5%8D%81%E5%88%86%E6%9D%A1%E4%BB%B6%E3%81%AF%E3%83%98%E3%83%83%E3%82%BB%E8%A1%8C%E5%88%97%E3%81%8C%E5%8D%8A%E8%B2%A0%E5%AE%9A%E5%80%A4%E3%81%AE%E8%A8%BC%E6%98%8E/">[Read more]</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
      <a href="/mblog/page/6/" class="button inline prev">
        &lt; [<span class="button__text">Newer posts</span>]
      </a>
    
    
      ::
    
    
      <a href="/mblog/page/8/" class="button inline next">
        [<span class="button__text">Older posts</span>] &gt;
      </a>
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/mblog/bundle.min.js"></script>





  
</div>

</body>
</html>
