<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>重要度 on MatLoverによるMatlab以外のブログ</title>
    <link>http://localhost:1313/mblog/tags/%E9%87%8D%E8%A6%81%E5%BA%A6/</link>
    <description>Recent content in 重要度 on MatLoverによるMatlab以外のブログ</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Wed, 12 Feb 2020 00:23:01 +0900</lastBuildDate>
    <atom:link href="http://localhost:1313/mblog/tags/%E9%87%8D%E8%A6%81%E5%BA%A6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>モデルの予測結果を説明するLIMEの理論</title>
      <link>http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/</link>
      <pubDate>Wed, 12 Feb 2020 00:23:01 +0900</pubDate>
      <guid>http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;モデルの予測結果を説明する方法として&lt;strong&gt;LIME&lt;/strong&gt;があります。&#xA;LIMEはディープラーニングに限らず、任意のモデルに対して予測結果を適用することができます。&#xA;また手法としては結構有名かと思います。&lt;/p&gt;&#xA;&lt;p&gt;今回はそんなLIMEの理論について説明します。&lt;/p&gt;&#xA;&lt;p&gt;論文：&lt;a href=&#34;https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf&#34;&gt;“Why Should I Trust You?” Explaining the Predictions of Any Classifie&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;limeの戦略&#34;&gt;LIMEの戦略&lt;/h1&gt;&#xA;&lt;p&gt;任意のモデル$f$に入力$x \in \mathbb{R}^d$が与えられたときの予測結果$f(x)$への特徴量の寄与を求めることを考えます。&lt;/p&gt;&#xA;&lt;p&gt;LIMEでは$x$近傍（近傍については後述）に対しては$f$と同じような予測をすることができる、かつ解釈が容易なモデル$g$を求めます。&#xA;例えば$g$が線形モデルの場合には、$g$の各係数を見ることで特徴量の寄与を得ることが可能です。あるいは$g$が決定木であれば、人間でもある程度容易にモデルの解釈が可能です。ですから、このようなモデル$g$を$f$の代わりに使って、予測結果の解釈をしようというモチベーションです。&#xA;ただし、LIMEでは$g$には特徴量の値が$0$か$1$となるベクトル$x&amp;rsquo;$が入力として与えられるものとします。これは何らかのルールで$x$の要素と$x&amp;rsquo;$の要素が対応づいているとします。ここも詳細をあとで述べます。&#xA;以上のように、解釈が難しいモデル$f$を解釈が容易なモデル$g$に落とし込むことがLIMEのやりたいことになります。&lt;/p&gt;&#xA;&lt;p&gt;実際にどうやって$g$を求めるのかといえば、次式のようになります。&#xA;$${\rm argmin_{g \in G}} \ L(f, g, \pi_x) + \Omega(g).$$&lt;/p&gt;&#xA;&lt;p&gt;ここで、&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$L$は損失関数です。$x$近傍で$g$の予測値が$f$の予測値に近いと、小さくなるように$L$を定義します。&lt;/li&gt;&#xA;&lt;li&gt;$\pi_x$は損失関数で使われる重みで、$x$の近傍点が$x$から遠いほど小さい値を取るようにします。詳細は後述する線形モデルの項を参照。&lt;/li&gt;&#xA;&lt;li&gt;$\Omega$はモデルの複雑さとなります。決定木を使う場合には木の深さであったり、線形モデルの場合には非ゼロの重みの数になります。モデルを解釈するためには、モデルはシンプルな方が良いため、$\Omega$を加えることで$g$をなるべく人間にやさしいモデルにしてあげます。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;まだ色々と詳細を述べていないため、わからないところは多々あると思いますが、上式は&lt;strong&gt;なるべくシンプルなモデルで$x$の近傍で$f$と近似する$g$を見つける&lt;/strong&gt;といったことを意味します。&#xA;この局所的に近似された$g$が得られれば、$x$近傍での特徴量が$g$へ与える寄与がわかる、つまり$f$へ与える寄与が近似的にはわかります。&lt;/p&gt;&#xA;&lt;p&gt;次に画像の場合のケースについて、詳細に踏み込みます。&lt;/p&gt;&#xA;&lt;h1 id=&#34;画像に対する線形モデルでのlime&#34;&gt;画像に対する線形モデルでのLIME&lt;/h1&gt;&#xA;&lt;h2 id=&#34;superpixel&#34;&gt;superpixel&lt;/h2&gt;&#xA;&lt;p&gt;画像にLIMEを適用する場合、まず次のように入力画像をsuperpixelに分割し、領域ごとに寄与を求めていきます。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/1341b73a17da593ffc43cebc86969604.jpg&#34; alt=&#34;&#34;&gt;&#xA;引用元：https://towardsdatascience.com/understanding-how-lime-explains-predictions-d404e5d1829c&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;実際には上記のようにある程度細かく領域を分けますが、以下では例として扱いやすいように次のような画像を考えて、粗く領域を分けていきます（左がオリジナルのくまモンで、右がsuperpixelに分割されたくまモンです）。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/ad1fa258f844d5a4ad33e45d75dcf7da.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/cc5a03cf0c2b50e3217a99edddcc002b.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;各領域を$g$に与える入力$x&amp;rsquo;$の各要素に対応させます。例えば1番の領域が$x&amp;rsquo;$の1番目の要素、2番が2番目の要素のようにします。その上で、$x&amp;rsquo;$の各要素が1のときには対応する領域のピクセルが$x$と同じピクセル値、0のときにはその領域がグレーで埋められた画像と対応していると考えます。&#xA;具体的には&#xA;$$x&amp;rsquo; = [0, 0, 1, 1, 0,0,0,0]$$&#xA;としたとき、3番目と4番目だけが1ですので、この$x&amp;rsquo;$に対応した画像は次のようになります。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/158a3d802d662d2e95988553c4d83e5d.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;近傍のサンプリング&#34;&gt;近傍のサンプリング&lt;/h2&gt;&#xA;&lt;p&gt;LIMEでは $x$の近傍のサンプリングをおこないます。&#xA;画像の場合に近傍とはどうなるんでしょうか？直感的には謎じゃないでしょうか。&lt;/p&gt;&#xA;&lt;p&gt;LIMEの場合には分割された領域のうち、適当な個数（個数もランダムに決めますが、個数の下限は決めておきます）をそのままにし、それ以外をグレーに置き換える処理をします。&#xA;$x&amp;rsquo;$の話でいえば、適当な個数の要素については1とし、それ以外は0とする処理に等しいです。&lt;/p&gt;&#xA;&lt;p&gt;このようにして得られた画像を$x$の近傍として扱います。またこのようにして近傍を得ることを、近傍のサンプリングとします。&#xA;先程示した$x&amp;rsquo;$に対応した画像も$x$の近傍になります。&lt;/p&gt;&#xA;&lt;h2 id=&#34;線形モデルのケース&#34;&gt;線形モデルのケース&lt;/h2&gt;&#xA;&lt;p&gt;$g$が線形モデルの場合には$g(z&amp;rsquo;)$は次のようになります。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
