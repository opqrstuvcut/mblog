<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>画像 on MatLoverによるMatlab以外のブログ</title>
    <link>https://opqrstuvcut.github.io/mblog/tags/%E7%94%BB%E5%83%8F/</link>
    <description>Recent content in 画像 on MatLoverによるMatlab以外のブログ</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 28 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://opqrstuvcut.github.io/mblog/tags/%E7%94%BB%E5%83%8F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>「Hidden in plain sight： VLMs overlook their visual representations」の論文紹介</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/hidden-in-plain-sight-vlms-overlook-their-visual-representations%E3%81%AE%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/hidden-in-plain-sight-vlms-overlook-their-visual-representations%E3%81%AE%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/</guid>
      <description>&lt;p&gt;今回紹介するのは&#xA;&lt;a href=&#34;https://arxiv.org/pdf/2506.08008&#34;&gt;Hidden in plain sight: VLMs overlook their visual representations&lt;/a&gt;&#xA;です.&lt;/p&gt;&#xA;&lt;p&gt;テキストの生成というよりも画像が中心となるタスクに対し、オープンソースのVisual Language Modelの性能について調査した論文になっています.&#xA;DINOやCLIPをLLMに組み込んだマルチモーダルモデルは、単体のViT系のモデルよりも性能が&lt;strong&gt;大きく下がる&lt;/strong&gt;ことを示しています.&lt;/p&gt;</description>
    </item>
    <item>
      <title>外部知識を活用して効率的に性能向上を達成したYOLO-RD</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AD%98%E3%82%92%E6%B4%BB%E7%94%A8%E3%81%97%E3%81%A6%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AB%E6%80%A7%E8%83%BD%E5%90%91%E4%B8%8A%E3%82%92%E9%81%94%E6%88%90%E3%81%97%E3%81%9Fyolo-rd/</link>
      <pubDate>Sat, 31 May 2025 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AD%98%E3%82%92%E6%B4%BB%E7%94%A8%E3%81%97%E3%81%A6%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AB%E6%80%A7%E8%83%BD%E5%90%91%E4%B8%8A%E3%82%92%E9%81%94%E6%88%90%E3%81%97%E3%81%9Fyolo-rd/</guid>
      <description>&lt;p&gt;YOLO-RD (Retriever-Dictionary) は、物体検出の分野で定番となっているYOLO（You Only Look Once）シリーズの最新研究です.&#xA;今回は、ICLR2025で発表されたYOLO-RD(&lt;a href=&#34;https://arxiv.org/abs/2410.15346&#34;&gt;https://arxiv.org/abs/2410.15346&lt;/a&gt;)について解説します.&lt;/p&gt;</description>
    </item>
    <item>
      <title>画像認識モデルの性能をあげるためのTips</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%80%A7%E8%83%BD%E3%82%92%E3%81%82%E3%81%92%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AEtips/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%80%A7%E8%83%BD%E3%82%92%E3%81%82%E3%81%92%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AEtips/</guid>
      <description>&lt;p&gt;画像分類モデルを作っているときに予測精度をあげるのに役に立ったなぁという方法の一覧のメモです。&#xA;簡単にできるものから順に紹介しているつもりです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>画像と自然言語でのマルチモーダルなImageBERT</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%A8%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E3%81%A7%E3%81%AE%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E3%81%AAimagebert/</link>
      <pubDate>Mon, 24 Feb 2020 19:46:50 +0900</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%A8%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E3%81%A7%E3%81%AE%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E3%81%AAimagebert/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;最近Microsoftから発表されたImageBERTについて紹介します。&lt;br&gt;&#xA;ImageBERTはBERTの入力に自然言語だけではなく、画像も受け付けるようにしたマルチモーダルなモデルです。&#xA;また論文ではモデルのアーキテクチャだけではなく、学習方法にも新たな提案がされています。&lt;br&gt;&#xA;実験ではImage-to-Sentenceでの検索とSentence-to-Imageの検索タスクでSOTAが示されています。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
