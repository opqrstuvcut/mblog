<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLaDA on MatLoverによるMatlab以外のブログ</title>
    <link>http://localhost:1313/mblog/tags/llada/</link>
    <description>Recent content in LLaDA on MatLoverによるMatlab以外のブログ</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 30 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/mblog/tags/llada/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>拡散言語モデルのLLaDA</title>
      <link>http://localhost:1313/mblog/posts/%E6%8B%A1%E6%95%A3%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AEllada/</link>
      <pubDate>Mon, 30 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/mblog/posts/%E6%8B%A1%E6%95%A3%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AEllada/</guid>
      <description>&lt;h1 id=&#34;bertを拡張した生成モデル拡散型llmlladaの概要と可能性&#34;&gt;BERTを拡張した生成モデル？拡散型LLM「LLaDA」の概要と可能性&lt;/h1&gt;&#xA;&lt;p&gt;2025年に入り、拡散モデルを用いた大規模言語モデル（LLM）が注目されています.特に「Gemini Diffusion」や「LLaDA（Large Language Diffusion with mAsking）」といった新しいアプローチは、従来の自己回帰型（autoregressive）モデルとは異なる性質を持ち、今後のLLMのあり方を変える可能性すらあります.&#xA;提案手法のLLaDAとLLaMAを比較したものが以下で、提案手法は遜色ない性能が出ています.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E6%8B%A1%E6%95%A3%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AEllada/fig1.png&#34; alt=&#34;性能比較top&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;本記事では、拡散モデルベースのLLMであるLLaDAについて、その背景、構造、実験結果などを解説します.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;自己回帰型モデルの限界&#34;&gt;自己回帰型モデルの限界&lt;/h2&gt;&#xA;&lt;p&gt;従来のLLM（例：GPT系）は自己回帰型モデルに分類され、トークンを一つずつ順番に生成していきます.しかし、この方式には次のような課題があります：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;逐次処理のため推論効率が悪い&lt;/li&gt;&#xA;&lt;li&gt;「Reversal Curse」に弱い（参考：&lt;a href=&#34;https://arxiv.org/pdf/2309.12288%EF%BC%89&#34;&gt;THE REVERSAL CURSE: LLMS TRAINED ON “A IS B” FAIL TO LEARN “B IS A”&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reversal Curseは次の例のようにトム・クルーズの親については回答できても、メアリー・リー・ファイファーの子どもは誰かを答えることができないという問題です.学習データにはそういったデータがないため、このようなことが起こるようです.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E6%8B%A1%E6%95%A3%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AEllada/reversal_curse.png&#34; alt=&#34;Reversal Curse&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;従来のllmのアプローチ&#34;&gt;従来のLLMのアプローチ&lt;/h2&gt;&#xA;&lt;p&gt;LLMでは一般に次の左式か右式の問題を解けるようにモデルのパラメーター$\theta$を学習していきます.&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\max_{\theta} \mathbb{E}_{p_{data}(x)} \log p_\theta(x) \Leftrightarrow \min_\theta {\rm KL}(p_{data}(x)||p_\theta(x)).&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;特に自己回帰モデルの場合は、過去のトークンをもとにして次のトークンを予測する問題を解く形になっています.&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;p_\theta(x) = p_\theta(x^1) \prod_{i=2}^L p_\theta(x^i|x^1,\dots,x^{i-1}).&#xA;$$&lt;/p&gt;&#xA;&lt;h2 id=&#34;lladaのアプローチ拡散モデル型のllm&#34;&gt;LLaDAのアプローチ：拡散モデル型のLLM&lt;/h2&gt;&#xA;&lt;p&gt;LLaDAは、自己回帰ではなく&lt;strong&gt;拡散モデル&lt;/strong&gt;のアプローチを採用しています.これはBERTのようなマスク予測タスクに近く、以下のような構成です.&lt;/p&gt;&#xA;&lt;h3 id=&#34;事前学習pretraining&#34;&gt;事前学習（Pretraining）&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/mblog/posts/%E6%8B%A1%E6%95%A3%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AEllada/fig2_1.png&#34; alt=&#34;事前学習の概要&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;事前学習ではBERTのようにマスクされた単語を当てるタスクを解きます. ただし、BERTは15%をマスクするようにしていましたが、提案手法では0~100%のランダムな割合だけマスクするようになっています.&lt;/p&gt;&#xA;&lt;p&gt;損失関数は次の通りです：&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\mathcal{L}(\theta) := -\mathbb{E}_{t,x_0,x_t} \left[\frac{1}{t} \sum_{i=1}^L \textbf{1}[x_t^i =M]\log p_\theta(x_0^i|x_t) \right].&#xA;$$&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
