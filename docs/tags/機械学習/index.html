<!DOCTYPE html>
<html lang="ja">
<head><script src="/mblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=mblog/livereload" data-no-instant defer></script>
  
    <title>機械学習 :: MatLoverによるMatlab以外のブログ</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LFC5W8DKV1"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-LFC5W8DKV1');
        }
      </script>



  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terminal.min.77ee67c1d456ac0c280223661a10b75c7729c59aeb33001424a72a14b363e310.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/mblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/mblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="ja" />
<meta property="og:type" content="website" />
<meta property="og:title" content="機械学習">
<meta property="og:description" content="" />
<meta property="og:url" content="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/" />
<meta property="og:site_name" content="MatLoverによるMatlab以外のブログ" />

  <meta property="og:image" content="http://localhost:1313/mblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/index.xml" rel="alternate" type="application/rss+xml" title="MatLoverによるMatlab以外のブログ" />







<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous">

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
            ],
            throwOnError : false
        });
    });
</script>


<style>
  section.article-content h2 {
    background-color: rgb(245, 245, 245);
    padding: 10px;
  }

  :root {
    --ja-font-family: "メイリオ", "Meiryo";
    --base-font-family: "Lato", var(--sys-font-family), var(--ja-font-family),
      sans-serif;
    --body-background: #ffffe0;
  }


</style>


</head>
<body>


<div class="container full">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://localhost:1313/mblog/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/mblog/">Home</a></li>
        
      
        
          <li><a href="/mblog/archives/">Archives</a></li>
        
      
        
          <li><a href="/mblog/search/">Search</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/mblog/" >Home</a></li>
        
      
        
          <li><a href="/mblog/archives/" >Archives</a></li>
        
      
        
          <li><a href="/mblog/search/" >Search</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  <h1>Posts for: #機械学習</h1>
  
  <div class="posts">
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/individual-conditional-expectation/">Individual Conditional Expectation</a>
        </h1>
        <div class="post-meta"><time class="post-date">2021-10-19</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/individual-conditional-expectation/">Individual Conditional Expectation</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%AA%AC%E6%98%8E%E5%8F%AF%E8%83%BDai/">説明可能AI</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/individual-conditional-expectation/ice_age.png"
    class="post-cover"
    alt="Individual Conditional Expectation"
    title="Cover Image" />


        <div class="post-content">
          
            <p>Individual Conditional Expectation(ICE)は任意のモデルのある特徴量に対するデータごとの挙動を確認する手法です。<br>
例えば、ある特定のデータのある特徴量が大きくなるにつれ、モデルの出力がどういった変化をするかを見ます。</p>
<p>PDPの記事を先に見ると、理解がはやいかと思います。<br>
<a href="https://opqrstuvcut.github.io/mblog/posts/partial-dependence-plot/">Partial Dependence Plotの解説記事</a></p>
<h1 id="individual-conditional-expectationの概要">Individual Conditional Expectationの概要</h1>
<p>ICEは冒頭に述べたとおりなので、あまり細かい話をする必要がないのですが、Partial Dependence Plot(PDP)との違いを述べておきます。<br>
PDPはデータの集合の全体に対して、ある特徴量の値を順に変化させていき、そのときのモデルの出力の平均値をみる方法でした。<br>
一方で、ICEはモデルの出力の平均値を取らず、データごとに変化をみます。そのため、PDPだと一本の曲線がプロットできますが、ICEではデータの数だけ曲線がプロットできます。</p>
<h1 id="individual-conditional-expectationはの実験">Individual Conditional Expectationはの実験</h1>
<p>kaggleのtitanicの問題でIndividual Conditional Expectationを試してみます。
モデルはLightGBMの勾配ブースティング法を利用しています。</p>
<h2 id="年齢に対するindividual-conditional-expectation">年齢に対するIndividual Conditional Expectation</h2>
<p>年齢を$0,5,10,\cdots,65$と変化させてみた結果が以下のとおりです。縦軸はタイタニックに乗った乗客の生存確率の予測値です。1つ1つの曲線が1つの乗客に対応します。<br>
<img src="/mblog/posts/individual-conditional-expectation/ice_age.png" alt="年齢に対するIndividual Conditional Expectation"><br>
これを見ると、傾向として年齢が大人になるくらいまでは、年齢とともに生存確率が下がっていきます。これは直感に合った結果です。
変わったところでいくと、生存確率が年齢の変化とともに変わらない人がいます。<br>
生存確率が0.7以上であり続けた人のデータを軽く確認したところ、性別は全員女性でした。PDPのときもそうでしたが、女性の生存確率が高いモデルになっているのがここからもわかります。</p>
<p>また、ICEでは左端の値をすべてのデータで揃えることで見やすくすることがあります。<br>
各データごとに、0歳のときの予測値でそれぞれの予測値を引いてみた結果が以下のとおりです。
<img src="/mblog/posts/individual-conditional-expectation/ice_age_centered.png" alt="年齢に対するIndividual Conditional Expectation"><br>
データの変化の比較がしやすくなりましたね。</p>
<h2 id="実装">実装</h2>
<p>実装は次のとおりです。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">individual_conditional_expectation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                       <span class="n">x</span><span class="p">:</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                       <span class="n">target</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                       <span class="n">candidates</span><span class="p">:</span><span class="n">List</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">replaced_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">ice_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">replaced_val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">candidates</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">replaced_x</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">replaced_val</span>
</span></span><span class="line"><span class="cl">        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">replaced_x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">ice_vals</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ice_vals</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">candidates</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">target</span> <span class="o">=</span> <span class="s2">&#34;Age&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">ice</span> <span class="o">=</span> <span class="n">individual_conditional_expectation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                         <span class="n">train_x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">candidates</span><span class="o">=</span><span class="n">candidates</span><span class="p">)</span>
</span></span></code></pre></div><h1 id="まとめ">まとめ</h1>
<p>PDPのようにICEも実装が簡単で、わかりやすい結果が得られます。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/individual-conditional-expectation/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/partial-dependence-plot/">Partial Dependence Plot</a>
        </h1>
        <div class="post-meta"><time class="post-date">2021-10-14</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/partial-dependence-plot/">Partial Dependence Plot</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%AA%AC%E6%98%8E%E5%8F%AF%E8%83%BDai/">説明可能AI</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/partial-dependence-plot/ppd_sex.png"
    class="post-cover"
    alt="Partial Dependence Plot"
    title="Cover Image" />


        <div class="post-content">
          
            <p>Partial Dependence Plotは任意のモデルのある特徴量に対するglobalな挙動を確認できる手法です。<br>
例えば、特徴量が大きくなるにつれ、モデルの出力がどういった変化をするかがわかります。</p>
<h1 id="partial-dependence-plotの概要">Partial Dependence Plotの概要</h1>
<p>学習済みのモデル$f$へ入力する特徴量$x$のうち、$i$番目の特徴量の変化に対する$f$の出力の挙動の変化を確認したいとします。<br>
このとき、次のようにモデルの出力の期待値を計算します。
$$ E_{X_C}[f(x_i, X_C)] = \int p(X_C) f(x_i, X_C) dX_C .$$
ここで$X_C$は$x_i$以外の特徴量になっていまして、$x_i$の値だけを固定し、それ以外の特徴量について積分をしています。<br>
こうすることで、$x_i$の値により、おおよそどれくらいの出力の差が出るのかがわかります。</p>
<p>注意点として、$x_i$と$X_C$は独立でなければいけません。<br>
独立でないときには$x_i$は$X_C$の関数としてあらわされるため、期待値の計算において$X_C$の変化にともない、$x_i$が変化することになります。こうなると、$x_i$が固定という前提と一致しなくなります。</p>
<h1 id="partial-dependence-plotの実験">Partial Dependence Plotの実験</h1>
<p>kaggleのtitanicの問題でPartial Dependence Plotを試してみます。
モデルはLightGBMの勾配ブースティング法を利用しています。</p>
<p>期待値の計算は訓練データの特徴量$X_{C_{j}},j=1,2,\cdots,n$を用いて以下のように近似値を利用しています。
$$ E_{X_C}[f(x_i, X_C)] = \int p(X_C) f(x_i, X_C) dX_C \approx \frac{1}{n} \sum_{j=1}^n f(x_i,X_{jC}) .$$</p>
<h2 id="年齢に対するpartial-dependence-plot">年齢に対するPartial Dependence Plot</h2>
<p>年齢を$0,5,10,\cdots,65$と変化させてみた結果が以下のとおりです。<br>
<img src="/mblog/posts/partial-dependence-plot/ppd_age.png" alt="年齢に対するPartial Dependence Plot"><br>
年齢が低いほうが、生存しやすかった傾向が読み取れます。また35歳にピークがありますので、なにか理由がありそうです。例えば、年齢があがるほど客室のクラスが良くなりやすいのかもしれません（そうだとすると年齢と客室のクラスは独立ではないのかという話になりますので、実際にはここの考察が必要になりそうです）。</p>
<h2 id="性別に対するpartial-dependence-plot">性別に対するPartial Dependence Plot</h2>
<p>性別についても結果を示します。<br>
<img src="/mblog/posts/partial-dependence-plot/ppd_sex.png" alt="性別に対するPPD"><br>
女性のほうが生存しやすかったという傾向が見て取れます。</p>
<h2 id="実装">実装</h2>
<p>実装は次のとおりです。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_partial_dependence_func_val</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                    <span class="n">x</span><span class="p">:</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">target</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">candidates</span><span class="p">:</span><span class="n">List</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">expecteds</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="n">replaced_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">replaced_val</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">replaced_x</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">replaced_val</span>
</span></span><span class="line"><span class="cl">        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">replaced_x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">expecteds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">expecteds</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">candidates</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">target</span> <span class="o">=</span> <span class="s2">&#34;Age&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">ppd</span> <span class="o">=</span> <span class="n">get_partial_dependence_func_val</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                      <span class="n">train_x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                      <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                      <span class="n">candidates</span><span class="o">=</span><span class="n">candidates</span><span class="p">)</span>
</span></span></code></pre></div><h1 id="まとめ">まとめ</h1>
<p>Partial Dependence Plotは実装が簡単で、わかりやすい結果が得られます。<br>
ただし、特徴量間が独立でないときは仮定が崩れますので、注意が必要です。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/partial-dependence-plot/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/kl-divergence%E3%81%AB%E4%B8%8E%E3%81%88%E3%82%8B%E5%88%86%E5%B8%83%E3%82%92%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E6%84%8F%E5%91%B3%E3%82%92%E3%81%BE%E3%81%98%E3%82%81%E3%81%AB%E8%80%83%E3%81%88%E3%81%9F%E3%81%93%E3%81%A8%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99/">KL divergenceに与える分布を入れ替えることの意味をまじめに考えたことあります？</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-03-02</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/python/">Python</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/kldivergence/">KLdivergence</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/pytorch/">PyTorch</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%AD%A3%E8%A6%8F%E5%88%86%E5%B8%83/">正規分布</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/kl-divergence%E3%81%AB%E4%B8%8E%E3%81%88%E3%82%8B%E5%88%86%E5%B8%83%E3%82%92%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E6%84%8F%E5%91%B3%E3%82%92%E3%81%BE%E3%81%98%E3%82%81%E3%81%AB%E8%80%83%E3%81%88%E3%81%9F%E3%81%93%E3%81%A8%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99/983be7a190c4aaf3488cd6c3d4471158.png"
    class="post-cover"
    alt="KL divergenceに与える分布を入れ替えることの意味をまじめに考えたことあります？"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>みんながよく使うKL(Kullback–Leibler) divergenceの話題です。
KL divergenceといえば2つの確率分布の違いを計算できるやつですね。
KL divergenceは対称性というものがなく、与えられた2つの分布を入れ替えるとKL divergenceの値が変わります。
今回は、この入れ替えたときの影響を最小化問題を例としてまじめに考えます。</p>
<h1 id="kl-divergence">KL divergence</h1>
<p>KL divergenceは2つの確率分布がどれだけ異なるかを数値としてあらわすものです。
具体的には次のように定義されます。
$$ KL(p||q) = \int p(\mathbf{x}) \log \left(\frac{p(\mathbf{x})}{q(\mathbf{x})}\right) {\rm d\mathbf{x}}. $$
$p$と$q$はそれぞれ確率分布であり、$KL(p||q)$が大きいほど、2つの分布はより異なることをあらわします。また$KL(p||q)=0$のとき、$p$と$q$は等しい分布です。
なお、$KL(p||q) \geq 0$が成り立つことに注意してください。</p>
<h1 id="kl-divergenceの最小化問題">KL divergenceの最小化問題</h1>
<h2 id="klpqのケース">KL(p||q)のケース</h2>
<p>仮に分布$p$が固定されているものだとして、$KL(p||q)$が最小化されるように$q$を決めることを考えます。ただし、$p=q$になることはないとします。</p>
<p>前述したKL divergenceの定義をみてみると、$p(\mathbf{x})$が0でない値をもつ領域では$q(\mathbf{x})$も$p(\mathbf{x})$に近い値かあるいは$p(\mathbf{x})$より大きい値にならなければ、$KL(p||q)$が大きくなってしまいます。よってこの場合にはKL divergenceを最小化するような**$q$は$p$全体をカバーするように広がる分布**になると考えられます。</p>
<h2 id="klqpのケース">KL(q||p)のケース</h2>
<p>次にKL divergenceに与える$p$と$q$の順序をひっくり返し、$KL(q||p)$の最小化問題を考えてみます。$KL(q||p)$は
$$ KL(q||p) = \int q(\mathbf{x}) \log \left(\frac{q(\mathbf{x})}{p(\mathbf{x})}\right) {\rm d\mathbf{x}}$$
ですね。
$KL(q||p)$が小さくなるにはどうすればよいかといえば、$p(\mathbf{x})$が0に近いような領域で$q(\mathbf{x})$が小さくなるようにすればよいです。$p(\mathbf{x})$が小さい領域はいくらでもあり、そういったところに大きい$q(\mathbf{x})$が割り当てられると、$KL(q||p)$が大きくなってしまいますね。このため、イメージとしては、$KL(q||p)$を最小化するような**$q$の密度は$p$の密度が大きいところに集中するような分布**になると考えられます。</p>
<h1 id="実験">実験</h1>
<p>上記の話が成り立つのかを実験してみます。</p>
<h2 id="実験準備">実験準備</h2>
<p>$p(\mathbf{x})$は次のようにします。</p>
<p>$$p(\mathbf{x}|\mathbf{u},\Sigma)=\frac{1}{{2\pi}|\Sigma|^{1/2}}\exp\biggl[-\frac{(\mathbf{x}-\mathbf{u})^{\top}\Sigma^{-1}(\mathbf{x}-\mathbf{u})}{2}\biggr].$$
また$\mathbf{u}$と$\Sigma$はそれぞれ
$$\mathbf{u} = \begin{pmatrix} 0.3 \\ -0.2 \end{pmatrix}, \Sigma =\begin{pmatrix} 0.9&amp;-0.7 \\ -0.7 &amp; 0.9 \end{pmatrix}$$
とました。
$p$を確率密度毎に色わけして表示してみると、以下のとおりです。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/kl-divergence%E3%81%AB%E4%B8%8E%E3%81%88%E3%82%8B%E5%88%86%E5%B8%83%E3%82%92%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E6%84%8F%E5%91%B3%E3%82%92%E3%81%BE%E3%81%98%E3%82%81%E3%81%AB%E8%80%83%E3%81%88%E3%81%9F%E3%81%93%E3%81%A8%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/">モデルの予測結果を説明するLIMEの理論</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-02-12</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/lime/">LIME</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E9%87%8D%E8%A6%81%E5%BA%A6/">重要度</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%AF%84%E4%B8%8E/">寄与</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/1341b73a17da593ffc43cebc86969604.jpg"
    class="post-cover"
    alt="モデルの予測結果を説明するLIMEの理論"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>モデルの予測結果を説明する方法として<strong>LIME</strong>があります。
LIMEはディープラーニングに限らず、任意のモデルに対して予測結果を適用することができます。
また手法としては結構有名かと思います。</p>
<p>今回はそんなLIMEの理論について説明します。</p>
<p>論文：<a href="https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf">“Why Should I Trust You?” Explaining the Predictions of Any Classifie</a></p>
<h1 id="limeの戦略">LIMEの戦略</h1>
<p>任意のモデル$f$に入力$x \in \mathbb{R}^d$が与えられたときの予測結果$f(x)$への特徴量の寄与を求めることを考えます。</p>
<p>LIMEでは$x$近傍（近傍については後述）に対しては$f$と同じような予測をすることができる、かつ解釈が容易なモデル$g$を求めます。
例えば$g$が線形モデルの場合には、$g$の各係数を見ることで特徴量の寄与を得ることが可能です。あるいは$g$が決定木であれば、人間でもある程度容易にモデルの解釈が可能です。ですから、このようなモデル$g$を$f$の代わりに使って、予測結果の解釈をしようというモチベーションです。
ただし、LIMEでは$g$には特徴量の値が$0$か$1$となるベクトル$x&rsquo;$が入力として与えられるものとします。これは何らかのルールで$x$の要素と$x&rsquo;$の要素が対応づいているとします。ここも詳細をあとで述べます。
以上のように、解釈が難しいモデル$f$を解釈が容易なモデル$g$に落とし込むことがLIMEのやりたいことになります。</p>
<p>実際にどうやって$g$を求めるのかといえば、次式のようになります。
$${\rm argmin_{g \in G}} \ L(f, g, \pi_x) + \Omega(g).$$</p>
<p>ここで、</p>
<ul>
<li>$L$は損失関数です。$x$近傍で$g$の予測値が$f$の予測値に近いと、小さくなるように$L$を定義します。</li>
<li>$\pi_x$は損失関数で使われる重みで、$x$の近傍点が$x$から遠いほど小さい値を取るようにします。詳細は後述する線形モデルの項を参照。</li>
<li>$\Omega$はモデルの複雑さとなります。決定木を使う場合には木の深さであったり、線形モデルの場合には非ゼロの重みの数になります。モデルを解釈するためには、モデルはシンプルな方が良いため、$\Omega$を加えることで$g$をなるべく人間にやさしいモデルにしてあげます。</li>
</ul>
<p>まだ色々と詳細を述べていないため、わからないところは多々あると思いますが、上式は<strong>なるべくシンプルなモデルで$x$の近傍で$f$と近似する$g$を見つける</strong>といったことを意味します。
この局所的に近似された$g$が得られれば、$x$近傍での特徴量が$g$へ与える寄与がわかる、つまり$f$へ与える寄与が近似的にはわかります。</p>
<p>次に画像の場合のケースについて、詳細に踏み込みます。</p>
<h1 id="画像に対する線形モデルでのlime">画像に対する線形モデルでのLIME</h1>
<h2 id="superpixel">superpixel</h2>
<p>画像にLIMEを適用する場合、まず次のように入力画像をsuperpixelに分割し、領域ごとに寄与を求めていきます。</p>
<blockquote>
<p><img src="/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/1341b73a17da593ffc43cebc86969604.jpg" alt="">
引用元：https://towardsdatascience.com/understanding-how-lime-explains-predictions-d404e5d1829c</p></blockquote>
<p>実際には上記のようにある程度細かく領域を分けますが、以下では例として扱いやすいように次のような画像を考えて、粗く領域を分けていきます（左がオリジナルのくまモンで、右がsuperpixelに分割されたくまモンです）。</p>
<p><img src="/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/ad1fa258f844d5a4ad33e45d75dcf7da.png" alt=""><img src="/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/cc5a03cf0c2b50e3217a99edddcc002b.jpg" alt=""></p>
<p>各領域を$g$に与える入力$x&rsquo;$の各要素に対応させます。例えば1番の領域が$x&rsquo;$の1番目の要素、2番が2番目の要素のようにします。その上で、$x&rsquo;$の各要素が1のときには対応する領域のピクセルが$x$と同じピクセル値、0のときにはその領域がグレーで埋められた画像と対応していると考えます。
具体的には
$$x&rsquo; = [0, 0, 1, 1, 0,0,0,0]$$
としたとき、3番目と4番目だけが1ですので、この$x&rsquo;$に対応した画像は次のようになります。</p>
<p><img src="/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/158a3d802d662d2e95988553c4d83e5d.jpg" alt=""></p>
<h2 id="近傍のサンプリング">近傍のサンプリング</h2>
<p>LIMEでは $x$の近傍のサンプリングをおこないます。
画像の場合に近傍とはどうなるんでしょうか？直感的には謎じゃないでしょうか。</p>
<p>LIMEの場合には分割された領域のうち、適当な個数（個数もランダムに決めますが、個数の下限は決めておきます）をそのままにし、それ以外をグレーに置き換える処理をします。
$x&rsquo;$の話でいえば、適当な個数の要素については1とし、それ以外は0とする処理に等しいです。</p>
<p>このようにして得られた画像を$x$の近傍として扱います。またこのようにして近傍を得ることを、近傍のサンプリングとします。
先程示した$x&rsquo;$に対応した画像も$x$の近傍になります。</p>
<h2 id="線形モデルのケース">線形モデルのケース</h2>
<p>$g$が線形モデルの場合には$g(z&rsquo;)$は次のようになります。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E4%BA%88%E6%B8%AC%E7%B5%90%E6%9E%9C%E3%82%92%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8Blime%E3%81%AE%E7%90%86%E8%AB%96/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/uber%E8%A3%BD%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E3%83%84%E3%83%BC%E3%83%ABmanifold/">Uber製の機械学習モデルのデバッグツールManifold</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-01-28</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/manifold/">manifold</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E7%89%B9%E5%BE%B4%E9%87%8F/">特徴量</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/python/">Python</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/uber%E8%A3%BD%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E3%83%84%E3%83%BC%E3%83%ABmanifold/2f11d99ea2c3cf569c040d9555f5ab2c.png"
    class="post-cover"
    alt="Uber製の機械学習モデルのデバッグツールManifold"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>Uberが公開している機械学習モデルの予測と特徴量の関係性を可視化するツールである<a href="https://github.com/uber/manifold#upload-csv-to-demo-app">Manifold</a>を紹介します。</p>
<h1 id="manifoldを試す">Manifoldを試す</h1>
<p>Manifoldでできることを見ていきます。</p>
<h2 id="インストール">インストール</h2>
<p>レポジトリをgit cloneしてから、githubのページにあるように以下のようにしてインストールできました。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># under the root directory, install all dependencies</span>
</span></span><span class="line"><span class="cl">yarn
</span></span><span class="line"><span class="cl"><span class="c1"># demo app is in examples/manifold directory</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> examples/manifold
</span></span><span class="line"><span class="cl"><span class="c1"># instal demo app dependencies</span>
</span></span><span class="line"><span class="cl">yarn
</span></span><span class="line"><span class="cl"><span class="c1"># start the app</span>
</span></span><span class="line"><span class="cl">npm run start
</span></span></code></pre></div><h2 id="準備">準備</h2>
<p>まずユーザーは次の3つのデータを用意します。</p>
<ol>
<li>入力データの特徴量を記述したcsv</li>
<li>入力データに対するラベル</li>
<li>入力データに対するモデルの予測値（分類問題の場合には各クラスに属する確率になります）</li>
</ol>
<p>モデルはなんでも良く、必要なのは予測値であることに注意してください。</p>
<p>今回はkaggleのタイタニックのデータから適当にテストデータを作ってみました。
テストデータとlightgbmのモデルを用いて、次のような感じでManifoldに必要なデータを作ってます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;./titanic_res/features.csv&#34;</span><span class="p">,</span> <span class="s2">&#34;w&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">columns</span> <span class="o">=</span> <span class="s2">&#34;,&#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span> <span class="c1"># X_testがテストデータの特徴量</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">X_test</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>　
</span></span><span class="line"><span class="cl">        <span class="n">f_string</span> <span class="o">=</span> <span class="s2">&#34;,&#34;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">features</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">f_string</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;./titanic_res/pred.csv&#34;</span><span class="p">,</span> <span class="s2">&#34;w&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">pred</span> <span class="o">=</span> <span class="n">bst</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># bstがlightgbmのモデル</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&#34;survived,death</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">prob</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="mi">1</span><span class="o">-</span><span class="n">prob</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>        
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;./titanic_res/truth.csv&#34;</span><span class="p">,</span> <span class="s2">&#34;w&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&#34;truth</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">truth</span> <span class="ow">in</span> <span class="n">y_test</span><span class="p">:</span> <span class="c1"># y_testがテストデータのラベル</span>
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="s2">&#34;survived&#34;</span> <span class="k">if</span> <span class="n">truth</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&#34;death&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="manifoldでの可視化">Manifoldでの可視化</h2>
<h3 id="アップロード">アップロード</h3>
<p>npm run startを実行すると、ブラウザ上でアプリが立ち上がります。
立ち上げ直後はファイルのアップロードを促されるので、準備したファイルをドラッグアンドドロップしてアップロードします。
<img src="/mblog/posts/uber%E8%A3%BD%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E3%83%84%E3%83%BC%E3%83%ABmanifold/1031826c887d80ad190bb59649cdbb48.png" alt=""></p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/uber%E8%A3%BD%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E3%83%84%E3%83%BC%E3%83%ABmanifold/">[Read more]</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
    
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/mblog/bundle.min.js"></script>





  
</div>

</body>
</html>
