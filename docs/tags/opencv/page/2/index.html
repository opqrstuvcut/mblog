<!DOCTYPE html>
<html lang="ja">
<head><script src="/mblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=mblog/livereload" data-no-instant defer></script>
  
    <title>OpenCV :: MatLoverによるMatlab以外のブログ</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/mblog/tags/opencv/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LFC5W8DKV1"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-LFC5W8DKV1');
        }
      </script>



  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terminal.min.77ee67c1d456ac0c280223661a10b75c7729c59aeb33001424a72a14b363e310.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/mblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/mblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="ja" />
<meta property="og:type" content="website" />
<meta property="og:title" content="OpenCV">
<meta property="og:description" content="" />
<meta property="og:url" content="http://localhost:1313/mblog/tags/opencv/" />
<meta property="og:site_name" content="MatLoverによるMatlab以外のブログ" />

  <meta property="og:image" content="http://localhost:1313/mblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/mblog/tags/opencv/index.xml" rel="alternate" type="application/rss+xml" title="MatLoverによるMatlab以外のブログ" />







<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous">

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
            ],
            throwOnError : false
        });
    });
</script>


<style>
  section.article-content h2 {
    background-color: rgb(245, 245, 245);
    padding: 10px;
  }

  :root {
    --ja-font-family: "メイリオ", "Meiryo";
    --base-font-family: "Lato", var(--sys-font-family), var(--ja-font-family),
      sans-serif;
    --body-background: #ffffe0;
  }


</style>


</head>
<body>


<div class="container full">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://localhost:1313/mblog/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/mblog/">Home</a></li>
        
      
        
          <li><a href="/mblog/archives/">Archives</a></li>
        
      
        
          <li><a href="/mblog/search/">Search</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/mblog/" >Home</a></li>
        
      
        
          <li><a href="/mblog/archives/" >Archives</a></li>
        
      
        
          <li><a href="/mblog/search/" >Search</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  <h1>Posts for: #OpenCV</h1>
  
  <div class="posts">
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/">画像の距離変換をおこなう</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-07</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B/">距離変換</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/10fec2481837301639f81cf34c21e4b1.png"
    class="post-cover"
    alt="画像の距離変換をおこなう"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>画像に対する距離変換とは、グレースケールの画像において、ピクセルから最も近い0の値をもつピクセルまでの距離を求めたものです。</p>
<p>早速OpenCVで試してみます。</p>
<h1 id="opencvで距離変換">OpenCVで距離変換</h1>
<p>次のようにして距離変換をおこなえます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">dist</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">distanceTransform</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">distanceType</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DIST_L2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">maskSize</span><span class="o">=</span><span class="mi">5</span>
</span></span><span class="line"><span class="cl">                            <span class="p">)</span>
</span></span></code></pre></div><p>distanceTypeに距離の計算方法を指定します。DIST_L2はユークリッド距離です。
maskSizeには最も近い0の値をもつピクセルまでの距離の近似値を計算するときに使うmaskの大きさを指定します。maskSize=5の例でいえば、maskをあらわす$5\times5$の行列の各要素にはmaskの中心からの距離が格納されています。このmaskを使うことで、正確に距離を計算するよりも速く距離（の近似値）が計算できます。</p>
<p>結果は以下のとおりです。</p>
<table>
  <thead>
      <tr>
          <th>入力画像</th>
          <th>距離変換適用（明るいほど距離大）</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/0b07b8f2f4af88f042743b022481f2b5.png" alt=""></td>
          <td><img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/10fec2481837301639f81cf34c21e4b1.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>背景が0の値をもつので、そこまでの距離が反映されています。窓の中心や、猫の顔の中心は背景から遠いので、大きな値をもっています。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/">floodFillで領域に色を塗る</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-06</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/floodfill/">floodFill</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/b7d4e85930d3ec37e0350ab3fe75e877.png"
    class="post-cover"
    alt="floodFillで領域に色を塗る"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>OpenCVのfloodFillを使うことで、選んだ点の周辺の似たような色のピクセルを塗りつぶすことができます。</p>
<h1 id="使い方">使い方</h1>
<p>次のようにしてfloodFillを利用できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">floodFill</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">seedPoint</span><span class="o">=</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">700</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">newVal</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">loDiff</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">upDiff</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</span></span></code></pre></div><p>まずmaskですが、入力画像の$(x,y)$がmaskの$(x+1, y+1)$に対応し、maskの値が0でないところは塗りつぶされません。入力画像に比べて縦横が2ピクセルずつ大きいので、元の画像の周辺に1ピクセルずつpaddingができたようなイメージですね。
seedPointに指定した座標が塗りつぶしの処理の起点になります。
newValに塗りつぶす色を指定します。
seedPointに指定したピクセルの値からloDiffを引いた値とseedPointに指定したピクセルの値にupDiffを加えた値の間に入っているピクセルをseedPointの隣から順に塗りつぶしていきます。</p>
<p>結果は以下のとおりです。</p>
<table>
  <thead>
      <tr>
          <th>入力画像</th>
          <th>floodFillの結果</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/b944ecdbe70bf25c0767c5274622e44a.png" alt=""></td>
          <td><img src="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/b7d4e85930d3ec37e0350ab3fe75e877.png" alt=""></td>
      </tr>
  </tbody>
</table>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/">Hough変換で円を検出</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-05</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/hough%E5%A4%89%E6%8F%9B/">Hough変換</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%86%86%E6%A4%9C%E5%87%BA/">円検出</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/51aa777f4487689837d45257fa1eba91.png"
    class="post-cover"
    alt="Hough変換で円を検出"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>Hough変換は直線を検出する方法として前回紹介したのですが、Hough変換を応用することで、円の検出も行えます。</p>
<h1 id="opencvで円の検出">OpenCVで円の検出</h1>
<p>次の画像から円を検出してみます。<br>
<img src="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/e976800df4c7c67950f6c87dadab89b3.png" alt=""></p>
<p>円の検出は以下のようにおこないます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">hough_circle</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HoughCircles</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">HOUGH_GRADIENT</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                <span class="n">dp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">minDist</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">param1</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">param2</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</span></span></code></pre></div><p>HoughLinesと異なり、画像はグレースケールの状態で渡せば、なかでエッジ検出をおこなってくれます。<br>
methodには手法を指定しますが、HOUGH_GRADIENTしかないようです。<br>
dpには分解能を指定しています。1にすると画像の解像度と同じ分解能をもちます。<br>
minDistには円同士の最小の距離を指定します。これより近いと2つの円として認識されません。<br>
param1はCanny法のしきい値の上限、param2は円上にあると判定されたエッジの点の数に対するしきい値です。</p>
<p>結果は以下のとおりです。<br>
<img src="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/51aa777f4487689837d45257fa1eba91.png" alt=""><br>
大まかには円が検出できていることがわかります。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/">Hough（ハフ）変換で直線を見つけよう</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-04</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/hough%E5%A4%89%E6%8F%9B/">Hough変換</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/f57bd9c6dc056b82e658a2f6ca7b6258.png"
    class="post-cover"
    alt="Hough（ハフ）変換で直線を見つけよう"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>Hough変換は画像から直線をみつける方法です。</p>
<h1 id="簡単な原理">簡単な原理</h1>
<p>入力として2値画像を考えます。
Hough変換では候補となる直線を用意し、直線上にいくつ0でないピクセルがあるかを数えます。
このピクセルの個数が指定したしきい値以上であった場合、その候補の直線は正しい直線として扱います。</p>
<p>なお、OpenCVでは直線の候補は以下のように$(\rho, \theta)$による極座標系であらわされています。
$$ \rho = x \cos \theta + y \sin \theta .$$
$\rho$は原点からの直線の距離、$\theta$は直線の角度をあらわします。</p>
<p>$\theta$が0でないとしたとき、上式をちょっと変形することで見慣れた形の方程式になるかと思います。
$$ y = \frac{\rho}{\sin\theta} - x \frac{\cos \theta}{\sin \theta}. $$</p>
<p>わざわざ極座標系であらわす理由はなにかというと、$y=ax+b$ような直線に対してy軸に平行な直線を考えるときに、傾きが$\infty$の直線となり扱いづらくなることを防ぐためです。
極座標系ですと、無理なくy軸に平行な直線を扱うことができます。</p>
<h1 id="opencvで試してみる">OpenCVで試してみる</h1>
<p>次の画像に対してHough変換を適用します。<br>
<img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/fc6611dea1559319bc4baebf641d0a6a.png" alt=""><br>
Hough変換にかける前に、Canny法でエッジを抽出しておきます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">threshold1</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">threshold2</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="n">apertureSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">L2gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/ee45891c46a4955315b6ce6e817e2d07.png" alt=""><br>
Canny法の結果に対して、次のようにHough変換を適用できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">hough_lines</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HoughLines</span><span class="p">(</span><span class="n">canny</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                             <span class="n">threshold</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</span></span></code></pre></div><p>rhoとthetaはそれぞれの軸方向の直線の候補の分解能になります。小さいほどたくさんの直線が見つかるかと思います。thresholdに直線の候補を採用するかを決めるしきい値を指定します。
また、min_thetaとmax_thetaで見つかる直線のthetaの最小値、最大値を決めることもできます。</p>
<p>検出された直線のパラメータ$(\rho, \theta)$は以下のようにして変換して、画像に直線として書き込んでいます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">t</span> <span class="o">=</span> <span class="mi">3000</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">hough_lines</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">rho</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x0</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">rho</span>
</span></span><span class="line"><span class="cl">    <span class="n">y0</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">rho</span>
</span></span><span class="line"><span class="cl">    <span class="n">x1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x0</span> <span class="o">-</span> <span class="n">t</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># 媒介変数表示</span>
</span></span><span class="line"><span class="cl">    <span class="n">y1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">y2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y0</span> <span class="o">-</span> <span class="n">t</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span>
</span></span></code></pre></div><p>結果は以下のとおりです。<br>
<img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/f57bd9c6dc056b82e658a2f6ca7b6258.png" alt=""><br>
カーテンや窓、猫の底の部分が直線として検出されています。余計な直線も結構検出されています。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/">Canny法でエッジ検出</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-03</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/canny/">Canny</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/5154e105157ba91bf3bf7306d1cfffe1.jpg"
    class="post-cover"
    alt="Canny法でエッジ検出"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>エッジ検出の方法として、Canny法というものがあります。
SobelフィルタやLaplacianフィルタもエッジ検出ができるわけですが、Canny法を使うとより正確に輪郭を検出することが可能です。</p>
<h1 id="canny法の簡単な原理">Canny法の簡単な原理</h1>
<h2 id="勾配の計算">勾配の計算</h2>
<p>Canny法では画像を平滑化したあとに、Sobelフィルタによって勾配を計算します。
OpenCVでは勾配の大きさは以下の2つのうちのどちらかで計算がなされます。$G_x$と$G_y$はそれぞれ$x$方向、$y$方向の勾配です。</p>
<ol>
<li>2ノルムの場合
$$ \rm{grad}=\sqrt{G_x^2 + G_y^2}. $$</li>
<li>1ノルムの場合
$$ \rm{grad}= |G_x| + |G_y|. $$</li>
</ol>
<p>2ノルムのほうが正確ですが、計算量では1ノルムのほうが優れています。</p>
<h2 id="極大値を求める">極大値を求める</h2>
<p>次に、計算された勾配から、勾配の極大値を求めます。こうすることで、余計な箇所がエッジとして検出されるのを防ぎます。</p>
<h2 id="しきい値処理">しきい値処理</h2>
<p>最後に、しきい値処理でエッジとして扱うかどうかを決めます。
Canny法のしきい値は2つあり、1つはこの値より大きければエッジとすると決めるためのもの、もう1つはこの値よりも小さければエッジではないと決めるためのものです。
じゃあ2つのしきい値の間はどうなるの？という話ですが、隣接しているピクセルがエッジと判定されていれば、エッジと判定するようにし、そうでなければエッジではないと判定します。
単純なしきい値でのエッジの判定よりも、より柔軟ですね。</p>
<p>ただし、しきい値が非常に重要になることが容易に想像できます。</p>
<h1 id="opencvでcanny法をためす">OpenCVでCanny法をためす</h1>
<p>Canny法は以下のようにして実行できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="n">threshold1</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="n">threshold2</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="n">apertureSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="n">L2gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p>threshold1がしきい値の小さい方で、threshold2がしきい値の大きい方です。apertureSizeにSobelフィルタのサイズを指定しています。また勾配の大きさに2ノルムを使う場合にはL2gradientをTrueにします。</p>
<p>結果を以下に示します。</p>
<table>
  <thead>
      <tr>
          <th>元画像</th>
          <th>canny（2ノルム）</th>
          <th>canny（1ノルム）</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/8defd1c89359b1b8b5f6142e6e0105bf.jpg" alt=""></td>
          <td><img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/a0d7c2f605896b780afcc1f54a4acaad.jpg" alt=""></td>
          <td><img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/5154e105157ba91bf3bf7306d1cfffe1.jpg" alt=""></td>
      </tr>
  </tbody>
</table>
<p>2ノルムのほうがきれいにエッジが取れている気がします。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/">ヒストグラム平坦化</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-02</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/">ヒストグラム平坦化</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/e534d7e8e9969a0405e4a1b8f7eea112.png"
    class="post-cover"
    alt="ヒストグラム平坦化"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>今日はヒストグラム平坦化を扱います。</p>
<p>ヒストグラム平坦化はコントラストが偏っているような画像を補正します。
結果として、コントラストがある程度平坦化された結果が得られます。</p>
<p>処理の中身としては、実際には画像のピクセル値の累積分布関数で写像したうえで、最大値と最小値が広がるように調整してあげるというイメージです。</p>
<h1 id="opencvでヒストグラム平坦化">OpenCVでヒストグラム平坦化</h1>
<p>次の画像にヒストグラム平坦化を適用してみます。このままだと全くみえません。<br>
<img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/51cf7f08ccc657141d3e65ef1b466e4e.png" alt=""></p>
<p>この画像の画素値のヒストグラムは以下のとおりです。だいぶ偏ってますね。<br>
<img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/de36036169c411bbe353ffdf628df858.png" alt=""></p>
<p>ヒストグラム平坦化は次のようにしておこなえます。めちゃくちゃ簡単です。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">equalizeHist</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/e534d7e8e9969a0405e4a1b8f7eea112.png" alt=""><br>
ちゃんと見えるようになりましたね。</p>
<p>この画像の画素値のヒストグラムは以下のとおりです。<br>
<img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/e250638d16771a11e5bf8cc073ff4caf.png" alt=""></p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/">Non-Local Means Denoisingでノイズ除去</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-08-01</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/fnlmd/">FNLMD</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/">ノイズ除去</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/783215bfb0d1c75f10337b84d03a1a34.png"
    class="post-cover"
    alt="Non-Local Means Denoisingでノイズ除去"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<h1 id="non-local-means-denoisingのアイデア">Non-Local Means Denoisingのアイデア</h1>
<p>今回はノイズ除去を扱うのですが、特にガウスノイズを考えます。
これは平均が0となるノイズですので、着目しているピクセルにある意味で<strong>似ている</strong>ピクセルを画像中から探してきて、それらの平均を取れば、ノイズの影響が消えたピクセルが得られるはずです。
これがNon-Local Means Denoisingのアイデアになります。</p>
<h1 id="似ているピクセルをどう定義するか">似ているピクセルをどう定義するか</h1>
<p>Non-Local Means Denoisingでは着目しているピクセルの値自体ではなく、着目しているピクセルの<strong>周辺の値</strong>同士の差分を取ることで、似ているかどうかを考えます。
この考えから定義されるピクセル$p$と$q$間の距離は以下のようになります。
$$ d^2(B(p, f), B(q,f)) = \frac{1}{3(2f + 1)^2} \sum_{c=1}^3 \sum_{j \in B(0, f)} (I_c(p+j) - I_c(q+j))^2. $$
ここで$B(p,f)$は着目しているピクセル$p$のサイズの周辺のピクセルで、サイズが$(2f + 1) \times (2f + 1)$となっています。$I_c(p+j)$が周辺ピクセルの$c$番目のchannelの値をあらわします。</p>
<h1 id="平均値の取り方">平均値の取り方</h1>
<p>先程定義した距離を使って以下のような重みを計算します。
$$ w(p,q) = e^{-\max(d^2 - 2\sigma^2, 0) / h^2}. $$
$\sigma^2$はノイズの分散になります（OpenCVの関数で実行するときには特にこれを指定しないので、上手く処理されている？）。$h$は与えるパラメーターで、大きいほど$w$の値に差がつきづらくなります。
距離$d^2$が小さいと$w$が1に近い値を取り、$d^2$が大きいほど$w$は小さい値になります。
この$w$を重みとしたピクセル値の重み付き平均を取ることがNon-Local Means Denoisingでの処理になります。</p>
<p>この重み付き平均をとることで、似ているピクセルは強く考慮されますが、似ていないピクセルはほとんど影響を与えないため、似ているピクセルだけでの平均が取れるような計算処理になっています。</p>
<p>なお、すべてのピクセル同士で距離$d^2$を計算すると、当然計算量が大変なことになります。
このため、実際には着目しているピクセルの周辺のどこまでを考慮するかを指定します。</p>
<h1 id="opencvでやってみる">OpenCVでやってみる</h1>
<p>OpenCVでNon-Local Means Denoisingをやってみます。</p>
<p>次の左の画像にノイズをのせて右の画像を生成しました。<br>
<img src="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/c9b2cd84393504aa9ce6c0f9929fe958.png" alt=""><img src="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/74a87a7adb65b77787e724d2e7e407e5.png" alt=""></p>
<p>これに対して次のようにして、Non-Local Means Denoisingを適用します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">denoised</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">fastNlMeansDenoisingColored</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                           <span class="n">h</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                           <span class="n">templateWindowSize</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                           <span class="n">searchWindowSize</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>
</span></span></code></pre></div><p>hはさきほどの重みで出てきた$h$と同じで、templateWindowSizeは$d^2$の計算で使われる$f$と同じで、searchWindowSizeは着目しているピクセルの周辺をどこまで考慮するかをあらわします。
ちなみに、fastNlMeansDenoisingという関数もありますが、カラー画像に対してはfastNlMeansDenoisingColoredが良いらしいです。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/">inpaintで画像の修復をする</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-07-31</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/inpaint/">inpaint</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%BE%A9%E5%85%83/">復元</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/6cfb060c01c9e2a5a569b5c14ee05620.png"
    class="post-cover"
    alt="inpaintで画像の修復をする"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>画像に汚れがついたり、傷がついているケースの修復には、最近ではディープラーニングを使った手法が色々出ていますが、画像処理の範囲でもできることがあります。
今回はOpenCVで修復をおこなってみます。</p>
<h1 id="opencvでやってみる">OpenCVでやってみる</h1>
<p>次の画像にノイズをのせていきます。<br>
<img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/6cfb060c01c9e2a5a569b5c14ee05620.png" alt=""></p>
<p>次のようなコードで画像にノイズをのせていきます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">300</span><span class="p">,</span><span class="mi">105</span><span class="p">),(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">450</span><span class="p">),(</span><span class="mi">600</span><span class="p">,</span><span class="mi">460</span><span class="p">),(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">750</span><span class="p">),(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">760</span><span class="p">),(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">105</span><span class="p">),(</span><span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">450</span><span class="p">),(</span><span class="mi">600</span><span class="p">,</span><span class="mi">460</span><span class="p">),(</span><span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">750</span><span class="p">),(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">760</span><span class="p">),(</span><span class="mi">255</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><table>
  <thead>
      <tr>
          <th>ノイズがのった画像</th>
          <th>ノイズ部分のmask画像</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/9b56f97f2e546e2112f37cb52fe29f70.png" alt=""></td>
          <td><img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/b5fb92837ffca156c74b247e0a00b76f.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>OpenCVのinpaint関数を使うと、このノイズがのった画像をある程度復元できます。
次のように利用します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">inpainted</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">inpaint</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">INPAINT_NS</span><span class="p">)</span>
</span></span></code></pre></div><p>第一引数に復元したい画像を指定し、第二引数に復元したい箇所をあらわしたマスク画像を指定します。第三引数が復元時に周辺のピクセルをいくつ利用するかを指定します。第四引数に復元のアルゴリズムを指定します。INPAINT_NS（Navier Stokes法）かINPAINT_TELEA（Alexandru Telea法）を指定できます。</p>
<table>
  <thead>
      <tr>
          <th>Navier Stokes法</th>
          <th>Alexandru Telea法</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/a575c7ee0289b3e759d2ad759aad4bb7.png" alt=""></td>
          <td><img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/8dfa48b36ca2cd45a71e1cae46d65918.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>どちらも結構いい感じに復元できています。右図のほうが文字の部分などはきれいに復元できている気がします。</p>
<p>ちなみにAlexandru Telea法で第三引数を10まで大きくしてみると、以下のようになります。<br>
<img src="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/c2c2a44c41b8f7e20682e1f9b8ddbe6f.png" alt=""></p>
<p>ちょっと復元した箇所が滲んだような感じになってしまってます。大きくしすぎには注意ですね。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B%E3%81%A7%E6%96%9C%E3%82%81%E3%81%8B%E3%82%89%E6%92%AE%E3%81%A3%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E4%B8%8A%E3%81%8B%E3%82%89%E8%A6%8B%E4%B8%8B%E3%82%8D%E3%81%99/">透過変換で斜めから撮った画像を上から見下ろす</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-07-30</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B/">透過変換</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B%E3%81%A7%E6%96%9C%E3%82%81%E3%81%8B%E3%82%89%E6%92%AE%E3%81%A3%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E4%B8%8A%E3%81%8B%E3%82%89%E8%A6%8B%E4%B8%8B%E3%82%8D%E3%81%99/80ab2bb0c531b5c091411d41a9dd10a4.png"
    class="post-cover"
    alt="透過変換で斜めから撮った画像を上から見下ろす"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<h1 id="透過変換とは">透過変換とは？</h1>
<p>透過変換はアフィン変換よりも柔軟な変換になっていまして、アフィン変換ではできない台形への変換が可能です。また台形から長方形への変換も可能です。
つまり、斜めに写っているものを上から見たような感じに変換ができるというわけです。</p>
<h1 id="opencvでやってみる">OpenCVでやってみる</h1>
<p>次の画像を長方形の画像に変換することを考えます。<br>
<img src="/mblog/posts/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B%E3%81%A7%E6%96%9C%E3%82%81%E3%81%8B%E3%82%89%E6%92%AE%E3%81%A3%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E4%B8%8A%E3%81%8B%E3%82%89%E8%A6%8B%E4%B8%8B%E3%82%8D%E3%81%99/130fb34c69db1a0a5b1505e2679dc456.png" alt=""></p>
<p>やりたいこととしてはこの本が斜めに（台形に）写っているので、これを長方形にすることです。</p>
<p>まず変換行列を作る必要があります。
これには次のようにgetPerspectiveTransformを使えば簡単にできます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">src</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">830</span><span class="p">,</span> <span class="mi">675</span><span class="p">],</span> <span class="p">[</span><span class="mi">26</span><span class="p">,</span> <span class="mi">2872</span><span class="p">],</span> <span class="p">[</span><span class="mi">2579</span><span class="p">,</span> <span class="mi">2852</span><span class="p">],</span> <span class="p">[</span><span class="mi">2350</span><span class="p">,</span> <span class="mi">455</span><span class="p">]],</span> 
</span></span><span class="line"><span class="cl">               <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">dst</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1150</span><span class="p">],</span> <span class="p">[</span><span class="mi">800</span><span class="p">,</span> <span class="mi">1150</span><span class="p">],</span> <span class="p">[</span><span class="mi">800</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">               <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">perspective_mat</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getPerspectiveTransform</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
</span></span></code></pre></div><p>これはsrcで指定した4つの座標がdstで指定した4つの座標に変換されるような変換行列を作ってくださいと関数に依頼しています。
srcで指定している4点は本の4隅の座標です。dstの1150と800という数値は実際の本の縦横比から適当に決めました。</p>
<p>この行列を使い、次のように変換をおこないます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">transformed</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">perspective_mat</span><span class="p">,</span> <span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">1150</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">transformed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="/mblog/posts/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B%E3%81%A7%E6%96%9C%E3%82%81%E3%81%8B%E3%82%89%E6%92%AE%E3%81%A3%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E4%B8%8A%E3%81%8B%E3%82%89%E8%A6%8B%E4%B8%8B%E3%82%8D%E3%81%99/80ab2bb0c531b5c091411d41a9dd10a4.png" alt=""></p>
<p>それっぽく長方形になりました。
ちょっと文字などが斜めになっていますが、本の表紙が浮いているせいかもしれません。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B%E3%81%A7%E6%96%9C%E3%82%81%E3%81%8B%E3%82%89%E6%92%AE%E3%81%A3%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E4%B8%8A%E3%81%8B%E3%82%89%E8%A6%8B%E4%B8%8B%E3%82%8D%E3%81%99/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h1 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%B8%E3%81%AE%E3%82%A2%E3%83%95%E3%82%A3%E3%83%B3%E5%A4%89%E6%8F%9B/">画像へのアフィン変換</a>
        </h1>
        <div class="post-meta"><time class="post-date">2020-07-29</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/affine/">affine</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%82%A2%E3%83%95%E3%82%A3%E3%83%B3%E5%A4%89%E6%8F%9B/">アフィン変換</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%B8%E3%81%AE%E3%82%A2%E3%83%95%E3%82%A3%E3%83%B3%E5%A4%89%E6%8F%9B/81a46863d26154ebd07353949e4d8171.png"
    class="post-cover"
    alt="画像へのアフィン変換"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>アフィン変換といえば、普通は2次元上の点や図形を拡大縮小したり、回転したり、平行移動したりといった変換をさします。
式の話をすると、ある2次元上の点$(x,y)$の$(x&rsquo;, y&rsquo;)$へのアフィン変換は次のようにして表現できます。
$$\begin{pmatrix}x&rsquo; \\ y&rsquo;  \\ 1 \end{pmatrix} =\begin{pmatrix} a &amp; b &amp; c\\ e &amp; f &amp; g \\ 0 &amp; 0 &amp; 1  \end{pmatrix} \begin{pmatrix}x \\ y \\ 1 \end{pmatrix}.  $$
$a,b,e,f$の値によって拡大縮小、回転をおこなうようにできますし、$c,g$の値によって平行移動が可能です。</p>
<p>今回はこのアフィン変換をOpenCVを使っておこないます。</p>
<h1 id="アフィン変換のやり方">アフィン変換のやり方</h1>
<p>OpenCVでは次のようにしてアフィン変換をおこないます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">transformed_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">warpAffine</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">affine_mat</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
</span></span></code></pre></div><p>affine_matとしているのが、アフィン変換で用いる行列です。
widthとheightは変換後の画像のサイズになります。</p>
<p>以下では次の画像に対するアフィン変換の例を示します。
<img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%B8%E3%81%AE%E3%82%A2%E3%83%95%E3%82%A3%E3%83%B3%E5%A4%89%E6%8F%9B/c4583d46713f7a842568e73b04422d57.png" alt=""></p>
<h1 id="平行移動">平行移動</h1>
<p>平行移動をするときは次のようなアフィン変換になります。
$$\begin{pmatrix}x&rsquo; \\ y&rsquo;  \\ 1 \end{pmatrix} =\begin{pmatrix} 1 &amp; 0 &amp; c\\ 0 &amp; 1 &amp; g \\ 0 &amp; 0 &amp; 1  \end{pmatrix} \begin{pmatrix}x \\ y \\ 1 \end{pmatrix}.  $$
もう少し式を書きくだせば、
$$\begin{eqnarray}x&rsquo; &amp;=&amp; x + c, \\y&rsquo;&amp;=&amp;y+g\end{eqnarray}$$
となるので、平行移動だとわかりますね。</p>
          
        </div>

        
          <div>
            <a class="read-more button inline" href="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%B8%E3%81%AE%E3%82%A2%E3%83%95%E3%82%A3%E3%83%B3%E5%A4%89%E6%8F%9B/">[Read more]</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
      <a href="/mblog/tags/opencv/" class="button inline prev">
        &lt; [<span class="button__text">Newer posts</span>]
      </a>
    
    
      ::
    
    
      <a href="/mblog/tags/opencv/page/3/" class="button inline next">
        [<span class="button__text">Older posts</span>] &gt;
      </a>
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/mblog/bundle.min.js"></script>





  
</div>

</body>
</html>
