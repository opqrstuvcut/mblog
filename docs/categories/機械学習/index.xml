<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>機械学習 on MatLoverによるMatlab以外のブログ</title>
    <link>https://opqrstuvcut.github.io/mblog/categories/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/</link>
    <description>Recent content in 機械学習 on MatLoverによるMatlab以外のブログ</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 23 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://opqrstuvcut.github.io/mblog/categories/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RT-DETR v2のファインチューニング</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/rt-detr-v2%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/</link>
      <pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/rt-detr-v2%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/</guid>
      <description>&lt;p&gt;RT-DETR v2のファインチューニングをおこなったのでメモ。&lt;br&gt;&#xA;レポジトリは &lt;a href=&#34;https://github.com/lyuwenyu/RT-DETR&#34;&gt;https://github.com/lyuwenyu/RT-DETR&lt;/a&gt; を参照してください。 また、本記事ではPyTorch版を前提としています。&lt;/p&gt;&#xA;&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;&#xA;&lt;p&gt;PyTorch版の&lt;a href=&#34;https://github.com/lyuwenyu/RT-DETR/tree/main/rtdetrv2_pytorch&#34;&gt;README&lt;/a&gt;を見てみるとそれほど記載がないですが、結構簡単にファインチューニングが可能になっています。&lt;br&gt;&#xA;おおまかに以下の手順になります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Were RNNs All We Needed?を読んだのでまとめ</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/were-rnns-all-we-needed%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0%E3%81%AE%E3%81%A7%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/were-rnns-all-we-needed%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0%E3%81%AE%E3%81%A7%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>&lt;p&gt;Were RNNs All We Needed?を読んだので、その内容をまとめておきます。&lt;br&gt;&#xA;&lt;a href=&#34;https://arxiv.org/abs/2410.01201&#34;&gt;https://arxiv.org/abs/2410.01201&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;&#xA;&lt;p&gt;Transformerを用いたアーキテクチャの場合、推論に時系列長の二乗に比例した計算量が必要となるため、単純には非常に長い時系列データを扱うことはできません．&lt;br&gt;&#xA;ちょうど一年前くらいにMambaという状態空間モデルベースの手法が提案されており、このMambaならば時系列長に比例した計算量となるため計算量的にはMambaが好ましいです．また学習も効率良くおこなえるうえ、精度的にも良い性能が得られることが分かってきており、有望な手法の1つです．&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tabularデータ向けのサーベイ論文を読んだのでメモ</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/tabular%E3%83%87%E3%83%BC%E3%82%BF%E5%90%91%E3%81%91%E3%81%AE%E3%82%B5%E3%83%BC%E3%83%99%E3%82%A4%E8%AB%96%E6%96%87%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0%E3%81%AE%E3%81%A7%E3%83%A1%E3%83%A2/</link>
      <pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/tabular%E3%83%87%E3%83%BC%E3%82%BF%E5%90%91%E3%81%91%E3%81%AE%E3%82%B5%E3%83%BC%E3%83%99%E3%82%A4%E8%AB%96%E6%96%87%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0%E3%81%AE%E3%81%A7%E3%83%A1%E3%83%A2/</guid>
      <description>&lt;p&gt;Deep Learning(DL)を用いたテーブルデータ向けの手法は色々提案されており、度々、精度面で勾配ブースティング法を超えたとか超えないと話題になる気がします。&lt;br&gt;&#xA;テーブルデータ周りのDL手法に詳しくない身からすると実際のところどうなのかというのは謎だったので、サーベイ論文を読んでみました。&lt;br&gt;&#xA;読んだ論文：&lt;a href=&#34;https://arxiv.org/abs/2110.01889&#34;&gt;Deep Neural Networks and Tabular Data: A Survey&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>YOLOv5モデルをONNXモデルにして使いたいけど後処理が面倒なとき</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/yolov5%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92onnx%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AB%E3%81%97%E3%81%A6%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%84%E3%81%91%E3%81%A9%E5%BE%8C%E5%87%A6%E7%90%86%E3%81%8C%E9%9D%A2%E5%80%92%E3%81%AA%E3%81%A8%E3%81%8D/</link>
      <pubDate>Sun, 17 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/yolov5%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92onnx%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AB%E3%81%97%E3%81%A6%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%84%E3%81%91%E3%81%A9%E5%BE%8C%E5%87%A6%E7%90%86%E3%81%8C%E9%9D%A2%E5%80%92%E3%81%AA%E3%81%A8%E3%81%8D/</guid>
      <description>&lt;h1 id=&#34;困ったこと&#34;&gt;困ったこと&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ultralytics/yolov5&#34;&gt;YOLOv5&lt;/a&gt;は便利なライブラリですが、ONNXへモデルを変換したときにちょっと困ったことがあります。&lt;br&gt;&#xA;というのも、変換後のONNXモデルにはNMSなどの後処理が含まれていないため、後処理は別途用意する必要があります。&lt;br&gt;&#xA;公式ではPyTorchの関数を使ったNMSになっているため、そのまま後処理のコードをコピーしようとすれば実行環境上にONNX RuntimeとPyTorchの両方を用意しないといけません。でもせっかくONNXを使うなら、環境にPyTorchを入れたくないですよね。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Individual Conditional Expectation</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/individual-conditional-expectation/</link>
      <pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/individual-conditional-expectation/</guid>
      <description>&lt;p&gt;Individual Conditional Expectation(ICE)は任意のモデルのある特徴量に対するデータごとの挙動を確認する手法です。&lt;br&gt;&#xA;例えば、ある特定のデータのある特徴量が大きくなるにつれ、モデルの出力がどういった変化をするかを見ます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Partial Dependence Plot</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/partial-dependence-plot/</link>
      <pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/partial-dependence-plot/</guid>
      <description>&lt;p&gt;Partial Dependence Plotは任意のモデルのある特徴量に対するglobalな挙動を確認できる手法です。&lt;br&gt;&#xA;例えば、特徴量が大きくなるにつれ、モデルの出力がどういった変化をするかがわかります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>貧乏人なのでPoor Man’s BERTを読んで解説</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/</link>
      <pubDate>Sun, 21 Jun 2020 15:22:01 +0900</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;最近自然言語処理をよくやっていて、BERTを使うことも多いです。&#xA;BERTの性能は高く素晴らしいのですが、実際使う上では、私のような計算リソース弱者には辛いところがあります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>KL divergenceに与える分布を入れ替えることの意味をまじめに考えたことあります？</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/kl-divergence%E3%81%AB%E4%B8%8E%E3%81%88%E3%82%8B%E5%88%86%E5%B8%83%E3%82%92%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E6%84%8F%E5%91%B3%E3%82%92%E3%81%BE%E3%81%98%E3%82%81%E3%81%AB%E8%80%83%E3%81%88%E3%81%9F%E3%81%93%E3%81%A8%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99/</link>
      <pubDate>Mon, 02 Mar 2020 18:01:01 +0900</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/kl-divergence%E3%81%AB%E4%B8%8E%E3%81%88%E3%82%8B%E5%88%86%E5%B8%83%E3%82%92%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E6%84%8F%E5%91%B3%E3%82%92%E3%81%BE%E3%81%98%E3%82%81%E3%81%AB%E8%80%83%E3%81%88%E3%81%9F%E3%81%93%E3%81%A8%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;みんながよく使うKL(Kullback–Leibler) divergenceの話題です。&#xA;KL divergenceといえば2つの確率分布の違いを計算できるやつですね。&#xA;KL divergenceは対称性というものがなく、与えられた2つの分布を入れ替えるとKL divergenceの値が変わります。&#xA;今回は、この入れ替えたときの影響を最小化問題を例としてまじめに考えます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>画像と自然言語でのマルチモーダルなImageBERT</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%A8%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E3%81%A7%E3%81%AE%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E3%81%AAimagebert/</link>
      <pubDate>Mon, 24 Feb 2020 19:46:50 +0900</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%A8%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E3%81%A7%E3%81%AE%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E3%81%AAimagebert/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;最近Microsoftから発表されたImageBERTについて紹介します。&lt;br&gt;&#xA;ImageBERTはBERTの入力に自然言語だけではなく、画像も受け付けるようにしたマルチモーダルなモデルです。&#xA;また論文ではモデルのアーキテクチャだけではなく、学習方法にも新たな提案がされています。&lt;br&gt;&#xA;実験ではImage-to-Sentenceでの検索とSentence-to-Imageの検索タスクでSOTAが示されています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pandasのgroupbyの使い方をまとめる</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/pandas%E3%81%AEgroupby%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%82%8B/</link>
      <pubDate>Fri, 14 Feb 2020 12:04:01 +0900</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/pandas%E3%81%AEgroupby%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%82%8B/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Pandasのgroupbyについては雰囲気でやっていたところがありますので、ちょっと真面目に使い方を調べてみました。使っているPandasのバージョンは1.0.1です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uber製の機械学習モデルのデバッグツールManifold</title>
      <link>https://opqrstuvcut.github.io/mblog/posts/uber%E8%A3%BD%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E3%83%84%E3%83%BC%E3%83%ABmanifold/</link>
      <pubDate>Tue, 28 Jan 2020 22:52:36 +0900</pubDate>
      <guid>https://opqrstuvcut.github.io/mblog/posts/uber%E8%A3%BD%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E3%83%84%E3%83%BC%E3%83%ABmanifold/</guid>
      <description>&lt;p&gt;本記事はQrunchからの転載です。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Uberが公開している機械学習モデルの予測と特徴量の関係性を可視化するツールである&lt;a href=&#34;https://github.com/uber/manifold#upload-csv-to-demo-app&#34;&gt;Manifold&lt;/a&gt;を紹介します。&lt;/p&gt;&#xA;&lt;h1 id=&#34;manifoldを試す&#34;&gt;Manifoldを試す&lt;/h1&gt;&#xA;&lt;p&gt;Manifoldでできることを見ていきます。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
