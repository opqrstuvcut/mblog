<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>統計 on MatLoverによるMatlab以外のブログ</title>
    <link>http://localhost:1313/mblog/categories/%E7%B5%B1%E8%A8%88/</link>
    <description>Recent content in 統計 on MatLoverによるMatlab以外のブログ</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 18 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/mblog/categories/%E7%B5%B1%E8%A8%88/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>WAIC</title>
      <link>http://localhost:1313/mblog/posts/waic/</link>
      <pubDate>Sat, 18 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/mblog/posts/waic/</guid>
      <description>&lt;p&gt;かなり前に「渡辺澄夫ベイズ理論100問 with R/Stan」を読み終わったのもあり、忘れないうちにWAICを自分なりにまとめておきます．&lt;/p&gt;&#xA;&lt;h2 id=&#34;waic&#34;&gt;WAIC&lt;/h2&gt;&#xA;&lt;h3 id=&#34;waicの適用範囲&#34;&gt;WAICの適用範囲&lt;/h3&gt;&#xA;&lt;p&gt;情報量基準のAICやTICは正則性を仮定していますが、実際には正則性が成り立たないケースが多いです．&lt;br&gt;&#xA;WAICは正則性を仮定せずとも利用できる情報量基準になっていて、適用範囲が広いです．ただし、どんなケースでもOKかといえばそうではなく、次の条件を満たしている必要があります（「渡辺澄夫ベイズ理論100問 with R/Stan」の(1.21)）．&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;$$&#xA;\mathbb{E}_X \left[\left \{ \log \frac{p(X| \theta_{*})}{p(X|\theta)} \right \}^2 \right] \leq c \mathbb{E}_X \left[\log \frac{p(X| \theta_{*})}{p(X|\theta)}  \right].&#xA;$$&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;上記の$c&amp;gt;0$は定数、$\theta$はモデルのパラメーター、$\theta_{*}$は真の分布$q$とのKLダイバージェンスを最も小さくするモデルのパラメーターをあらわします．&lt;/p&gt;&#xA;&lt;p&gt;この条件を満たすとき、統計モデル$\{p(\cdot|\theta)\}_{\theta \in \Theta}$および真の分布$q$に対して対数尤度比関数が相対的に有限な分散をもつといいます．これが意味するところを考えてみます．&lt;br&gt;&#xA;左辺は対数尤度比の二乗の期待値ですが、&#xA;$V[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 \leq \mathbb{E}[X^2]$ですから、&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;V_X \left[\log \frac{p(X| \theta*)}{p(X|\theta)}  \right] \leq c \mathbb{E}_X \left[\log \frac{p(X| \theta*)}{p(X|\theta)}  \right].&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;といえます．このため、対数尤度比の分散は期待値に比例した値以下になるという解釈で良さそうです．&lt;br&gt;&#xA;「相対的に」の意味は書籍からははっきりとは読み取れなかったのですが、（右辺の期待値に対して）相対的に有限ということなのかなと思っています．&lt;/p&gt;&#xA;&lt;h3 id=&#34;waicの定義&#34;&gt;WAICの定義&lt;/h3&gt;&#xA;&lt;p&gt;さて、WAICはどうやって計算するのかという話になりますが、以下のようにWAICが定義されています．&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;{\rm WAIC_n} := T_n + \frac{1}{n}V_n.&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;上記の$T_n$は経験損失をあらわし&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\begin{align*}&#xA;T_n &amp;amp;:= - \frac{1}{n}\sum_{i=1}^n \log r(x_i|x_1,\cdots, x_n), \\&#xA;r(x|x_1,\cdots,x_n) &amp;amp;:= \int_{\Theta} p(x|\theta) p(\theta|x_1,\cdots,x_n) {\rm d}\theta&#xA;\end{align*}&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>スピアマンの順位相関係数の導出</title>
      <link>http://localhost:1313/mblog/posts/%E3%82%B9%E3%83%94%E3%82%A2%E3%83%9E%E3%83%B3%E3%81%AE%E9%A0%86%E4%BD%8D%E7%9B%B8%E9%96%A2%E4%BF%82%E6%95%B0%E3%81%AE%E5%B0%8E%E5%87%BA/</link>
      <pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/mblog/posts/%E3%82%B9%E3%83%94%E3%82%A2%E3%83%9E%E3%83%B3%E3%81%AE%E9%A0%86%E4%BD%8D%E7%9B%B8%E9%96%A2%E4%BF%82%E6%95%B0%E3%81%AE%E5%B0%8E%E5%87%BA/</guid>
      <description>&lt;p&gt;スピアマンの順位相関係数の導出のメモになります。&lt;/p&gt;&#xA;&lt;h1 id=&#34;導出&#34;&gt;導出&lt;/h1&gt;&#xA;&lt;p&gt;$n$個のデータに対する2種類の値をそれぞれ$x_1,\cdots,x_n$と$y_1,\cdots,y_n$とします。&lt;br&gt;&#xA;そして、それらを何らかの方法で並べたときの順位をあらわす関数を$x_i$に対しては$R: \mathbb{R} \rightarrow \mathbb{N}$、$y_i$に対しては$S: \mathbb{R} \rightarrow \mathbb{N}$と定義します。なお、もしも同じ数が与えられたときは、適当に異なる順位をつけるとしておきます。$R$と$S$は順位をあらわす自然数に写す関数であるため全射です。&lt;br&gt;&#xA;また$R(x_1),\cdots,R(x_n)$の平均を$\bar{R}$、標準偏差を$\sigma_R$、$S(y_1),\cdots,S(y_n)$の平均を$\bar{S}$、標準偏差を$\sigma_S$とします。&lt;/p&gt;&#xA;&lt;p&gt;いまやりたいことは$x_1,\cdots, x_n$と$y_1,\cdots, y_n$に対するスピアマンの順位相関係数を求めることです。&#xA;スピアマンの順位相関係数$r$は$R(x_1),\cdots, R(x_n)$と$S(y_1),\cdots, S(y_n)$に対するピアソンの相関係数になりますので、次のようにあらわされます。&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\begin{align*}&#xA;r &amp;amp;= \frac{\frac{1}{n}\sum_{i=1}^n (R(x_i) - \bar{R})(S(y_i) - \bar{S}) }{\sigma_R \sigma_S}.&#xA;\end{align*}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;上式は次のように整理できます。&#xA;$$&#xA;\begin{align*}&#xA;r &amp;amp;= \frac{\frac{1}{n}\sum_{i=1}^n (R(x_i)S(y_i) -\bar{S}R(x_i) -\bar{R}S(y_i) + \bar{R}\bar{S}) }{\sigma_R \sigma_S} \\&#xA;&amp;amp;= \frac{\frac{1}{n}(\sum_{i=1}^n R(x_i)S(y_i)) -\bar{S}\bar{R} -\bar{R}\bar{S} + \bar{R}\bar{S} }{\sigma_R \sigma_S} \\&#xA;&amp;amp;= \frac{\frac{1}{n}(\sum_{i=1}^n R(x_i)S(y_i)) -\bar{R}\bar{S}  }{\sigma_R \sigma_S}.&#xA;\end{align*}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;ここで、$d_i= R(x_i) - S(y_i)$とおくと、&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\begin{align*}&#xA;r &amp;amp;= \frac{\frac{1}{n}\left\{\sum_{i=1}^n \frac{1}{2}(R(x_i)^2 -2 R(x_i)S(x_i) + S(y_i)^2 - d_i^2) + R(x_i)S(y_i)\right\} -\bar{R}\bar{S}  }{\sigma_R \sigma_S}  \\&#xA;&amp;amp;= \frac{\frac{1}{n}\left\{\sum_{i=1}^n \frac{1}{2}(R(x_i)^2 + S(y_i)^2 - d_i^2)\right\} -\bar{R}\bar{S}  }{\sigma_R \sigma_S}&#xA;\end{align*}&#xA;$$&#xA;となります。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
