<!DOCTYPE html>
<html lang="ja">
<head><script src="/mblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=mblog/livereload" data-no-instant defer></script>
  
    <title>画像認識モデルの性能をあげるためのTips :: MatLoverによるMatlab以外のブログ</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="画像分類モデルを作っているときに予測精度をあげるのに役に立ったなぁという方法の一覧のメモです。 簡単にできるものから順に紹介しているつもりです。
ConvolutionとFC層との橋渡しにはGlobal Averaging Poolingを使う ネットにある転移学習の例をコピペすると、畳み込み層の出力を1次元にするところでFlattenを使ってたりします。 でも実はGlobal Averaging Poolingを使ったほうが精度が良くなるかもしれません。
精度を改善するのもそうですが、モデルのパラメーターを大きく減らせることも非常に大きい恩恵だったりもします。
EfficientNetはNoisy Student版を使う 転移学習に素のEfficientNetを利用している方は多いと思いますが、Noisy Stundent版の重みを用いて転移学習することでさらに性能があがるかもしれません。
TensorFlowであれば、こちらのレポジトリが利用可能です。 https://github.com/qubvel/efficientnet
Label Smoothingを使う 1か0かのハードラベルではなく、ソフトラベルを使って過学習を抑える方法です。 TensorFlowだと、簡単に使えます。
tf.keras.losses.categorical_crossentropy(y, y_hat, label_smoothing=0.1) Learning Rate Schedulerを使う 学習率のスケジューラーを利用してみると、精度が良くなるかもしれません。
例えば、lossが下がりきったタイミングで学習率を0.1倍にしてみると、lossが少し落ちたりします。
性能が変わらないことも多いので、あまり期待しないほうが良いかも。
RandAugmentを使う RandAugmentは各画像に対して、ランダムにAugmentをいくつか利用する方法です。 RandAugmentのパラメーターはいくつのAugmentを利用するかと各Agumentでのパラメーターを制御するための値の2つのみになります。そのため、Augmentに関するパラメーターのグリッドサーチも一応可能です。
&ldquo;パラメーターがたったの2つでいいの！？&ldquo;と普通の人は効果を疑うかと思いますが、実際に試してみるとかなりうまくいきました。
使うときには、imgaugなどのライブラリを利用すると良いかと思います。次のようにしてRandAugmentを利用可能です。
import imgaug.augmenters as iaa images = iaa.RandAugment(n=2, m=30)(images=images) 論文によると、AutoAugmentよりも性能が良いという結果が出ています。
PyTorch用の実装もネットで適当に探せばすぐに見つかります。
GridMaskを使う GridMaskはAugmentの一つで、Cutoutと同じような種類のAugmentになります。 Cutoutと違い、Grid状のMaskをかける方法になります。
問題によっては結構性能があがりました。
実装はググると色々見つかります。
" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/mblog/post/00063/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LFC5W8DKV1"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-LFC5W8DKV1');
        }
      </script>



  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terminal.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/mblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/mblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="ja" />
<meta property="og:type" content="article" />
<meta property="og:title" content="画像認識モデルの性能をあげるためのTips">
<meta property="og:description" content="画像分類モデルを作っているときに予測精度をあげるのに役に立ったなぁという方法の一覧のメモです。 簡単にできるものから順に紹介しているつもりです。
ConvolutionとFC層との橋渡しにはGlobal Averaging Poolingを使う ネットにある転移学習の例をコピペすると、畳み込み層の出力を1次元にするところでFlattenを使ってたりします。 でも実はGlobal Averaging Poolingを使ったほうが精度が良くなるかもしれません。
精度を改善するのもそうですが、モデルのパラメーターを大きく減らせることも非常に大きい恩恵だったりもします。
EfficientNetはNoisy Student版を使う 転移学習に素のEfficientNetを利用している方は多いと思いますが、Noisy Stundent版の重みを用いて転移学習することでさらに性能があがるかもしれません。
TensorFlowであれば、こちらのレポジトリが利用可能です。 https://github.com/qubvel/efficientnet
Label Smoothingを使う 1か0かのハードラベルではなく、ソフトラベルを使って過学習を抑える方法です。 TensorFlowだと、簡単に使えます。
tf.keras.losses.categorical_crossentropy(y, y_hat, label_smoothing=0.1) Learning Rate Schedulerを使う 学習率のスケジューラーを利用してみると、精度が良くなるかもしれません。
例えば、lossが下がりきったタイミングで学習率を0.1倍にしてみると、lossが少し落ちたりします。
性能が変わらないことも多いので、あまり期待しないほうが良いかも。
RandAugmentを使う RandAugmentは各画像に対して、ランダムにAugmentをいくつか利用する方法です。 RandAugmentのパラメーターはいくつのAugmentを利用するかと各Agumentでのパラメーターを制御するための値の2つのみになります。そのため、Augmentに関するパラメーターのグリッドサーチも一応可能です。
&ldquo;パラメーターがたったの2つでいいの！？&ldquo;と普通の人は効果を疑うかと思いますが、実際に試してみるとかなりうまくいきました。
使うときには、imgaugなどのライブラリを利用すると良いかと思います。次のようにしてRandAugmentを利用可能です。
import imgaug.augmenters as iaa images = iaa.RandAugment(n=2, m=30)(images=images) 論文によると、AutoAugmentよりも性能が良いという結果が出ています。
PyTorch用の実装もネットで適当に探せばすぐに見つかります。
GridMaskを使う GridMaskはAugmentの一つで、Cutoutと同じような種類のAugmentになります。 Cutoutと違い、Grid状のMaskをかける方法になります。
問題によっては結構性能があがりました。
実装はググると色々見つかります。
" />
<meta property="og:url" content="http://localhost:1313/mblog/post/00063/" />
<meta property="og:site_name" content="MatLoverによるMatlab以外のブログ" />

  <meta property="og:image" content="http://localhost:1313/mblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">

  <meta property="article:section" content="Deep Learning" />

  <meta property="article:section" content="深層学習" />


  <meta property="article:published_time" content="2021-03-13 00:00:00 &#43;0000 UTC" />












</head>
<body>


<div class="container">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://localhost:1313/mblog/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/mblog/">Home</a></li>
        
      
        
          <li><a href="/mblog/page/archives/">Archives</a></li>
        
      
        
          <li><a href="/mblog/page/search/">Search</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/mblog/" >Home</a></li>
        
      
        
          <li><a href="/mblog/page/archives/" >Archives</a></li>
        
      
      
        <li>
          <ul class="menu">
            <li class="menu__trigger">&nbsp;▾</li>
            <li>
              <ul class="menu__dropdown">
                
                  
                    <li><a href="/mblog/page/search/" >Search</a></li>
                  
                
              </ul>
            </li>
          </ul>
        </li>
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<article class="post">
  <h1 class="post-title">
    <a href="http://localhost:1313/mblog/post/00063/">画像認識モデルの性能をあげるためのTips</a>
  </h1>
  <div class="post-meta"><time class="post-date">2021-03-13</time></div>

  
    <span class="post-tags">
      
      #<a href="http://localhost:1313/mblog/tags/deep-learning/">Deep Learning</a>&nbsp;
      
      #<a href="http://localhost:1313/mblog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/">深層学習</a>&nbsp;
      
      #<a href="http://localhost:1313/mblog/tags/%E7%94%BB%E5%83%8F/">画像</a>&nbsp;
      
      #<a href="http://localhost:1313/mblog/tags/efficientnet/">EfficientNet</a>&nbsp;
      
      #<a href="http://localhost:1313/mblog/tags/tensorflow/">TensorFlow</a>&nbsp;
      
      #<a href="http://localhost:1313/mblog/tags/pytorch/">PyTorch</a>&nbsp;
      
    </span>
  
  


  

  <div class="post-content"><div>
        <p>画像分類モデルを作っているときに予測精度をあげるのに役に立ったなぁという方法の一覧のメモです。
簡単にできるものから順に紹介しているつもりです。</p>
<h1 id="convolutionとfc層との橋渡しにはglobal-averaging-poolingを使う">ConvolutionとFC層との橋渡しにはGlobal Averaging Poolingを使う<a href="#convolutionとfc層との橋渡しにはglobal-averaging-poolingを使う" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>ネットにある転移学習の例をコピペすると、畳み込み層の出力を1次元にするところでFlattenを使ってたりします。
でも実はGlobal Averaging Poolingを使ったほうが精度が良くなるかもしれません。<br>
精度を改善するのもそうですが、モデルのパラメーターを大きく減らせることも非常に大きい恩恵だったりもします。</p>
<h1 id="efficientnetはnoisy-student版を使う">EfficientNetはNoisy Student版を使う<a href="#efficientnetはnoisy-student版を使う" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>転移学習に素のEfficientNetを利用している方は多いと思いますが、Noisy Stundent版の重みを用いて転移学習することでさらに性能があがるかもしれません。</p>
<p>TensorFlowであれば、こちらのレポジトリが利用可能です。
<a href="https://github.com/qubvel/efficientnet">https://github.com/qubvel/efficientnet</a></p>
<h1 id="label-smoothingを使う">Label Smoothingを使う<a href="#label-smoothingを使う" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>1か0かのハードラベルではなく、ソフトラベルを使って過学習を抑える方法です。
TensorFlowだと、簡単に使えます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">categorical_crossentropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                         <span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span></span></code></pre></div><h1 id="learning-rate-schedulerを使う">Learning Rate Schedulerを使う<a href="#learning-rate-schedulerを使う" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>学習率のスケジューラーを利用してみると、精度が良くなるかもしれません。<br>
例えば、lossが下がりきったタイミングで学習率を0.1倍にしてみると、lossが少し落ちたりします。<br>
性能が変わらないことも多いので、あまり期待しないほうが良いかも。</p>
<h1 id="randaugmentを使う">RandAugmentを使う<a href="#randaugmentを使う" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>RandAugmentは各画像に対して、ランダムにAugmentをいくつか利用する方法です。
RandAugmentのパラメーターはいくつのAugmentを利用するかと各Agumentでのパラメーターを制御するための値の2つのみになります。そのため、Augmentに関するパラメーターのグリッドサーチも一応可能です。<br>
&ldquo;パラメーターがたったの2つでいいの！？&ldquo;と普通の人は効果を疑うかと思いますが、実際に試してみるとかなりうまくいきました。</p>
<p>使うときには、imgaugなどのライブラリを利用すると良いかと思います。次のようにしてRandAugmentを利用可能です。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">imgaug.augmenters</span> <span class="k">as</span> <span class="nn">iaa</span>
</span></span><span class="line"><span class="cl"><span class="n">images</span> <span class="o">=</span> <span class="n">iaa</span><span class="o">.</span><span class="n">RandAugment</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">30</span><span class="p">)(</span><span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">)</span>
</span></span></code></pre></div><p><a href="https://arxiv.org/abs/1909.13719">論文</a>によると、AutoAugmentよりも性能が良いという結果が出ています。</p>
<p>PyTorch用の実装もネットで適当に探せばすぐに見つかります。</p>
<h1 id="gridmaskを使う">GridMaskを使う<a href="#gridmaskを使う" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>GridMaskはAugmentの一つで、Cutoutと同じような種類のAugmentになります。
Cutoutと違い、Grid状のMaskをかける方法になります。<br>
問題によっては結構性能があがりました。<br>
実装はググると色々見つかります。</p>

      </div></div>

  

  
    

  
</article>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/mblog/bundle.min.js"></script>





  
</div>

</body>
</html>
