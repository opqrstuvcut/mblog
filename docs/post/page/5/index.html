<!DOCTYPE html>
<html lang="ja">
<head><script src="/mblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=mblog/livereload" data-no-instant defer></script>
  
    <title>Posts :: MatLoverによるMatlab以外のブログ</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/mblog/post/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LFC5W8DKV1"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-LFC5W8DKV1');
        }
      </script>



  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terminal.min.77ee67c1d456ac0c280223661a10b75c7729c59aeb33001424a72a14b363e310.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/mblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/mblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="ja" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Posts">
<meta property="og:description" content="" />
<meta property="og:url" content="http://localhost:1313/mblog/post/" />
<meta property="og:site_name" content="MatLoverによるMatlab以外のブログ" />

  <meta property="og:image" content="http://localhost:1313/mblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/mblog/post/index.xml" rel="alternate" type="application/rss+xml" title="MatLoverによるMatlab以外のブログ" />







<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous">

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
            ],
            throwOnError : false
        });
    });
</script>


<style>
  section.article-content h2 {
    background-color: rgb(245, 245, 245);
    padding: 10px;
  }

  :root {
    --ja-font-family: "メイリオ", "Meiryo";
    --base-font-family: "Lato", var(--sys-font-family), var(--ja-font-family),
      sans-serif;
    --body-background: #ffffe0;
  }


</style>


</head>
<body>


<div class="container full">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://localhost:1313/mblog/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/mblog/">Home</a></li>
        
      
        
          <li><a href="/mblog/archives/">Archives</a></li>
        
      
        
          <li><a href="/mblog/search/">Search</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/mblog/" >Home</a></li>
        
      
        
          <li><a href="/mblog/archives/" >Archives</a></li>
        
      
        
          <li><a href="/mblog/search/" >Search</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/opencv%E3%81%AE%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%AE%E8%A8%88%E7%AE%97%E3%81%AFnumpy%E3%82%88%E3%82%8A%E6%96%AD%E7%84%B6%E9%80%9F%E3%81%84/">OpenCVのヒストグラムの計算はNumPyより断然速い</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-10</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0/">ヒストグラム</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/opencv%E3%81%AE%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%AE%E8%A8%88%E7%AE%97%E3%81%AFnumpy%E3%82%88%E3%82%8A%E6%96%AD%E7%84%B6%E9%80%9F%E3%81%84/5703e41eaa88a7eb01fcb7ef796e3bb3.png"
    class="post-cover"
    alt="OpenCVのヒストグラムの計算はNumPyより断然速い"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>画像処理や集計、機械学習では何かとヒストグラムを計算するケースがありますね。</p>
<p>これに伴い、ヒストグラムを計算できるライブラリは色々あるかと思いますが、OpenCVでもヒストグラムを計算する機能をもっています。
<strong>NumPyでもヒストグラムの計算できるじゃない</strong>、と思いますが、実はOpenCVの方がNumPyのヒストグラムよりも断然速いです。今回はその辺りの比較もおこなっていきます。</p>
<h1 id="opencvのヒストグラム">OpenCVのヒストグラム</h1>
<p>せっかくOpenCVを使うので、以下の画像の画素値のヒストグラムを計算してみます。<br>
<img src="/mblog/posts/opencv%E3%81%AE%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%AE%E8%A8%88%E7%AE%97%E3%81%AFnumpy%E3%82%88%E3%82%8A%E6%96%AD%E7%84%B6%E9%80%9F%E3%81%84/5703e41eaa88a7eb01fcb7ef796e3bb3.png" alt=""></p>
<p>OpenCVでのヒストグラムの計算は以下のようにおこなえます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">hist</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcHist</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="n">img</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">histSize</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="n">ranges</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
</span></span></code></pre></div><ul>
<li>imagesにはヒストグラムの計算のもととなる画像をリストの形式で渡します。</li>
<li>channelsには画像のチャネルのうち、どれを用いてヒストグラムを計算するかを指定します。いまはグレースケールで1チャネルしかないため、0を指定しています。カラー画像のときにはBGRの3チャネルなので、channelに対応する0~2のどれかを指定します。</li>
<li>maskには画像と同じサイズの1チャネルのマスクを与えることで、ヒストグラムを計算する領域を制限できます。</li>
<li>histSizeにはヒストグラムのbinの数を与えます。</li>
<li>rangesにはヒストグラムの下限と上限を指定します。厳密には(0,256)を与えるということは$[0, 256)$のような区間をあらわすことに注意してください。</li>
</ul>
<p>結果を以下のように描画してみます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hist</span><span class="p">)),</span> <span class="n">hist</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;freq&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;val&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="/mblog/posts/opencv%E3%81%AE%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%AE%E8%A8%88%E7%AE%97%E3%81%AFnumpy%E3%82%88%E3%82%8A%E6%96%AD%E7%84%B6%E9%80%9F%E3%81%84/c54a4bc6afdf7c7d6bf9033664dfe9ef.png" alt=""></p>
<h1 id="numpyとの比較">NumPyとの比較</h1>
<p>cv2.calcHistによって得たヒストグラムと全く同じヒストグラムをNumPyを用いて得ることができます。
具体的には次のようにします。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">numpy_hist</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> 
</span></span><span class="line"><span class="cl">                                     <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                     <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>
</span></span></code></pre></div><p>さて、速度はどれくらい違うかという話になりますが、%%timeitによって測定した結果が以下のとおりです。</p>
<table>
  <thead>
      <tr>
          <th>方法</th>
          <th>timeitの結果</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>cv2.calcHist</td>
          <td>2.95 ms ± 186 µs per loop</td>
      </tr>
      <tr>
          <td>np.histogram</td>
          <td>109 ms ± 7.22 ms per loop</td>
      </tr>
  </tbody>
</table>
<p>36倍程度OpenCVのほうが速いことがわかります。
全然違うのでびっくりしますね。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/opencv%E3%81%AE%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%AE%E8%A8%88%E7%AE%97%E3%81%AFnumpy%E3%82%88%E3%82%8A%E6%96%AD%E7%84%B6%E9%80%9F%E3%81%84/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/">Grabcutsで背景と猫を分離したい</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-09</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/grabcuts/">Grabcuts</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/dba26e4507ff86058f0c703b8298c1f9.png"
    class="post-cover"
    alt="Grabcutsで背景と猫を分離したい"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>次のような画像があったとします。<br>
<img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/b7906bd0d4bbe04cf62dab0eda766889.png" alt=""></p>
<p>ここから猫だけ抽出したいときに、ツールを使えば少し手間はかかりますが、切り取れると思います。<br>
実はOpenCVのGrabcutsを使えば非常に簡単にそれが実現できます。
（ディープラーニング使えばできるよね？はおいておいて）</p>
<h1 id="grabcutsを使ってみる">Grabcutsを使ってみる</h1>
<h2 id="矩形を指定">矩形を指定</h2>
<p>最初に猫を囲うような矩形を指定する方法を試していきます。
OpenCVのGrabcutsは以下のように利用できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">bgd_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">65</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">fgd_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">65</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rect</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">grabCut</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">rect</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">bgd_model</span><span class="p">,</span> <span class="n">fgd_model</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">cv2</span><span class="o">.</span><span class="n">GC_INIT_WITH_RECT</span><span class="p">)</span>
</span></span></code></pre></div><p>各引数の意味は以下のとおりです。</p>
<ul>
<li>maskの詳細は一旦おいておきます。</li>
<li>rectは猫を囲う矩形をあらわし、$(x,y,w,h)$の形式のタプルです。</li>
<li>bgd_modelとfgd_modelは内部で利用する変数なのですが、わざわざ外から与える必要があります。
なぜかといえば、grabCut関数を適用したあとに、同じ画像に再度grabCutを適用したいケースがあるのですが、そういったときに<strong>同じ</strong>bgd_modelとfgd_modelを使い回す必要があるためです。
そのため、外から変数を与えられるようになっています。</li>
<li>6つめの引数の10とあるのは、アルゴリズムの反復回数です。</li>
<li>最後のcv2.GC_INIT_WITH_RECTは指定した<strong>矩形</strong>をもとに前景である猫を抽出してくださいと指定しているflagです。</li>
</ul>
<p>分割された領域の情報はmaskに格納されます。
maskに格納される値は以下のような意味になります。</p>
<ul>
<li>0は確実に背景</li>
<li>1は確実に前景</li>
<li>2は多分背景</li>
<li>3は多分前景</li>
</ul>
<p>以下のようにして抽出された前景を抽出します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">plot_cut_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">cut_img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">mask</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">mask</span><span class="o">==</span><span class="mi">3</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cut_img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/b05f14364e9986447f89ea7659ea620e.png" alt=""></p>
<p>上手く猫だけを抽出できていますね。</p>
<h2 id="maskを指定">maskを指定</h2>
<p>次に下の画像から猫を抽出することを考えます。<br>
<img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/a8fc1d6fcb0643ca35828ac428fbb855.png" alt=""></p>
<p>まずは、さきほどと同じようにやってみます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">bgdModel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">65</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">fgdModel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">65</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rect</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">grabCut</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">rect</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">bgdModel</span><span class="p">,</span> <span class="n">fgdModel</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">cv2</span><span class="o">.</span><span class="n">GC_INIT_WITH_RECT</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/14b37a03eb325726dd45995a470bf0c1.png" alt=""></p>
<p>椅子と猫の色味が似ているためか上手くいきません。</p>
<p>ここでmaskの出番です。
前景として扱いたい部分をmaskに指定してあげることができます。
猫の顔の右下の部分を前景としたいので、その部分のmaskの値を1にします。<br>
また、grabCutの最後の引数もcv2.GC_INIT_WITH_MASKというflagに変えることで、maskを使えるようにします。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">mask</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">130</span><span class="p">,</span> <span class="mi">200</span><span class="p">:</span><span class="mi">280</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">grabCut</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">rect</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">bgdModel</span><span class="p">,</span> <span class="n">fgdModel</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">cv2</span><span class="o">.</span><span class="n">GC_INIT_WITH_MASK</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/2387bca0c34c5db2fe637178b5bb136b.png" alt=""></p>
<p>いい感じです！
追加で猫の顔の右上もmaskに前景として指定します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">mask</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">:</span><span class="mi">270</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">cv2</span><span class="o">.</span><span class="n">grabCut</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">bgdModel</span><span class="p">,</span> <span class="n">fgdModel</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">cv2</span><span class="o">.</span><span class="n">GC_INIT_WITH_MASK</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/dba26e4507ff86058f0c703b8298c1f9.png" alt=""></p>
<p>ほぼほぼ上手く猫が抽出できました！</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/grabcuts%E3%81%A7%E8%83%8C%E6%99%AF%E3%81%A8%E7%8C%AB%E3%82%92%E5%88%86%E9%9B%A2%E3%81%97%E3%81%9F%E3%81%84/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/watershed%E3%81%A7%E9%A0%98%E5%9F%9F%E6%A4%9C%E5%87%BA/">Watershedで領域検出</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-08</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/watershed/">WaterShed</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/watershed%E3%81%A7%E9%A0%98%E5%9F%9F%E6%A4%9C%E5%87%BA/37b16430461df0454f7771d8d4bbfaef.png"
    class="post-cover"
    alt="Watershedで領域検出"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>Watershedと呼ばれる方法を使うと、指定したマーカーの情報と画像のエッジから画像中の領域の分割をおこなってくれます。
マーカーとしては、この位置は領域1、この位置は領域2それ以外は背景だよといった感じの情報を与えます。</p>
<p>実際にOpenCVでやってみましょう。</p>
<h1 id="opencvでwatershed">OpenCVでWatershed</h1>
<p>次の画像にWaterShedを適用してみます。<br>
<img src="/mblog/posts/watershed%E3%81%A7%E9%A0%98%E5%9F%9F%E6%A4%9C%E5%87%BA/cdf9a74e4a1e0477d2066efbf86e93cb.png" alt=""></p>
<p>いま、4つの物体が写っていますので、これを4つの領域と背景に分けることを考えます。
マーカーは以下のように指定します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">marker</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">504</span><span class="p">,</span> <span class="mi">378</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">marker</span><span class="p">[</span><span class="mi">90</span><span class="p">:</span><span class="mi">130</span><span class="p">,</span> <span class="mi">100</span><span class="p">:</span><span class="mi">130</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">marker</span><span class="p">[</span><span class="mi">230</span><span class="p">:</span><span class="mi">270</span><span class="p">,</span> <span class="mi">125</span><span class="p">:</span><span class="mi">180</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">marker</span><span class="p">[</span><span class="mi">120</span><span class="p">:</span><span class="mi">150</span><span class="p">,</span> <span class="mi">250</span><span class="p">:</span><span class="mi">280</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl"><span class="n">marker</span><span class="p">[</span><span class="mi">280</span><span class="p">:</span><span class="mi">310</span><span class="p">,</span> <span class="mi">290</span><span class="p">:</span><span class="mi">320</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
</span></span></code></pre></div><p>markerに代入した1~4の値がそれぞれの物体上にくるようにしています。
マーカーの位置と画像を重ねると次のようになります。<br>
<img src="/mblog/posts/watershed%E3%81%A7%E9%A0%98%E5%9F%9F%E6%A4%9C%E5%87%BA/6fcd43a57464d0169077f97f8b0f6ec5.png" alt=""></p>
<p>OpenCVのWatershedは次のようにして実行できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">watershed</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">marker</span><span class="p">)</span>
</span></span></code></pre></div><p>返り値には領域を分割した結果をあらわす行列が格納されています。
行列のサイズは画像と同じになっていて、各要素の値はその座標がどの領域かを示した値が入っています。
描画してみると以下のようになります。<br>
<img src="/mblog/posts/watershed%E3%81%A7%E9%A0%98%E5%9F%9F%E6%A4%9C%E5%87%BA/37b16430461df0454f7771d8d4bbfaef.png" alt=""><br>
3つはちゃんと領域が分割できています。
白いボトルは上手くいきませんでした。エッジがあまり取れていないのかもしれないです。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/watershed%E3%81%A7%E9%A0%98%E5%9F%9F%E6%A4%9C%E5%87%BA/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/">画像の距離変換をおこなう</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-07</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B/">距離変換</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/10fec2481837301639f81cf34c21e4b1.png"
    class="post-cover"
    alt="画像の距離変換をおこなう"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>画像に対する距離変換とは、グレースケールの画像において、ピクセルから最も近い0の値をもつピクセルまでの距離を求めたものです。</p>
<p>早速OpenCVで試してみます。</p>
<h1 id="opencvで距離変換">OpenCVで距離変換</h1>
<p>次のようにして距離変換をおこなえます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">dist</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">distanceTransform</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">distanceType</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DIST_L2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">maskSize</span><span class="o">=</span><span class="mi">5</span>
</span></span><span class="line"><span class="cl">                            <span class="p">)</span>
</span></span></code></pre></div><p>distanceTypeに距離の計算方法を指定します。DIST_L2はユークリッド距離です。
maskSizeには最も近い0の値をもつピクセルまでの距離の近似値を計算するときに使うmaskの大きさを指定します。maskSize=5の例でいえば、maskをあらわす$5\times5$の行列の各要素にはmaskの中心からの距離が格納されています。このmaskを使うことで、正確に距離を計算するよりも速く距離（の近似値）が計算できます。</p>
<p>結果は以下のとおりです。</p>
<table>
  <thead>
      <tr>
          <th>入力画像</th>
          <th>距離変換適用（明るいほど距離大）</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/0b07b8f2f4af88f042743b022481f2b5.png" alt=""></td>
          <td><img src="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/10fec2481837301639f81cf34c21e4b1.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>背景が0の値をもつので、そこまでの距離が反映されています。窓の中心や、猫の顔の中心は背景から遠いので、大きな値をもっています。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/">floodFillで領域に色を塗る</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-06</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/floodfill/">floodFill</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/b7d4e85930d3ec37e0350ab3fe75e877.png"
    class="post-cover"
    alt="floodFillで領域に色を塗る"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>OpenCVのfloodFillを使うことで、選んだ点の周辺の似たような色のピクセルを塗りつぶすことができます。</p>
<h1 id="使い方">使い方</h1>
<p>次のようにしてfloodFillを利用できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">floodFill</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                    <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">seedPoint</span><span class="o">=</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">700</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">newVal</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">loDiff</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">upDiff</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</span></span></code></pre></div><p>まずmaskですが、入力画像の$(x,y)$がmaskの$(x+1, y+1)$に対応し、maskの値が0でないところは塗りつぶされません。入力画像に比べて縦横が2ピクセルずつ大きいので、元の画像の周辺に1ピクセルずつpaddingができたようなイメージですね。
seedPointに指定した座標が塗りつぶしの処理の起点になります。
newValに塗りつぶす色を指定します。
seedPointに指定したピクセルの値からloDiffを引いた値とseedPointに指定したピクセルの値にupDiffを加えた値の間に入っているピクセルをseedPointの隣から順に塗りつぶしていきます。</p>
<p>結果は以下のとおりです。</p>
<table>
  <thead>
      <tr>
          <th>入力画像</th>
          <th>floodFillの結果</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/b944ecdbe70bf25c0767c5274622e44a.png" alt=""></td>
          <td><img src="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/b7d4e85930d3ec37e0350ab3fe75e877.png" alt=""></td>
      </tr>
  </tbody>
</table>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/">Hough変換で円を検出</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-05</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/hough%E5%A4%89%E6%8F%9B/">Hough変換</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%86%86%E6%A4%9C%E5%87%BA/">円検出</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/51aa777f4487689837d45257fa1eba91.png"
    class="post-cover"
    alt="Hough変換で円を検出"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>Hough変換は直線を検出する方法として前回紹介したのですが、Hough変換を応用することで、円の検出も行えます。</p>
<h1 id="opencvで円の検出">OpenCVで円の検出</h1>
<p>次の画像から円を検出してみます。<br>
<img src="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/e976800df4c7c67950f6c87dadab89b3.png" alt=""></p>
<p>円の検出は以下のようにおこないます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">hough_circle</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HoughCircles</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">HOUGH_GRADIENT</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                <span class="n">dp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">minDist</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                <span class="n">param1</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">param2</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</span></span></code></pre></div><p>HoughLinesと異なり、画像はグレースケールの状態で渡せば、なかでエッジ検出をおこなってくれます。<br>
methodには手法を指定しますが、HOUGH_GRADIENTしかないようです。<br>
dpには分解能を指定しています。1にすると画像の解像度と同じ分解能をもちます。<br>
minDistには円同士の最小の距離を指定します。これより近いと2つの円として認識されません。<br>
param1はCanny法のしきい値の上限、param2は円上にあると判定されたエッジの点の数に対するしきい値です。</p>
<p>結果は以下のとおりです。<br>
<img src="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/51aa777f4487689837d45257fa1eba91.png" alt=""><br>
大まかには円が検出できていることがわかります。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/">Hough（ハフ）変換で直線を見つけよう</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-04</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/hough%E5%A4%89%E6%8F%9B/">Hough変換</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/f57bd9c6dc056b82e658a2f6ca7b6258.png"
    class="post-cover"
    alt="Hough（ハフ）変換で直線を見つけよう"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>Hough変換は画像から直線をみつける方法です。</p>
<h1 id="簡単な原理">簡単な原理</h1>
<p>入力として2値画像を考えます。
Hough変換では候補となる直線を用意し、直線上にいくつ0でないピクセルがあるかを数えます。
このピクセルの個数が指定したしきい値以上であった場合、その候補の直線は正しい直線として扱います。</p>
<p>なお、OpenCVでは直線の候補は以下のように$(\rho, \theta)$による極座標系であらわされています。
$$ \rho = x \cos \theta + y \sin \theta .$$
$\rho$は原点からの直線の距離、$\theta$は直線の角度をあらわします。</p>
<p>$\theta$が0でないとしたとき、上式をちょっと変形することで見慣れた形の方程式になるかと思います。
$$ y = \frac{\rho}{\sin\theta} - x \frac{\cos \theta}{\sin \theta}. $$</p>
<p>わざわざ極座標系であらわす理由はなにかというと、$y=ax+b$ような直線に対してy軸に平行な直線を考えるときに、傾きが$\infty$の直線となり扱いづらくなることを防ぐためです。
極座標系ですと、無理なくy軸に平行な直線を扱うことができます。</p>
<h1 id="opencvで試してみる">OpenCVで試してみる</h1>
<p>次の画像に対してHough変換を適用します。<br>
<img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/fc6611dea1559319bc4baebf641d0a6a.png" alt=""><br>
Hough変換にかける前に、Canny法でエッジを抽出しておきます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">threshold1</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">threshold2</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="n">apertureSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">L2gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/ee45891c46a4955315b6ce6e817e2d07.png" alt=""><br>
Canny法の結果に対して、次のようにHough変換を適用できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">hough_lines</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HoughLines</span><span class="p">(</span><span class="n">canny</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                             <span class="n">threshold</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</span></span></code></pre></div><p>rhoとthetaはそれぞれの軸方向の直線の候補の分解能になります。小さいほどたくさんの直線が見つかるかと思います。thresholdに直線の候補を採用するかを決めるしきい値を指定します。
また、min_thetaとmax_thetaで見つかる直線のthetaの最小値、最大値を決めることもできます。</p>
<p>検出された直線のパラメータ$(\rho, \theta)$は以下のようにして変換して、画像に直線として書き込んでいます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">t</span> <span class="o">=</span> <span class="mi">3000</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">hough_lines</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">rho</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x0</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">rho</span>
</span></span><span class="line"><span class="cl">    <span class="n">y0</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">rho</span>
</span></span><span class="line"><span class="cl">    <span class="n">x1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x0</span> <span class="o">-</span> <span class="n">t</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># 媒介変数表示</span>
</span></span><span class="line"><span class="cl">    <span class="n">y1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">y2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y0</span> <span class="o">-</span> <span class="n">t</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span>
</span></span></code></pre></div><p>結果は以下のとおりです。<br>
<img src="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/f57bd9c6dc056b82e658a2f6ca7b6258.png" alt=""><br>
カーテンや窓、猫の底の部分が直線として検出されています。余計な直線も結構検出されています。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/hough%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B%E3%81%A7%E7%9B%B4%E7%B7%9A%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%88%E3%81%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/">Canny法でエッジ検出</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-03</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/canny/">Canny</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/5154e105157ba91bf3bf7306d1cfffe1.jpg"
    class="post-cover"
    alt="Canny法でエッジ検出"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>エッジ検出の方法として、Canny法というものがあります。
SobelフィルタやLaplacianフィルタもエッジ検出ができるわけですが、Canny法を使うとより正確に輪郭を検出することが可能です。</p>
<h1 id="canny法の簡単な原理">Canny法の簡単な原理</h1>
<h2 id="勾配の計算">勾配の計算</h2>
<p>Canny法では画像を平滑化したあとに、Sobelフィルタによって勾配を計算します。
OpenCVでは勾配の大きさは以下の2つのうちのどちらかで計算がなされます。$G_x$と$G_y$はそれぞれ$x$方向、$y$方向の勾配です。</p>
<ol>
<li>2ノルムの場合
$$ \rm{grad}=\sqrt{G_x^2 + G_y^2}. $$</li>
<li>1ノルムの場合
$$ \rm{grad}= |G_x| + |G_y|. $$</li>
</ol>
<p>2ノルムのほうが正確ですが、計算量では1ノルムのほうが優れています。</p>
<h2 id="極大値を求める">極大値を求める</h2>
<p>次に、計算された勾配から、勾配の極大値を求めます。こうすることで、余計な箇所がエッジとして検出されるのを防ぎます。</p>
<h2 id="しきい値処理">しきい値処理</h2>
<p>最後に、しきい値処理でエッジとして扱うかどうかを決めます。
Canny法のしきい値は2つあり、1つはこの値より大きければエッジとすると決めるためのもの、もう1つはこの値よりも小さければエッジではないと決めるためのものです。
じゃあ2つのしきい値の間はどうなるの？という話ですが、隣接しているピクセルがエッジと判定されていれば、エッジと判定するようにし、そうでなければエッジではないと判定します。
単純なしきい値でのエッジの判定よりも、より柔軟ですね。</p>
<p>ただし、しきい値が非常に重要になることが容易に想像できます。</p>
<h1 id="opencvでcanny法をためす">OpenCVでCanny法をためす</h1>
<p>Canny法は以下のようにして実行できます。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="n">threshold1</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="n">threshold2</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="n">apertureSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                  <span class="n">L2gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p>threshold1がしきい値の小さい方で、threshold2がしきい値の大きい方です。apertureSizeにSobelフィルタのサイズを指定しています。また勾配の大きさに2ノルムを使う場合にはL2gradientをTrueにします。</p>
<p>結果を以下に示します。</p>
<table>
  <thead>
      <tr>
          <th>元画像</th>
          <th>canny（2ノルム）</th>
          <th>canny（1ノルム）</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/8defd1c89359b1b8b5f6142e6e0105bf.jpg" alt=""></td>
          <td><img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/a0d7c2f605896b780afcc1f54a4acaad.jpg" alt=""></td>
          <td><img src="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/5154e105157ba91bf3bf7306d1cfffe1.jpg" alt=""></td>
      </tr>
  </tbody>
</table>
<p>2ノルムのほうがきれいにエッジが取れている気がします。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/canny%E6%B3%95%E3%81%A7%E3%82%A8%E3%83%83%E3%82%B8%E6%A4%9C%E5%87%BA/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/">ヒストグラム平坦化</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-02</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/">ヒストグラム平坦化</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/e534d7e8e9969a0405e4a1b8f7eea112.png"
    class="post-cover"
    alt="ヒストグラム平坦化"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>今日はヒストグラム平坦化を扱います。</p>
<p>ヒストグラム平坦化はコントラストが偏っているような画像を補正します。
結果として、コントラストがある程度平坦化された結果が得られます。</p>
<p>処理の中身としては、実際には画像のピクセル値の累積分布関数で写像したうえで、最大値と最小値が広がるように調整してあげるというイメージです。</p>
<h1 id="opencvでヒストグラム平坦化">OpenCVでヒストグラム平坦化</h1>
<p>次の画像にヒストグラム平坦化を適用してみます。このままだと全くみえません。<br>
<img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/51cf7f08ccc657141d3e65ef1b466e4e.png" alt=""></p>
<p>この画像の画素値のヒストグラムは以下のとおりです。だいぶ偏ってますね。<br>
<img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/de36036169c411bbe353ffdf628df858.png" alt=""></p>
<p>ヒストグラム平坦化は次のようにしておこなえます。めちゃくちゃ簡単です。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">equalizeHist</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/e534d7e8e9969a0405e4a1b8f7eea112.png" alt=""><br>
ちゃんと見えるようになりましたね。</p>
<p>この画像の画素値のヒストグラムは以下のとおりです。<br>
<img src="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/e250638d16771a11e5bf8cc073ff4caf.png" alt=""></p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E5%B9%B3%E5%9D%A6%E5%8C%96/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/">Non-Local Means Denoisingでノイズ除去</a>
        </h2>
        <div class="post-meta"><time class="post-date">2020-08-01</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/opencv/">OpenCV</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/fnlmd/">FNLMD</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/">ノイズ除去</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/783215bfb0d1c75f10337b84d03a1a34.png"
    class="post-cover"
    alt="Non-Local Means Denoisingでノイズ除去"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<h1 id="non-local-means-denoisingのアイデア">Non-Local Means Denoisingのアイデア</h1>
<p>今回はノイズ除去を扱うのですが、特にガウスノイズを考えます。
これは平均が0となるノイズですので、着目しているピクセルにある意味で<strong>似ている</strong>ピクセルを画像中から探してきて、それらの平均を取れば、ノイズの影響が消えたピクセルが得られるはずです。
これがNon-Local Means Denoisingのアイデアになります。</p>
<h1 id="似ているピクセルをどう定義するか">似ているピクセルをどう定義するか</h1>
<p>Non-Local Means Denoisingでは着目しているピクセルの値自体ではなく、着目しているピクセルの<strong>周辺の値</strong>同士の差分を取ることで、似ているかどうかを考えます。
この考えから定義されるピクセル$p$と$q$間の距離は以下のようになります。
$$ d^2(B(p, f), B(q,f)) = \frac{1}{3(2f + 1)^2} \sum_{c=1}^3 \sum_{j \in B(0, f)} (I_c(p+j) - I_c(q+j))^2. $$
ここで$B(p,f)$は着目しているピクセル$p$のサイズの周辺のピクセルで、サイズが$(2f + 1) \times (2f + 1)$となっています。$I_c(p+j)$が周辺ピクセルの$c$番目のchannelの値をあらわします。</p>
<h1 id="平均値の取り方">平均値の取り方</h1>
<p>先程定義した距離を使って以下のような重みを計算します。
$$ w(p,q) = e^{-\max(d^2 - 2\sigma^2, 0) / h^2}. $$
$\sigma^2$はノイズの分散になります（OpenCVの関数で実行するときには特にこれを指定しないので、上手く処理されている？）。$h$は与えるパラメーターで、大きいほど$w$の値に差がつきづらくなります。
距離$d^2$が小さいと$w$が1に近い値を取り、$d^2$が大きいほど$w$は小さい値になります。
この$w$を重みとしたピクセル値の重み付き平均を取ることがNon-Local Means Denoisingでの処理になります。</p>
<p>この重み付き平均をとることで、似ているピクセルは強く考慮されますが、似ていないピクセルはほとんど影響を与えないため、似ているピクセルだけでの平均が取れるような計算処理になっています。</p>
<p>なお、すべてのピクセル同士で距離$d^2$を計算すると、当然計算量が大変なことになります。
このため、実際には着目しているピクセルの周辺のどこまでを考慮するかを指定します。</p>
<h1 id="opencvでやってみる">OpenCVでやってみる</h1>
<p>OpenCVでNon-Local Means Denoisingをやってみます。</p>
<p>次の左の画像にノイズをのせて右の画像を生成しました。<br>
<img src="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/c9b2cd84393504aa9ce6c0f9929fe958.png" alt=""><img src="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/74a87a7adb65b77787e724d2e7e407e5.png" alt=""></p>
<p>これに対して次のようにして、Non-Local Means Denoisingを適用します。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">denoised</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">fastNlMeansDenoisingColored</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                           <span class="n">h</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                           <span class="n">templateWindowSize</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                           <span class="n">searchWindowSize</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>
</span></span></code></pre></div><p>hはさきほどの重みで出てきた$h$と同じで、templateWindowSizeは$d^2$の計算で使われる$f$と同じで、searchWindowSizeは着目しているピクセルの周辺をどこまで考慮するかをあらわします。
ちなみに、fastNlMeansDenoisingという関数もありますが、カラー画像に対してはfastNlMeansDenoisingColoredが良いらしいです。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/">[Read more]</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
      <a href="/mblog/post/page/4/" class="button inline prev">
        &lt; [<span class="button__text">Newer posts</span>]
      </a>
    
    
      ::
    
    
      <a href="/mblog/post/page/6/" class="button inline next">
        [<span class="button__text">Older posts</span>] &gt;
      </a>
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/mblog/bundle.min.js"></script>





  
</div>

</body>
</html>
