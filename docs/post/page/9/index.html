<!DOCTYPE html>
<html lang="ja">
<head><script src="/mblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=mblog/livereload" data-no-instant defer></script>
  
    <title>Posts :: MatLoverによるMatlab以外のブログ</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/mblog/post/" />


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-LFC5W8DKV1"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-LFC5W8DKV1');
        }
      </script>



  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terminal.min.77ee67c1d456ac0c280223661a10b75c7729c59aeb33001424a72a14b363e310.css">

  
  <link rel="stylesheet" href="http://localhost:1313/mblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/mblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/mblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="ja" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Posts">
<meta property="og:description" content="" />
<meta property="og:url" content="http://localhost:1313/mblog/post/" />
<meta property="og:site_name" content="MatLoverによるMatlab以外のブログ" />

  <meta property="og:image" content="http://localhost:1313/mblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">





  <link href="/mblog/post/index.xml" rel="alternate" type="application/rss+xml" title="MatLoverによるMatlab以外のブログ" />







<link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous">

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>

<script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
            ],
            throwOnError : false
        });
    });
</script>


<style>
  section.article-content h2 {
    background-color: rgb(245, 245, 245);
    padding: 10px;
  }

  :root {
    --ja-font-family: "メイリオ", "Meiryo";
    --base-font-family: "Lato", var(--sys-font-family), var(--ja-font-family),
      sans-serif;
    --body-background: #ffffe0;
  }


</style>


</head>
<body>


<div class="container full">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://localhost:1313/mblog/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/mblog/">Home</a></li>
        
      
        
          <li><a href="/mblog/archives/">Archives</a></li>
        
      
        
          <li><a href="/mblog/search/">Search</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/mblog/" >Home</a></li>
        
      
        
          <li><a href="/mblog/archives/" >Archives</a></li>
        
      
        
          <li><a href="/mblog/search/" >Search</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bdeeplift/">ディープラーニングのモデルの特徴量の寄与を求めるDeepLift</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-12-19</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/">深層学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/">ディープラーニング</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%AF%84%E4%B8%8E/">寄与</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/deeplift/">DeepLift</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/integrated-gradients/">Integrated Gradients</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/shap/">SHAP</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>ディープラーニングのモデルに対する特徴量の寄与を求める方法の1つである、DeepLiftについて今回は説明します。</p>
<p>参考文献：<a href="https://arxiv.org/pdf/1704.02685.pdf">Learning Important Features Through Propagating Activation Differences</a></p>
<h1 id="従来法の問題点">従来法の問題点</h1>
<p>DeepLiftを提案している論文では、以下の2つが従来手法の問題点として挙げられています。</p>
<h2 id="saturation-problem">saturation problem</h2>
<p>saturation problemは勾配が0であるような区間では寄与が0になってしまう問題です。
従来手法には勾配を利用する手法が多いですが、そのような手法ではsaturation problemが発生してしまいます。
以下の図をご覧ください。
<img src="/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bdeeplift/a78fcdb1dc3c5d2431c1ab31da893c9d.png" alt=""></p>
<p>図中の関数は$y = 1 - {\rm ReLU(1 - x)}$で、この関数を1つのネットワークとして考えてみます。
この関数では$x &lt; 1$では勾配が$1$となり、$x&gt;1$では勾配が$0$になります。
入力が$x=0$の場合に比べれば、$x=2$の場合は出力値が1だけ大きくなるため、寄与は$x=0$の場合よりも大きくなって欲しいです。しかしながら、寄与=勾配$\times$入力とする寄与の計算方法の場合、
$x = 0 $では残念ながら寄与が等しく0になってしまいます。
このようにReLUによって勾配が0になってしまうことは、Integrated Gradientsの提案論文のなかでも同様に問題として挙げられています。</p>
<h2 id="discontinuous-gradients">discontinuous gradients</h2>
<p>2つ目に挙げられている問題がdiscontinuous gradientsです。これも下図をご覧ください。
<img src="/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bdeeplift/b29d1ab9a442911e96451ac4cccdbc63.png" alt="">
左から、ネットワークをあらわしている関数$y={\rm ReLU(x - 10)}$、その勾配、寄与=勾配$\times $入力です。
このような関数に対しては計算される寄与値が$x=10$で不連続となり、$x=10$までは寄与が全く無いのに、$x=10$を超えると突然寄与の値が$10$を超えるようになります。
入力値のちょっとした差で寄与が大きく変わるのは良くないですね。</p>
<h1 id="deeplift">DeepLift</h1>
<p>前述した2つの問題を解決するDeepLiftのアイディアと適用結果について述べていきます。DeepLift以外にも、<a href="https://qrunch.net/@opqrstuvcut/entries/FKxqQpXc0lhh3LMn">Integrated Gradients</a>がこれら2つの問題を解決していますが、求まった寄与が直感的ではない場合があります。このことは適用結果で示します。</p>
<p>なお、DeepLiftで利用されているアイディアの1つとして、RevealCancel Ruleというものがありますが、書くのが大変になりそうなので省略します。</p>
<h2 id="deepliftのアイディア">DeepLiftのアイディア</h2>
<p>DeepLiftはIntegrated GradientsやSHAPと同様に、基準となる点を決めておき、そこから入力$x$がどれだけ異なるか、また基準点と$x$のネットワークの出力がどれだけ異なるかをもとにして寄与値を計算していきます。
この基準となる点を$x_1^0, \cdots, x_n^0$としておきます。</p>
<p>ディープラーニングで使われる計算は線形変換と非線形変換の2つに分けられ、DeepLiftではこれによって次のように寄与の計算方法が変わってきます。</p>
<h3 id="linear-rule">Linear Rule</h3>
<p>まず線形変換の方からです。線形変換には全結合層、畳み込み層が該当します。</p>
<p>入力（あるいはある隠れ層の出力）$x_1,\cdots, x_n$から次の層のあるニューロン$y$が、重み$w_i$とバイバス$b$を用いて次のようにあらわされるとします。
$$y =  \sum_{i=1}^N w_i x_i + b$$
基準点$x_1^0, \cdots, x_n^0$でも同様に
$$y^0 =  \sum_{i=1}^N w_i x_i^0 + b$$
となります。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bdeeplift/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/">FlutterでS3にファイルをアップロードする</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-12-08</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/aws/">AWS</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/s3/">S3</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/flutter/">flutter</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/dart/">Dart</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/cognito/">Cognito</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/5156acb6c29b977915456e21c1d96fb8.png"
    class="post-cover"
    alt="FlutterでS3にファイルをアップロードする"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>FlutterでS3へファイルをアップロードするための公式のライブラリはありませんが、有志によるライブラリ<a href="https://pub.dev/packages/amazon_s3_cognito">amazon_s3_cognito</a>があります。
今回はこちらの紹介+forkしてちょっと修正したのでよければ使ってねという話になります。</p>
<h1 id="事前準備">事前準備</h1>
<p>AWS cognitoでIDプールを作っておく必要があります。
cognitoのページを開くと以下のような表示がされるので、「IDプールの管理」を押します。
<img src="/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/51dca99b7523115a42a0e5331b29bba1.png" alt=""></p>
<p>新しいIDプールの作成を押し、以下のような感じで設定をします。
<img src="/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/f29b36e4c772d25380ee184e5d4b7128.png" alt=""></p>
<p>次のページでRoleのポリシーの設定ができますので、「詳細を表示」 -&gt; 「ポリシードキュメントを表示」 からポリシーを編集します。Uauthと書いてある方だけ編集すればOKです。
<img src="/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/ec491a947954374fa40c7f89a030e67b.png" alt=""></p>
<p>ポリシーは以下のようにすれば大丈夫ですが、バケット名は自分で適当なものに変更してください。</p>
<pre tabindex="0"><code>{
    &#34;Version&#34;: &#34;2012-10-17&#34;,
    &#34;Statement&#34;: [
        {
            &#34;Sid&#34;: &#34;VisualEditor0&#34;,
            &#34;Effect&#34;: &#34;Allow&#34;,
            &#34;Action&#34;: [
                &#34;mobileanalytics:PutEvents&#34;,
                &#34;cognito-sync:*&#34;
            ],
            &#34;Resource&#34;: &#34;*&#34;
        },
        {
            &#34;Sid&#34;: &#34;VisualEditor1&#34;,
            &#34;Effect&#34;: &#34;Allow&#34;,
            &#34;Action&#34;: &#34;s3:*Object&#34;,
            &#34;Resource&#34;: &#34;arn:aws:s3:::(バケット名)*&#34;
        }
    ]
}
</code></pre><p>おそらくこれでAWS側の設定は大丈夫かと思います。</p>
<h1 id="flutter側からファイルを送信する">Flutter側からファイルを送信する</h1>
<p>amazon_s3_cognitoをpubspec.yamlに追加して、flutter pub getしたら使う準備はできました。
次のようなコードでファイルをS3に送ることができます。</p>
<pre tabindex="0"><code>import &#39;package:amazon_s3_cognito/amazon_s3_cognito.dart&#39;;
import &#39;package:amazon_s3_cognito/aws_region.dart&#39;;

String uploadedImageUrl = await AmazonS3Cognito.upload(
            imagePath,
            BUCKET_NAME,
            IDENTITY_POOL_ID,
            IMAGE_NAME,
            AwsRegion.AP_NORTHEAST_1,
            AwsRegion.AP_NORTHEAST_1)
</code></pre><ul>
<li>imagePathはスマートフォン内の送りたいファイルのパスを指定します。</li>
<li>BUCKET_NAMEはS3のバケット名を指定します。</li>
<li>IDENTITY_POOL_IDはさきほど設定したAWS cognitoから次のような詳細ページにいくことで、取得できます。以下のIDプールのIDと書かれている行のダブルクォーテーションの部分をコピペすればOKです。
<img src="/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/5156acb6c29b977915456e21c1d96fb8.png" alt=""></li>
<li>IMAGE_NAMEはS3のバケット以下のファイルの保存先のパスを指定します。</li>
<li>AwsRegion.AP_NORTHEAST_1はregionを指定しています。2つ目はsub region？の設定らしいですが、なければ同じもので特に問題ありません。</li>
</ul>
<p>返り値はS3上の保存先のファイルパスになります。失敗したときは&quot;Failed&quot;だったり空のパスが渡ってきます。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/flutter%E3%81%A7s3%E3%81%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%82%A2%E3%83%83%E3%83%97%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E5%90%91%E3%81%91%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bintegrated-gradients%E3%81%AE%E8%A7%A3%E8%AA%AC/">ディープラーニング向けの特徴量の寄与を求めるIntegrated Gradientsの解説</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-12-08</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/">深層学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/">ディープラーニング</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E5%AF%84%E4%B8%8E%E5%BA%A6/">寄与度</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/feature-importance/">feature importance</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/integrated-gradients/">Integrated Gradients</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>機械学習のモデルの出力に対する入力された特徴量の寄与を求める手法の1つに、Integrated Gradientsというものがあります。
Integrated Gradientsはディープラーニング向けの手法ですが、他のディープラーニング向けの手法では満たしていない公理（性質）をいくつも満たしているという点で優れています。
今回はそんなIntegrated Gradientsを解説します。</p>
<p>参考論文：<a href="https://arxiv.org/abs/1703.01365">Axiomatic Attribution for Deep Networks</a></p>
<h1 id="先にbaselineのお話">先にbaselineのお話</h1>
<p>本題に入る前に、大事な考え方であるbaselineを説明しておきます。</p>
<p>人間が何か起こったことに対して原因を考えるとき、何かの基準となる事がその人の中にはあり、それに比べ、「ここが良くない」とか「ここが良かったから結果としてこういう結果になったんだな」、と考えるんじゃないでしょうか。
Integrated Gradientsの場合もその考え方を用います。
先程の例の基準がbaselineと呼ばれ、画像のタスクでは例えば真っ黒の画像が使われたり、自然言語のタスクではすべてを0にしたembeddingが使われたりします（これは手法によって異なります）。つまり、真っ黒の何も写っていない画像に比べて猫の写った画像はこういう風に異なるから、これは猫の画像と判断したんだな、というように考えていくことになります。</p>
<h1 id="2つの公理">2つの公理</h1>
<p>特徴量の寄与を求める既存手法の中でも勾配を用いた手法というのは多いです。しかしながら、論文中では勾配を用いた既存手法には問題があると指摘しています。
例えばGuided back-propagationは次のSensitivity(a)を満たしていませんし、DeepLiftはImplementation Invarianceを満たしていません。</p>
<h2 id="sensitivitya">Sensitivity(a)</h2>
<p>Sensitivity(a)の定義は以下のとおりです（ちなみにaと書いてあるのはbもあるということです。詳しく知りたい方は論文を参照ください）。</p>
<blockquote>
<p>Sensitivity(a): 入力値に対する出力がbaselineの出力と異なったとき、baselineと異なる値をもつ入力の特徴量の寄与は非ゼロである。</p></blockquote>
<p>次のような例を考えると、勾配を用いる手法におけるSensitivity(a)の必要性がわかります。
$f(x) = 1 - {\rm Relu}(1-x)$というネットワークを考えます。baselineが$x=0$、入力値が$x=2$とします。$f(0)=0$、$f(2)=1$となりますのでbaselineとは出力値が変わっています。しかしながら、$x=2$では勾配が$0$になりますので、例えば「勾配×入力値」で寄与を求める場合、寄与も$0$になります。
baselineに比べて出力値が変わったのに、寄与が$0$というのはおかしい結果だというのは納得いく話かなと思います。
このため、Sensitivity(a)は寄与を求める手法として満たすべきものだと著者は主張しています。</p>
<p><img src="/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E5%90%91%E3%81%91%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bintegrated-gradients%E3%81%AE%E8%A7%A3%E8%AA%AC/53d896e3bb5aef4b00f65f9615a86e72.png" alt=""></p>
<h2 id="implementation-invariance">Implementation Invariance</h2>
<p>Implementation Invarianceの定義は以下のとおりです。</p>
<blockquote>
<p>Implementation Invariance: 実装方法が異なっていても、同じ入力に対しては求まる寄与値は等しい。</p></blockquote>
<p>具体例を次に示します。</p>
<p><strong>Implementation Invarianceの例</strong>
例えば勾配${\partial f}/{\partial x}$を計算する手法の場合、この計算は隠れ層の出力$h$を使って、 $$\frac{\partial f}{\partial x} = \frac{\partial f}{\partial h}\frac{\partial h}{\partial x}$$
とあらわせます。
勾配を求める際に${\partial f}/{\partial x}$を直接計算しても、連鎖律を使って右辺の計算を用いても結果は一緒になります。
このケースはImplementation Invarianceを満たします。</p>
<p><strong>Implementation Invarianceではない例</strong>
DeepLiftの場合は離散化した勾配を用いて寄与を計算します。
連続値を扱っている限りは連鎖律が成り立ちますが、離散化すると連鎖律が成り立たなくな**。
つまり、
$$ \frac{f(x_1) - f(x_0)}{x_1 - x_0} \neq \frac{f(x_1) - f(x_0)}{h(x_1) - h(x_0)} \frac{h(x_1) - h(x_0)}{x_1 -x_0}$$
となります。
このように計算方法（実装方法）によって結果が変わる場合はImplementation Invarianceを満たしません。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E5%90%91%E3%81%91%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%81%AE%E5%AF%84%E4%B8%8E%E3%82%92%E6%B1%82%E3%82%81%E3%82%8Bintegrated-gradients%E3%81%AE%E8%A7%A3%E8%AA%AC/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/">CNNで画像中のピクセルの座標情報を考慮できるCoordConv</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-11-30</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/cnn/">CNN</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/coordconv/">CoordConv</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/">深層学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/">ディープラーニング</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF/">畳み込み</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/keras/">Keras</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/pytorch/">PyTorch</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/87ac6257d733ab494c7d120ec4e79a99.png"
    class="post-cover"
    alt="CNNで画像中のピクセルの座標情報を考慮できるCoordConv"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>CNNの表現能力の高さはすばらしいものがありますが、何でもうまくいくわけではありません。例えば、画像中の位置情報を考慮しないと解けないような問題は、通常のCNNではうまく対応できません（具体的な例はこの後説明します）。<br>
このような問題に対応した手法としてCoordConvというものがあります。CoordConvは座標情報をCNNのなかに組み込む手法で、これを使うことで解けるようになるケースや性能が大きく改善されるようなケースがあります。また「効くか分からないけど、とりあえず組み込む」ということをしても、デメリットはそれほどありません。</p>
<p>今回はこのCoordConvの紹介です。</p>
<p>論文：<a href="https://arxiv.org/pdf/1807.03247.pdf">https://arxiv.org/pdf/1807.03247.pdf</a>
Keras実装：<a href="https://github.com/titu1994/keras-coordconv">https://github.com/titu1994/keras-coordconv</a><br>
PyTorch実装：<a href="https://github.com/mkocabas/CoordConv-pytorch">https://github.com/mkocabas/CoordConv-pytorch</a><br>
ちなみに、Keras実装は使ったことがありますが、いい感じに仕事してくれました。</p>
<h1 id="通常のcnnだと解けない問題">通常のCNNだと解けない問題</h1>
<h2 id="解けない問題の紹介">解けない問題の紹介</h2>
<p>以下の図は論文で示されている、通常のCNNではうまく解けない、あるいは性能が悪い問題設定です。</p>
<blockquote>
<p><img src="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/efb07cdfddebc778bcbeeb190d527904.png" alt=""></p></blockquote>
<ul>
<li>Supervised Coordinate Classification は2次元座標xとyを入力として2次元のグレイスケールの画像を出力する問題です。入力の(x,y)の座標に対応するピクセルだけが1、それ以外のところは0になるように出力します。出力されるピクセルの数の分類問題となります。</li>
<li>Supervised Renderingも画像を出力しますが、入力(x,y)を中心とした9×9の四角に含まれるピクセルは1、それ以外は0になるように出力します。</li>
<li>Unsupervised Density LearningはGANによって赤か青の四角と丸が書かれた画像を出力する問題となります。</li>
<li>上記の画像にはないのですが、Supervised Coordinate Classification の入力と出力を逆にした問題も論文では試されています。つまり、1ピクセルだけ1でそれ以外は0であるようなone hot encodingを入力として、1の値をもつピクセルの座標(x,y)を出力するような問題です。</li>
</ul>
<h2 id="supervised-coordinate-classificationを通常のcnnで学習させた結果">Supervised Coordinate Classificationを通常のCNNで学習させた結果</h2>
<p>Supervised Coordinate Classificationを通常のCNNで学習させたときの結果を示します。</p>
<p>訓練データとテストデータの分け方で2種類の実験をおこなっています。<br>
1つは取りうる座標全体からランダムに訓練データとテストデータに分けたケースです。もう一つは座標全体のうち、右下の部分をテストデータにし、それ以外を訓練データとするケースです。これをあらわしたのが、それぞれ以下の図のUniform splitとQuadrant splitになります。</p>
<blockquote>



	
	<a href="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/f37f360d4f973fb8ae6a980331c16510.png">
	<img src="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/f37f360d4f973fb8ae6a980331c16510_hu_a42601ebd86404f2.png" alt="">
	</a>

</blockquote>
<p>上記の2つのパターンでそれぞれ訓練データでCNNを訓練し、accuracyを計測した結果が以下の図になります。</p>
<blockquote>
<p><img src="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/e9218e21fa4fbae75ff0078db0be5bb8.png" alt=""></p></blockquote>
<p>1つの点が1つの学習されたモデルでの訓練データとテストデータのaccuracyに対応しています（多分それぞれのモデルはハイパーパラメータが異なるのですが、はっきりと読み取れませんでした）。<br>
このグラフから、Uniform splitのときには訓練データのaccuracyは1.0になることがあっても、テストデータは高々0.86程度にしかならないことがわかります。また、Quadrant splitのときにはさらにひどい状況で、<strong>テストデータはまったく正解しません</strong>（ほとんど0ですね）。</p>
<p>問題設定を見ると、一見簡単な問題のように思えますが、実際には驚くほど解きにくい問題であることがわかります。</p>
<h2 id="unsupervised-density-learningを通常のcnnで学習させた結果">Unsupervised Density Learningを通常のCNNで学習させた結果</h2>
<p>次にGANのケースも見てみます。<br>
学習データでは青の図形と赤の図形はそれぞれ平面上に一様に分布します。下図の上段右がそれを示しており、赤の点と青の点がそれぞれの色の図形の中心位置をプロットしたものです。GANで生成する画像もこのように、図形が<strong>一様に色々なところに描かれて欲しい</strong>ところです。<br>
しかしながら、CNNを使ったGANのモデルが生成した画像では赤の図形と青の図形の位置の分布には偏りがあります（モード崩壊）。下図の下段右がこれを示しています。
<img src="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/0923d0009bc673227806d583954c2239.png" alt=""></p>
<h1 id="coordconv">CoordConv</h1>
<p>前述の問題はなぜ解きにくいのでしょうか。<br>
理由としては、CNNでは畳み込みの計算をおこなうだけであり、この畳み込みの計算では画像中のどこを畳み込んでいるのかは考慮できておらず、座標を考慮する必要がある問題がうまく解けないということが挙げられます。<br>
座標を考慮できていないから解けないならば、<strong>畳み込むときに座標情報を付与すればよいのでは</strong>、というのがCoordConvの発想です。</p>
<p>具体的には以下の右の層がCoordConvになります。
<img src="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/87ac6257d733ab494c7d120ec4e79a99.png" alt=""></p>
<p>通常のCNNとの違いは、画像の各ピクセルのx軸の座標をあらわしたチャネル（i coordinate）とy軸の座標をあらわしたチャネル（j coordinate）を追加するということだけです。ただし、それぞれのチャネルの値は[-1,1]に正規化されています。</p>
<p>例えば、5×5の画像の場合では、x軸の座標をあらわしたチャネル（i coordinate）は以下のような行列になります。<br>
$$ {\rm (i \ coordinate)} = \begin{bmatrix} -1 &amp; -0.5 &amp; 0 &amp; 0.5 &amp; 1 \\ -1 &amp; -0.5 &amp; 0 &amp; 0.5 &amp; 1 \\ -1 &amp; -0.5 &amp; 0 &amp; 0.5 &amp; 1 \\ -1 &amp; -0.5 &amp; 0 &amp; 0.5 &amp; 1 \\ -1 &amp; -0.5 &amp; 0 &amp; 0.5 &amp; 1 \\ \end{bmatrix} $$</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/cnn%E3%81%A7%E7%94%BB%E5%83%8F%E4%B8%AD%E3%81%AE%E3%83%94%E3%82%AF%E3%82%BB%E3%83%AB%E3%81%AE%E5%BA%A7%E6%A8%99%E6%83%85%E5%A0%B1%E3%82%92%E8%80%83%E6%85%AE%E3%81%A7%E3%81%8D%E3%82%8Bcoordconv/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/%E5%AE%89%E6%98%93%E3%81%AB%E9%80%86%E8%A1%8C%E5%88%97%E3%82%92%E6%95%B0%E5%80%A4%E8%A8%88%E7%AE%97%E3%81%99%E3%82%8B%E3%81%AE%E3%81%AF%E3%82%84%E3%82%81%E3%82%88%E3%81%86/">安易に逆行列を数値計算するのはやめよう</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-11-15</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/python/">Python</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/numpy/">Numpy</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E9%80%86%E8%A1%8C%E5%88%97/">逆行列</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/lu%E5%88%86%E8%A7%A3/">LU分解</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%A8%88%E7%AE%97%E9%87%8F/">計算量</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E9%80%A3%E7%AB%8B%E4%B8%80%E6%AC%A1%E6%96%B9%E7%A8%8B%E5%BC%8F/">連立一次方程式</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>逆行列を使った計算というのは機械学習ではそれなりに出てきます。
例えば、最小二乗法では
$$ x = (X^T X) ^{-1} Xb$$
の形の式を計算する必要がありますし、正規分布の分散を扱うときにも逆行列が出てきます。
こういうときにnp.linalg.invを使って逆行列を求めて、その後にベクトルとの積を求めるは簡単にできますから、特に何も考えずにそういうふうにしたくなります。</p>
<p><strong>でもそれって本当に逆行列の計算が必要ですか？</strong></p>
<p>多くの問題では逆行列の値そのものよりも、$x=A^{-1}b$のような逆行列とベクトルとの積が必要になります。そのような場合、実は<strong>計算はもっと速くできますよ</strong>、というのが今日のお話です。</p>
<p>ただし今回は式を深く追うことはしませんので、細かい計算量などが気になる方は別途どこかの講義資料などの参照をお願いします。</p>
<h1 id="逆行列を求めるための計算量">逆行列を求めるための計算量</h1>
<p>逆行列を求めるための方法として多くの人が思いつくのが、おそらく線形代数の教科書に載っている掃き出し法でしょう。掃き出し法は逆行列を求めたい行列$A$に対して操作をおこない、単位行列にしていくやり方ですね。
行列$A$のサイズを$n \times n$としたとき、掃き出し法に必要な乗除算は$n^3$回、引き算は$n(n-1)^2$回です。
また別途、行列$b$との積を計算する場合には乗算が$n^2$回、足し算が$n(n-1)$回かかることに注意してください。</p>
<p>実際にはnp.linalg.invはこの方法ではなく、後述する方法を利用して（半ば無理やり？）逆行列を求めますが、そうしても計算量は上記と同じ程度になります。</p>
<h1 id="連立一次方程式を解く方法">連立一次方程式を解く方法</h1>
<p>$x=A^{-1}b$の計算は、$Ax=b$の形をした連立一次方程式とみなすことができます（$x=A^{-1}b$の両辺に左から$A$を掛けるとわかりますね）。よって、<strong>連立一次方程式が解ければ、逆行列を求める必要はない</strong>ということです。</p>
<p>以下ではnp.linalg.solveでもおこなわれている、LU分解と前進後退代入を使った連立一次方程式の解き方について述べます。</p>
<h2 id="lu分解">LU分解</h2>
<p>行列$A$に対してLU分解をおこなうことを考えます。LU分解というのは下三角行列$L$と上三角行列$U$の積に行列$A$を分解することを指します。つまり、$$A = LU$$が成り立つような$L$と$U$を求めます。</p>
<p>LU分解の計算量は乗除算が$(n-1)(n^2+n+3)/3$回で引き算が$n(n-1)(2n-1)/6$回です。ここまでは先程出てきた逆行列を求めるための計算量よりも大分少ない計算量です。</p>
<p>もちろんLU分解だけでは連立一次方程式は解けず、次の前進後退代入をおこなう必要があります。</p>
<h2 id="前進後退代入">前進後退代入</h2>
<p>LU分解が済んでいるとすると、$Ax=b$は$LUx=b$とあらわせます。$y=Ux$とおいてあげると、
$$Ax=LUx= Ly=b$$
となりますので、$Ly=b$の連立一次方程式が出てきます。これを$y$について解くと次に
$$Ux = y$$
の連立一次方程式があらわれます。最後にこれを$x$について解くことで、ようやく欲しかった$x$が求まります。</p>
<p>$Ly=b$と$Ux=y$という連立一次方程式を解くなんて計算が重そうだ！と思うかもしれません。
しかしながら、$L$は下三角行列、$U$は上三角行列であるということを考慮するとそれほど計算量は多くなりません。実際、</p>
<ul>
<li>$Ly=b$を求める計算（前進代入）：乗算$n(n-1)/2$回、加減算$n(n-1)/2$回</li>
<li>$Ux=y$を求める計算（後退代入）：乗除算$n(n+1)/2$回、加減算$n(n-1)/2$回</li>
<li>上2つの計算量の和：乗除算$n^2$回、加減算$n(n-1)$回</li>
</ul>
<p>となります。なんとこれは<strong>前述した$A^{-1}$を$b$に掛けるときの計算量と等しいです！</strong>
一見大変そうな計算をしているのに、実は行列とベクトルの積と同じ計算量だなんて驚きです。</p>
<h2 id="lu分解と前進後退代入から逆行列を求める方法">LU分解と前進後退代入から逆行列を求める方法</h2>
<p>np.linalg.invでは連立一次方程式の計算を利用して逆行列を求めるといいました。これは単位行列$E$を右辺とした連立一次方程式を解くことを指しています。つまり以下の方程式です（右辺と解$X$が行列になりますが、単純に列の分だけ解くべき方程式が増えたと思えばOKです）。
$$A X = E.$$
この方程式を解くと、$X = A^{-1}$となるのがわかりますね。</p>
<p>この方法の前進後退代入の計算量は乗除算$n(2n^2+1)/3$回、加減算$n(n-1)(4n-5)/6$回となります（この計算量の計算は結構大変…）。
LU分解の計算量との合計は乗除算が$n^3 + n- 1$回、加減算が$n(n-1)^2$回となります。掃き出し法と比べて乗除算が$n-1$回増えますが、$n$が大きくなれば無視できる程度の差です。</p>
<h1 id="計算量のまとめ">計算量のまとめ</h1>
<p>計算量についてまとめると、以下のようになります。</p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">方法</th>
          <th style="text-align: center">乗除算</th>
          <th style="text-align: center">加減算</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">掃き出し法による逆行列の計算</td>
          <td style="text-align: center">$n^3$</td>
          <td style="text-align: center">$n(n-1)^2$</td>
      </tr>
      <tr>
          <td style="text-align: center">行列とベクトルの積</td>
          <td style="text-align: center">$n^2$</td>
          <td style="text-align: center">$n(n-1)$</td>
      </tr>
      <tr>
          <td style="text-align: center">LU分解</td>
          <td style="text-align: center">$(n-1)(n^2+n+3)/3$</td>
          <td style="text-align: center">$n(n-1)(2n-1)/6$</td>
      </tr>
      <tr>
          <td style="text-align: center">前進後退代入</td>
          <td style="text-align: center">$n^2$</td>
          <td style="text-align: center">$n(n-1)$</td>
      </tr>
      <tr>
          <td style="text-align: center">LU分解+前進後退代入による逆行列の計算</td>
          <td style="text-align: center">$n^3+n-1$</td>
          <td style="text-align: center">$n(n-1)^2$</td>
      </tr>
  </tbody>
</table>
<p>LU分解と前進後退代入によって$Ax=b$を解いた場合の計算量では$n^3$に$1/3$がかかっていますから、「逆行列を求める+ベクトルとの積を計算する」の場合に比べて$1/3$程度計算量が減ることがわかります。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/%E5%AE%89%E6%98%93%E3%81%AB%E9%80%86%E8%A1%8C%E5%88%97%E3%82%92%E6%95%B0%E5%80%A4%E8%A8%88%E7%AE%97%E3%81%99%E3%82%8B%E3%81%AE%E3%81%AF%E3%82%84%E3%82%81%E3%82%88%E3%81%86/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/minio%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%ABs3%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B/">MinIOでローカルにS3みたいなものを作って開発する</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-11-09</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/minio/">MinIO</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/python/">Python</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/boto3/">boto3</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/aws/">AWS</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/s3/">S3</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/docker/">Docker</a>&nbsp;
            
          </span>
        

        
  <img src="/mblog/posts/minio%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%ABs3%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B/2d89cc4c8b3b3d34194b32b843ff40bf.png"
    class="post-cover"
    alt="MinIOでローカルにS3みたいなものを作って開発する"
    title="Cover Image" />


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<p>AWSのS3を使うようなシステムを開発するときに、S3と連携する部分だけAWSにつなぐより、ローカルにS3が欲しいなぁってふと思いました。でもそんな都合が良い話があるわけないよなぁ、なんて思ったら実はありました！その名も<strong>MinIO</strong>。
今回はMinIOの使い方を簡単にご紹介します。とても簡単です。</p>
<p>MinIOのページはこちら。<a href="https://min.io">https://min.io</a></p>
<h1 id="導入">導入</h1>
<p>自分はDockerを利用しましたので、Docker経由での使い方になります。
Dockerは嫌だという場合には公式のページをご確認下さい。<a href="https://docs.min.io/">https://docs.min.io/</a></p>
<ol>
<li>Dockerをインストール。
Dockerを入れていない人はこの機会にぜひ入れましょう！今使っていなくとも、きっといつの日か別の機会にも使うんじゃないかと思います。インストールにはこの辺が参考になりそうです。<a href="http://docs.docker.jp/engine/installation/docker-ce.html">http://docs.docker.jp/engine/installation/docker-ce.html#</a></li>
<li>ターミナル等で次を実行して、MinIOのサーバを立ち上げる。</li>
</ol>
<pre tabindex="0"><code>docker run -p 9000:9000 \
--name minio_test \
-e &#34;MINIO_ACCESS_KEY=access_key_dayo&#34; \
-e &#34;MINIO_SECRET_KEY=secret_key_dayo&#34; \
minio/minio server /data
</code></pre><p>MINIO_ACCESS_KEYがAWSのアクセスキーで、MINIO_SECRET_KEYはシークレットキーに対応します。都合がよいように決めましょう。<br>
上のコマンドの初回実行時にはdocker imageのdownloadなどが走るのでちょっと時間がかかります。<br>
（Dockerを知らない人向け）アクセスするときにポートが9000は嫌だという人は、9000:9000の左側の数字を変えましょう。例えば8888:9000とかです。</p>
<p>実行がうまくいくと次のようなメッセージが表示されるかと思います。これでS3のようなものができました！すごく簡単<br>
http://127.0.0.1:9000 からMinIOのサーバにアクセスできるはずです。</p>
<pre tabindex="0"><code>Endpoint:  http://172.17.0.2:9000  http://127.0.0.1:9000

Browser Access:
   http://172.17.0.2:9000  http://127.0.0.1:9000

Object API (Amazon S3 compatible):
   Go:         https://docs.min.io/docs/golang-client-quickstart-guide
   Java:       https://docs.min.io/docs/java-client-quickstart-guide
   Python:     https://docs.min.io/docs/python-client-quickstart-guide
   JavaScript: https://docs.min.io/docs/javascript-client-quickstart-guide
   .NET:       https://docs.min.io/docs/dotnet-client-quickstart-guide
</code></pre><h1 id="使ってみる">使ってみる</h1>
<h2 id="ブラウザで利用">ブラウザで利用</h2>
<h3 id="アクセス">アクセス</h3>
<p>ブラウザで http://127.0.0.1:9000 にアクセスすると次のような画面が表示されます。<br>
Access KeyとSecret Keyはdocker runコマンドのときに指定した<strong>MINIO_ACCESS_KEY</strong>と<strong>MINIO_SECRET_KEY</strong>の値を入れましょう。これでログインできます。<br>
<img src="/mblog/posts/minio%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%ABs3%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B/2d89cc4c8b3b3d34194b32b843ff40bf.png" alt=""></p>
<p>ログインすると以下のような画面になります。
<img src="/mblog/posts/minio%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%ABs3%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B/3417aa166eed538583c50395327d69e3.png" alt=""></p>
<h3 id="バケット生成">バケット生成</h3>
<p>ここでAWSのS3のバケット相当のものが作れます。<br>
右下の+マークを押して、Create bucketを選択後、バケット名を入力すればOKです。この手順で、例えばtestという名前のバケットを作ると以下のようになります。
<img src="/mblog/posts/minio%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%ABs3%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B/6ef57990b7aa37c68828ed21e0d68815.png" alt="">
左側に生成したバケットが表示されていますね。</p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/minio%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%ABs3%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B/">[Read more]</a>
          </div>
        
      </article>
    
      <article class="post on-list">
        <h2 class="post-title">
          <a href="http://localhost:1313/mblog/posts/bert%E3%81%A7%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86%E3%83%9D%E3%82%B1%E3%83%A2%E3%83%B3%E3%81%AE%E8%AA%AC%E6%98%8E%E6%96%87%E7%94%9F%E6%88%90/">BERTでおこなうポケモンの説明文生成</a>
        </h2>
        <div class="post-meta"><time class="post-date">2019-11-07</time></div>

        
          <span class="post-tags">
            
            #<a href="http://localhost:1313/mblog/tags/python/">Python</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/bert/">BERT</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/pytorch/">PyTorch</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/">ディープラーニング</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/">深層学習</a>&nbsp;
            
            #<a href="http://localhost:1313/mblog/tags/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86/">自然言語処理</a>&nbsp;
            
          </span>
        

        


        <div class="post-content">
          
            <p>本記事はQrunchからの転載です。</p>
<hr>
<h1 id="概要">概要</h1>
<p>自然言語界隈では非常によく話題になるBERTですが、BERTを使った文生成を実装してみたので今回はその話をします。BERTの事前学習モデルが文生成のタスクで使えたら、比較的少なめの学習データでもそれっぽく文生成できたりしないかなぁと思ってやってみました。</p>
<p>実験ではポケモンの説明文を学習させて、生成させてみました。ちなみに自分はポケモンはルビー・サファイアで止まってますので、あんまりポケモンは分からないです。（他に面白そうな題材が見つからず…。遊戯王の通常モンスターの説明文でやりたかったんですが、データ数が700弱と少なすぎて断念。）</p>
<p>参考にした論文：<a href="https://arxiv.org/abs/1902.04094">BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model</a><br>
使用した事前学習モデル：<a href="http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT%E6%97%A5%E6%9C%AC%E8%AA%9EPretrained%E3%83%A2%E3%83%87%E3%83%AB">BERT日本語Pretrainedモデル</a><br>
実装したソースコード：<a href="https://github.com/opqrstuvcut/BertMouth">https://github.com/opqrstuvcut/BertMouth</a></p>
<h1 id="bertでの文生成">BERTでの文生成</h1>
<h2 id="学習">学習</h2>
<p>学習は以下のようなネットワークを使っておこないます。</p>



	
	<a href="/mblog/posts/bert%E3%81%A7%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86%E3%83%9D%E3%82%B1%E3%83%A2%E3%83%B3%E3%81%AE%E8%AA%AC%E6%98%8E%E6%96%87%E7%94%9F%E6%88%90/729b98aa8f9032f789244aa4e870b844.png">
	<img src="/mblog/posts/bert%E3%81%A7%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86%E3%83%9D%E3%82%B1%E3%83%A2%E3%83%B3%E3%81%AE%E8%AA%AC%E6%98%8E%E6%96%87%E7%94%9F%E6%88%90/729b98aa8f9032f789244aa4e870b844_hu_2a217fa32c138738.png" alt="">
	</a>


<p>ネットワークへの入力となる各トークンはサブワードになります。<br>
例えば今回のように京都大学の事前学習モデルを利用する場合には、「何日だってなにも食べなくても元気 ！背中のタネ にたくさん栄養があるから元気だ！」という文はJuman++で形態素解析された後、サブワードに分割され、</p>
<pre tabindex="0"><code>何/日/だって/なに/##も/食べ/なくて/も/元気/！/背中/の/タ/##ネ/に/たくさん/栄養/が/ある/から/元/##気/##だ/！
</code></pre><p>となります。</p>
<p>上記のネットワークを使って、ランダムにマスクした部分のサブワードの確率が予測できるように、以下の手順を繰り返して学習をすすめていきます。</p>
<ol>
<li>ある文がN個のトークンから構成されているときに、ランダムに1つのトークンを[MASK]に置き換える（上の図の例だと2番目のトークンがこれに該当します）。</li>
<li>1つのトークンを[MASK]に置き換えたトークン列をBERTに与える。</li>
<li>BERTの出力のうち、[MASK]に対応するトークンの出力${\rm O_{[MASK]}}$に対して全結合層とsoftmaxを適用する（softmaxの結果が全サブワードの出現確率になります）。</li>
<li>求められた[MASK]に対応する出現確率のうち、正解となるサブワードの確率が高くなるように、クロスエントロピーを用いて最適化する。</li>
</ol>
<h2 id="予測">予測</h2>
<p>予測は次のようにギブスサンプリングを使います。</p>
<ol>
<li>長さNのトークン列を初期化する。</li>
<li>以下を適当な回数繰り返す。
<ul>
<li>次を全トークンに対しておこなう。
<ol>
<li>i番目(i=1,&hellip;,N)のトークンを[MASK]で置き換え、学習したネットワークに入力する。</li>
<li>出現確率が最大のサブワードで[MASK]のトークンを置換する。</li>
</ol>
</li>
</ul>
</li>
</ol>
<p>トークン列の初期化には全サブワードから一様分布に従ってサンプリングしていますが、人間が適当な文を入れてあげてもいいですし、色々やりようはあるかと思います。</p>
<h1 id="実験">実験</h1>
<h2 id="データ">データ</h2>
<p>学習には https://wiki.ポケモン.com/wiki/ポケモン一覧 のポケモンの説明文から、漢字が使われている文のみを利用しています。訓練データに使われたのは4730文で、例えば以下のような文が含まれます。</p>
<ul>
<li>生まれたときから 背中に 不思議な タネが 植えてあって 体と ともに 育つという。</li>
<li>トレーナーとの 絆が パワーの 源。 ジェット機を しのぐ 飛行能力を 誇る。</li>
</ul>
<p>こんな感じのポケモンの説明文を自動で生成できたら面白いなぁと思ったので、このデータでやってみました。うまく行けば架空のポケモンが作れますね！</p>
<h2 id="結果">結果</h2>
<p>学習したモデルで予測した結果を示します。ちなみに予測するときにサブワードの数をあらかじめ指定しますが、以下の例ではサブワードの数は20です。</p>
<p><strong>生成文1: 弱い獲物を一度捕まえると止まらない。毎日１８時間鳴くチビノーズ。</strong></p>
          
        </div>

        
           <div>
            <a class="read-more button inline" href="/mblog/posts/bert%E3%81%A7%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86%E3%83%9D%E3%82%B1%E3%83%A2%E3%83%B3%E3%81%AE%E8%AA%AC%E6%98%8E%E6%96%87%E7%94%9F%E6%88%90/">[Read more]</a>
          </div>
        
      </article>
    

    <div class="pagination">
  <div class="pagination__buttons">
    
      <a href="/mblog/post/page/8/" class="button inline prev">
        &lt; [<span class="button__text">Newer posts</span>]
      </a>
    
    
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/mblog/bundle.min.js"></script>





  
</div>

</body>
</html>
